[0m14:40:27.825775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A31EB6F4D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A3226A0B90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A322CEAE40>]}


============================== 14:40:27.829764 | cbecef13-aaec-4475-a3cd-58fb4e777024 ==============================
[0m14:40:27.829764 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:40:27.831277 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m14:40:28.046550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cbecef13-aaec-4475-a3cd-58fb4e777024', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A322DAA570>]}
[0m14:40:28.108441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cbecef13-aaec-4475-a3cd-58fb4e777024', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A3217532F0>]}
[0m14:40:28.117504 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:40:28.378564 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:40:28.379479 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:40:28.380494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'cbecef13-aaec-4475-a3cd-58fb4e777024', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A32350B6E0>]}
[0m14:40:29.251276 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.raw
[0m14:40:29.262504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cbecef13-aaec-4475-a3cd-58fb4e777024', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A322DA5AF0>]}
[0m14:40:29.307661 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:40:29.311545 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:40:29.420253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cbecef13-aaec-4475-a3cd-58fb4e777024', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A323576F30>]}
[0m14:40:29.420253 [info ] [MainThread]: Found 4 sources, 424 macros
[0m14:40:29.423340 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:40:29.424464 [debug] [MainThread]: Command end result
[0m14:40:29.439959 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:40:29.442468 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:40:29.445482 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:40:29.446477 [debug] [MainThread]: Command `dbt build` succeeded at 14:40:29.446477 after 1.73 seconds
[0m14:40:29.446477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A322CEB380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A322CEB410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A322CEB590>]}
[0m14:40:29.447479 [debug] [MainThread]: Flushing usage events
[0m14:40:30.476558 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:40:56.561822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022976EFCCB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022976E164B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022976E14F20>]}


============================== 14:40:56.566357 | 5c260d2d-07a4-4fc8-ac95-e1a1cf043d9f ==============================
[0m14:40:56.566357 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:40:56.566889 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:40:56.780819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5c260d2d-07a4-4fc8-ac95-e1a1cf043d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022975C0A5D0>]}
[0m14:40:56.840178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5c260d2d-07a4-4fc8-ac95-e1a1cf043d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002297857D5B0>]}
[0m14:40:56.844145 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:40:57.102284 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:40:57.160064 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:40:57.160064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5c260d2d-07a4-4fc8-ac95-e1a1cf043d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002297A493650>]}
[0m14:40:58.031872 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.duckdb.raw
[0m14:40:58.043282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5c260d2d-07a4-4fc8-ac95-e1a1cf043d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002297A40A2A0>]}
[0m14:40:58.088635 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:40:58.090714 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:40:58.126768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5c260d2d-07a4-4fc8-ac95-e1a1cf043d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002297A076C90>]}
[0m14:40:58.127766 [info ] [MainThread]: Found 4 sources, 424 macros
[0m14:40:58.129340 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:40:58.130269 [debug] [MainThread]: Command end result
[0m14:40:58.147235 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:40:58.149711 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:40:58.152758 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:40:58.153755 [debug] [MainThread]: Command `dbt build` succeeded at 14:40:58.153755 after 1.70 seconds
[0m14:40:58.153755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022979422780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022979149070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229797EACF0>]}
[0m14:40:58.154758 [debug] [MainThread]: Flushing usage events
[0m14:40:59.251306 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:41:51.321872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002585E21D7F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002585DF1FB30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258609F7530>]}


============================== 14:41:51.325365 | eca706d8-9606-47d8-acd2-245f584537d1 ==============================
[0m14:41:51.325365 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:41:51.326352 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m14:41:51.536908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eca706d8-9606-47d8-acd2-245f584537d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258615DE810>]}
[0m14:41:51.597806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eca706d8-9606-47d8-acd2-245f584537d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025861426660>]}
[0m14:41:51.601723 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:41:51.877786 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:41:51.942906 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:41:51.944142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'eca706d8-9606-47d8-acd2-245f584537d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025862266150>]}
[0m14:41:52.814075 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.duckdb
[0m14:41:52.825058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eca706d8-9606-47d8-acd2-245f584537d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025862266240>]}
[0m14:41:52.872235 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:41:52.874726 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:41:52.910878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eca706d8-9606-47d8-acd2-245f584537d1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025863134E60>]}
[0m14:41:52.910878 [info ] [MainThread]: Found 4 sources, 424 macros
[0m14:41:52.912867 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:41:52.913865 [debug] [MainThread]: Command end result
[0m14:41:52.929377 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:41:52.931930 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:41:52.934941 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:41:52.936499 [debug] [MainThread]: Command `dbt build` succeeded at 14:41:52.935940 after 1.73 seconds
[0m14:41:52.937039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002585E21D7F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000258602C5CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025861D9F5C0>]}
[0m14:41:52.937039 [debug] [MainThread]: Flushing usage events
[0m14:41:53.829762 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:46:47.695426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE2766DBE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE277D5880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE26EE1E20>]}


============================== 14:46:47.698819 | 3053d695-6104-42d2-b5fc-7193635bdeed ==============================
[0m14:46:47.698819 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:46:47.699816 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:46:47.915109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3053d695-6104-42d2-b5fc-7193635bdeed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE2410A390>]}
[0m14:46:47.975316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3053d695-6104-42d2-b5fc-7193635bdeed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE267F7320>]}
[0m14:46:47.978339 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:46:48.237396 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:46:48.360320 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:46:48.360829 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:46:48.361336 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.duckdb
[0m14:46:48.372934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3053d695-6104-42d2-b5fc-7193635bdeed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE2854A030>]}
[0m14:46:48.424545 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:46:48.426933 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:46:48.449068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3053d695-6104-42d2-b5fc-7193635bdeed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE28A843B0>]}
[0m14:46:48.449068 [info ] [MainThread]: Found 4 sources, 424 macros
[0m14:46:48.449576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3053d695-6104-42d2-b5fc-7193635bdeed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE2854B110>]}
[0m14:46:48.451337 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:46:48.452846 [debug] [MainThread]: Command end result
[0m14:46:48.468595 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:46:48.470628 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:46:48.473210 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:46:48.474231 [debug] [MainThread]: Command `dbt run` succeeded at 14:46:48.474231 after 0.90 seconds
[0m14:46:48.474740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE267517C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE2766DBE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE27CE6AB0>]}
[0m14:46:48.475249 [debug] [MainThread]: Flushing usage events
[0m14:46:49.456642 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:49:43.116666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025549887740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002554D609EE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002554D249130>]}


============================== 14:49:43.120693 | 5bb04b8d-fa17-4668-9917-b3d88e797821 ==============================
[0m14:49:43.120693 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:49:43.121675 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m14:49:43.331517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5bb04b8d-fa17-4668-9917-b3d88e797821', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002554AF006E0>]}
[0m14:49:43.392899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5bb04b8d-fa17-4668-9917-b3d88e797821', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002554C3F7470>]}
[0m14:49:43.396486 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:49:43.656667 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:49:43.768843 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:49:43.768843 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:49:43.769836 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.duckdb
[0m14:49:43.781405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5bb04b8d-fa17-4668-9917-b3d88e797821', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002554D9AAC90>]}
[0m14:49:43.830189 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:49:43.832123 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:49:43.866219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5bb04b8d-fa17-4668-9917-b3d88e797821', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002554E72FE90>]}
[0m14:49:43.866219 [info ] [MainThread]: Found 4 sources, 424 macros
[0m14:49:43.868194 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:49:43.870744 [debug] [MainThread]: Command end result
[0m14:49:43.887044 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:49:43.889065 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:49:43.891572 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:49:43.892565 [debug] [MainThread]: Command `dbt build` succeeded at 14:49:43.892565 after 0.93 seconds
[0m14:49:43.893566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002554D7326F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002554D733980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002554D733A40>]}
[0m14:49:43.894074 [debug] [MainThread]: Flushing usage events
[0m14:49:44.779457 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:54:54.543055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231C7D78890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231C7D79B20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231C7D7BA40>]}


============================== 14:54:54.547096 | 9147752c-a792-4d77-820d-e9074b620ec8 ==============================
[0m14:54:54.547096 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:54:54.548093 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\Julien\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:54:54.762001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9147752c-a792-4d77-820d-e9074b620ec8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231C8676750>]}
[0m14:54:54.822415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9147752c-a792-4d77-820d-e9074b620ec8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231C8233C20>]}
[0m14:54:54.825489 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:54:55.099068 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:54:55.155670 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m14:54:55.155670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '9147752c-a792-4d77-820d-e9074b620ec8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231C7D7A300>]}
[0m14:54:56.031361 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.duckdb
[0m14:54:56.042195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9147752c-a792-4d77-820d-e9074b620ec8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231C90126C0>]}
[0m14:54:56.087650 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:54:56.090641 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:54:56.126932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9147752c-a792-4d77-820d-e9074b620ec8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231C91D6BD0>]}
[0m14:54:56.126932 [info ] [MainThread]: Found 4 sources, 424 macros
[0m14:54:56.129497 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:54:56.130040 [debug] [MainThread]: Command end result
[0m14:54:56.146770 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:54:56.148766 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:54:56.152161 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:54:56.153155 [debug] [MainThread]: Command `dbt build` succeeded at 14:54:56.153155 after 1.72 seconds
[0m14:54:56.153889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231C80D97C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231C78AF6E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000231C78AF8F0>]}
[0m14:54:56.153889 [debug] [MainThread]: Flushing usage events
[0m14:54:57.095129 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:55:47.681583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131A792E7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131AB8D2B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131AA785250>]}


============================== 14:55:47.685590 | d2b7e922-bccc-4880-b4d1-d634af29c3d7 ==============================
[0m14:55:47.685590 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:55:47.686106 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\Julien\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:55:47.899012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd2b7e922-bccc-4880-b4d1-d634af29c3d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131AA72A450>]}
[0m14:55:47.958917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd2b7e922-bccc-4880-b4d1-d634af29c3d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131A7E9AF60>]}
[0m14:55:47.962604 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:55:48.222763 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:55:48.342881 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m14:55:48.342881 [debug] [MainThread]: Partial parsing: added file: archi://models\duckdb\test.sql
[0m14:55:48.616488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd2b7e922-bccc-4880-b4d1-d634af29c3d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131AC7C8200>]}
[0m14:55:48.678843 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:55:48.680928 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:55:48.717663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd2b7e922-bccc-4880-b4d1-d634af29c3d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131ACBCE660>]}
[0m14:55:48.717663 [info ] [MainThread]: Found 1 model, 4 sources, 424 macros
[0m14:55:48.719606 [info ] [MainThread]: 
[0m14:55:48.720603 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:55:48.720603 [info ] [MainThread]: 
[0m14:55:48.721895 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:55:48.722851 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev'
[0m14:55:48.846892 [debug] [ThreadPool]: Using duckdb connection "list_dev"
[0m14:55:48.846892 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dev"'
    
  
  
[0m14:55:48.848183 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:55:48.866527 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m14:55:48.867521 [debug] [ThreadPool]: On list_dev: Close
[0m14:55:48.870690 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now create_dev_main)
[0m14:55:48.870690 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "main"
"
[0m14:55:48.877695 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m14:55:48.877695 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dev'
        and type='sqlite'
    
  
[0m14:55:48.878203 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:48.892710 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m14:55:48.893696 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m14:55:48.893696 [debug] [ThreadPool]: On create_dev_main: BEGIN
[0m14:55:48.894693 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:48.895211 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m14:55:48.895211 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
    
        create schema if not exists "dev"."main"
    
[0m14:55:48.895724 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:48.896773 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m14:55:48.896773 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m14:55:48.896773 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m14:55:48.897741 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:48.897741 [debug] [ThreadPool]: On create_dev_main: Close
[0m14:55:48.901247 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev_main'
[0m14:55:48.906768 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m14:55:48.907276 [debug] [ThreadPool]: On list_dev_main: BEGIN
[0m14:55:48.907276 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:55:48.915898 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:55:48.916410 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m14:55:48.916410 [debug] [ThreadPool]: On list_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev_main"} */
select
      'dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'dev'
  
[0m14:55:48.959958 [debug] [ThreadPool]: SQL status: OK in 0.043 seconds
[0m14:55:48.961532 [debug] [ThreadPool]: On list_dev_main: ROLLBACK
[0m14:55:48.962548 [debug] [ThreadPool]: Failed to rollback 'list_dev_main'
[0m14:55:48.962548 [debug] [ThreadPool]: On list_dev_main: Close
[0m14:55:48.966916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd2b7e922-bccc-4880-b4d1-d634af29c3d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131ACAAA030>]}
[0m14:55:48.967425 [debug] [MainThread]: Using duckdb connection "master"
[0m14:55:48.967932 [debug] [MainThread]: On master: BEGIN
[0m14:55:48.967932 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:55:48.976159 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m14:55:48.976159 [debug] [MainThread]: On master: COMMIT
[0m14:55:48.977458 [debug] [MainThread]: Using duckdb connection "master"
[0m14:55:48.977458 [debug] [MainThread]: On master: COMMIT
[0m14:55:48.978436 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:55:48.978436 [debug] [MainThread]: On master: Close
[0m14:55:48.982740 [debug] [Thread-1 (]: Began running node model.archi.test
[0m14:55:48.982760 [info ] [Thread-1 (]: 1 of 1 START sql view model main.test .......................................... [RUN]
[0m14:55:48.983737 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.test'
[0m14:55:48.983737 [debug] [Thread-1 (]: Began compiling node model.archi.test
[0m14:55:48.991579 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.test"
[0m14:55:48.992576 [debug] [Thread-1 (]: Began executing node model.archi.test
[0m14:55:49.026671 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.test"
[0m14:55:49.027668 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m14:55:49.028666 [debug] [Thread-1 (]: On model.archi.test: BEGIN
[0m14:55:49.028666 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:55:49.038199 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:55:49.038199 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m14:55:49.038199 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "dev"."main"."test__dbt_tmp" as (
    SELECT * FROM "dev"."raw"."raw_commits"
  );

[0m14:55:49.074804 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "dev"."main"."test__dbt_tmp" as (
    SELECT * FROM "dev"."raw"."raw_commits"
  );

[0m14:55:49.074804 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:55:49.075755 [debug] [Thread-1 (]: On model.archi.test: ROLLBACK
[0m14:55:49.080932 [debug] [Thread-1 (]: Failed to rollback 'model.archi.test'
[0m14:55:49.080932 [debug] [Thread-1 (]: On model.archi.test: Close
[0m14:55:49.087913 [debug] [Thread-1 (]: Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^
[0m14:55:49.094965 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2b7e922-bccc-4880-b4d1-d634af29c3d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131AC250FE0>]}
[0m14:55:49.094965 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main.test ................................. [[31mERROR[0m in 0.11s]
[0m14:55:49.095976 [debug] [Thread-1 (]: Finished running node model.archi.test
[0m14:55:49.096960 [debug] [Thread-4 (]: Marking all children of 'model.archi.test' to be skipped because of status 'error'.  Reason: Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^.
[0m14:55:49.097983 [debug] [MainThread]: Using duckdb connection "master"
[0m14:55:49.098955 [debug] [MainThread]: On master: BEGIN
[0m14:55:49.098955 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:55:49.107974 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m14:55:49.107974 [debug] [MainThread]: On master: COMMIT
[0m14:55:49.108482 [debug] [MainThread]: Using duckdb connection "master"
[0m14:55:49.108482 [debug] [MainThread]: On master: COMMIT
[0m14:55:49.108990 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:55:49.109498 [debug] [MainThread]: On master: Close
[0m14:55:49.111520 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:55:49.112522 [debug] [MainThread]: Connection 'create_dev_main' was properly closed.
[0m14:55:49.112522 [debug] [MainThread]: Connection 'list_dev_main' was properly closed.
[0m14:55:49.113030 [debug] [MainThread]: Connection 'model.archi.test' was properly closed.
[0m14:55:49.113030 [info ] [MainThread]: 
[0m14:55:49.114024 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.39 seconds (0.39s).
[0m14:55:49.114973 [debug] [MainThread]: Command end result
[0m14:55:49.132902 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:55:49.134874 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:55:49.140516 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:55:49.140516 [info ] [MainThread]: 
[0m14:55:49.141498 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:55:49.141498 [info ] [MainThread]: 
[0m14:55:49.142495 [error] [MainThread]:   Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^
[0m14:55:49.142495 [info ] [MainThread]: 
[0m14:55:49.143492 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:55:49.144489 [debug] [MainThread]: Command `dbt build` failed at 14:55:49.144489 after 1.58 seconds
[0m14:55:49.144489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131AB785700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131AB785070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131AB786780>]}
[0m14:55:49.145488 [debug] [MainThread]: Flushing usage events
[0m14:55:50.035189 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:57:01.483275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CFF36E690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CFB92FB60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CFF34A9F0>]}


============================== 14:57:01.487298 | 555a28bd-3844-40ff-957a-074fe07af650 ==============================
[0m14:57:01.487298 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:57:01.488280 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Julien\\.dbt', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m14:57:01.705820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '555a28bd-3844-40ff-957a-074fe07af650', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CFE781A60>]}
[0m14:57:01.771538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '555a28bd-3844-40ff-957a-074fe07af650', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CFFD78A70>]}
[0m14:57:01.775035 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:57:02.033630 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:57:02.166100 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:57:02.166100 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:57:02.197567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '555a28bd-3844-40ff-957a-074fe07af650', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CFFD55850>]}
[0m14:57:02.261807 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:57:02.264006 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:57:02.300459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '555a28bd-3844-40ff-957a-074fe07af650', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D00B684D0>]}
[0m14:57:02.301707 [info ] [MainThread]: Found 1 model, 4 sources, 424 macros
[0m14:57:02.304664 [info ] [MainThread]: 
[0m14:57:02.305168 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:57:02.305186 [info ] [MainThread]: 
[0m14:57:02.306200 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:57:02.306200 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev'
[0m14:57:02.391381 [debug] [ThreadPool]: Using duckdb connection "list_dev"
[0m14:57:02.391932 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dev"'
    
  
  
[0m14:57:02.391932 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:57:02.402551 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m14:57:02.404593 [debug] [ThreadPool]: On list_dev: Close
[0m14:57:02.407099 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now create_dev_main)
[0m14:57:02.407609 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "main"
"
[0m14:57:02.413651 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m14:57:02.413651 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dev'
        and type='sqlite'
    
  
[0m14:57:02.413651 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:57:02.423724 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:57:02.425234 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m14:57:02.425234 [debug] [ThreadPool]: On create_dev_main: BEGIN
[0m14:57:02.425234 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:57:02.426230 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m14:57:02.426230 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
    
        create schema if not exists "dev"."main"
    
[0m14:57:02.426746 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:57:02.427255 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m14:57:02.428248 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m14:57:02.428248 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m14:57:02.428248 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:57:02.429284 [debug] [ThreadPool]: On create_dev_main: Close
[0m14:57:02.432346 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev_main'
[0m14:57:02.437278 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m14:57:02.438275 [debug] [ThreadPool]: On list_dev_main: BEGIN
[0m14:57:02.438275 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:57:02.446481 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:57:02.446481 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m14:57:02.447443 [debug] [ThreadPool]: On list_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev_main"} */
select
      'dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'dev'
  
[0m14:57:02.490778 [debug] [ThreadPool]: SQL status: OK in 0.043 seconds
[0m14:57:02.492280 [debug] [ThreadPool]: On list_dev_main: ROLLBACK
[0m14:57:02.493282 [debug] [ThreadPool]: Failed to rollback 'list_dev_main'
[0m14:57:02.493790 [debug] [ThreadPool]: On list_dev_main: Close
[0m14:57:02.496308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '555a28bd-3844-40ff-957a-074fe07af650', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D0073E330>]}
[0m14:57:02.497438 [debug] [MainThread]: Using duckdb connection "master"
[0m14:57:02.497438 [debug] [MainThread]: On master: BEGIN
[0m14:57:02.497438 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:57:02.506916 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m14:57:02.506916 [debug] [MainThread]: On master: COMMIT
[0m14:57:02.507914 [debug] [MainThread]: Using duckdb connection "master"
[0m14:57:02.507914 [debug] [MainThread]: On master: COMMIT
[0m14:57:02.507914 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:57:02.508950 [debug] [MainThread]: On master: Close
[0m14:57:02.511972 [debug] [Thread-1 (]: Began running node model.archi.test
[0m14:57:02.512963 [info ] [Thread-1 (]: 1 of 1 START sql view model main.test .......................................... [RUN]
[0m14:57:02.513470 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.test'
[0m14:57:02.513470 [debug] [Thread-1 (]: Began compiling node model.archi.test
[0m14:57:02.520550 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.test"
[0m14:57:02.521057 [debug] [Thread-1 (]: Began executing node model.archi.test
[0m14:57:02.556208 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.test"
[0m14:57:02.557603 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m14:57:02.557603 [debug] [Thread-1 (]: On model.archi.test: BEGIN
[0m14:57:02.557603 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:57:02.566510 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m14:57:02.566510 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m14:57:02.567458 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "dev"."main"."test__dbt_tmp" as (
    SELECT * FROM "dev"."raw"."raw_commits"
  );

[0m14:57:02.603895 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "dev"."main"."test__dbt_tmp" as (
    SELECT * FROM "dev"."raw"."raw_commits"
  );

[0m14:57:02.604892 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:57:02.605444 [debug] [Thread-1 (]: On model.archi.test: ROLLBACK
[0m14:57:02.609523 [debug] [Thread-1 (]: Failed to rollback 'model.archi.test'
[0m14:57:02.610546 [debug] [Thread-1 (]: On model.archi.test: Close
[0m14:57:02.615260 [debug] [Thread-1 (]: Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^
[0m14:57:02.617891 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '555a28bd-3844-40ff-957a-074fe07af650', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018D00F44170>]}
[0m14:57:02.617891 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main.test ................................. [[31mERROR[0m in 0.10s]
[0m14:57:02.618871 [debug] [Thread-1 (]: Finished running node model.archi.test
[0m14:57:02.619874 [debug] [Thread-4 (]: Marking all children of 'model.archi.test' to be skipped because of status 'error'.  Reason: Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^.
[0m14:57:02.621376 [debug] [MainThread]: Using duckdb connection "master"
[0m14:57:02.621376 [debug] [MainThread]: On master: BEGIN
[0m14:57:02.621376 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:57:02.630506 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m14:57:02.630506 [debug] [MainThread]: On master: COMMIT
[0m14:57:02.630506 [debug] [MainThread]: Using duckdb connection "master"
[0m14:57:02.631501 [debug] [MainThread]: On master: COMMIT
[0m14:57:02.632220 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:57:02.632220 [debug] [MainThread]: On master: Close
[0m14:57:02.635229 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:57:02.635229 [debug] [MainThread]: Connection 'create_dev_main' was properly closed.
[0m14:57:02.636228 [debug] [MainThread]: Connection 'list_dev_main' was properly closed.
[0m14:57:02.636228 [debug] [MainThread]: Connection 'model.archi.test' was properly closed.
[0m14:57:02.636228 [info ] [MainThread]: 
[0m14:57:02.637225 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.33 seconds (0.33s).
[0m14:57:02.637225 [debug] [MainThread]: Command end result
[0m14:57:02.653615 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:57:02.655659 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:57:02.661610 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:57:02.661610 [info ] [MainThread]: 
[0m14:57:02.662597 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:57:02.663113 [info ] [MainThread]: 
[0m14:57:02.663113 [error] [MainThread]:   Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^
[0m14:57:02.664099 [info ] [MainThread]: 
[0m14:57:02.664099 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m14:57:02.665727 [debug] [MainThread]: Command `dbt build` failed at 14:57:02.665727 after 1.30 seconds
[0m14:57:02.666243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CFE6A2A20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CFE6A29F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018CFE6A1280>]}
[0m14:57:02.666243 [debug] [MainThread]: Flushing usage events
[0m14:57:03.688007 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:00:33.886779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E4B079A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E4B07A870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E4ACBF380>]}


============================== 15:00:33.890860 | 49bdb364-1453-4199-9bd3-99f9295be5f5 ==============================
[0m15:00:33.890860 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:00:33.891924 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\Julien\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:00:34.126631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '49bdb364-1453-4199-9bd3-99f9295be5f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E4BE54B00>]}
[0m15:00:34.195560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '49bdb364-1453-4199-9bd3-99f9295be5f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E4A98EA80>]}
[0m15:00:34.200228 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:00:34.489321 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:00:34.637275 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:00:34.637275 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:00:34.672896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '49bdb364-1453-4199-9bd3-99f9295be5f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E4BE29490>]}
[0m15:00:34.745392 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:00:34.748573 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:00:34.787069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '49bdb364-1453-4199-9bd3-99f9295be5f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E4C54B770>]}
[0m15:00:34.787069 [info ] [MainThread]: Found 1 model, 4 sources, 424 macros
[0m15:00:34.790115 [info ] [MainThread]: 
[0m15:00:34.791154 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:00:34.791705 [info ] [MainThread]: 
[0m15:00:34.792217 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:00:34.793868 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev'
[0m15:00:34.887976 [debug] [ThreadPool]: Using duckdb connection "list_dev"
[0m15:00:34.887976 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dev"'
    
  
  
[0m15:00:34.887976 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:00:34.900738 [debug] [ThreadPool]: SQL status: OK in 0.013 seconds
[0m15:00:34.902734 [debug] [ThreadPool]: On list_dev: Close
[0m15:00:34.905267 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now create_dev_main)
[0m15:00:34.906208 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "main"
"
[0m15:00:34.914437 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:00:34.914437 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dev'
        and type='sqlite'
    
  
[0m15:00:34.915440 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:00:34.924991 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m15:00:34.926582 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:00:34.927602 [debug] [ThreadPool]: On create_dev_main: BEGIN
[0m15:00:34.928209 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:00:34.928209 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:00:34.928752 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
    
        create schema if not exists "dev"."main"
    
[0m15:00:34.929296 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:00:34.930309 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m15:00:34.930966 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:00:34.930966 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m15:00:34.931507 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:00:34.931507 [debug] [ThreadPool]: On create_dev_main: Close
[0m15:00:34.935316 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev_main'
[0m15:00:34.940320 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m15:00:34.941625 [debug] [ThreadPool]: On list_dev_main: BEGIN
[0m15:00:34.941625 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:00:34.950864 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m15:00:34.951749 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m15:00:34.951749 [debug] [ThreadPool]: On list_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev_main"} */
select
      'dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'dev'
  
[0m15:00:34.999077 [debug] [ThreadPool]: SQL status: OK in 0.046 seconds
[0m15:00:35.000271 [debug] [ThreadPool]: On list_dev_main: ROLLBACK
[0m15:00:35.002090 [debug] [ThreadPool]: Failed to rollback 'list_dev_main'
[0m15:00:35.002090 [debug] [ThreadPool]: On list_dev_main: Close
[0m15:00:35.006137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '49bdb364-1453-4199-9bd3-99f9295be5f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E4BE56210>]}
[0m15:00:35.006137 [debug] [MainThread]: Using duckdb connection "master"
[0m15:00:35.007177 [debug] [MainThread]: On master: BEGIN
[0m15:00:35.007177 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:00:35.017751 [debug] [MainThread]: SQL status: OK in 0.010 seconds
[0m15:00:35.017751 [debug] [MainThread]: On master: COMMIT
[0m15:00:35.018291 [debug] [MainThread]: Using duckdb connection "master"
[0m15:00:35.018291 [debug] [MainThread]: On master: COMMIT
[0m15:00:35.019314 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:00:35.019314 [debug] [MainThread]: On master: Close
[0m15:00:35.023243 [debug] [Thread-1 (]: Began running node model.archi.test
[0m15:00:35.024237 [info ] [Thread-1 (]: 1 of 1 START sql view model main.test .......................................... [RUN]
[0m15:00:35.025249 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.test'
[0m15:00:35.025314 [debug] [Thread-1 (]: Began compiling node model.archi.test
[0m15:00:35.035000 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.test"
[0m15:00:35.035000 [debug] [Thread-1 (]: Began executing node model.archi.test
[0m15:00:35.075798 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.test"
[0m15:00:35.076796 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:00:35.076796 [debug] [Thread-1 (]: On model.archi.test: BEGIN
[0m15:00:35.077782 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:00:35.087494 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m15:00:35.087494 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:00:35.087494 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "dev"."main"."test__dbt_tmp" as (
    SELECT * FROM "dev"."raw"."raw_commits"
  );

[0m15:00:35.128844 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "dev"."main"."test__dbt_tmp" as (
    SELECT * FROM "dev"."raw"."raw_commits"
  );

[0m15:00:35.128844 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:00:35.129610 [debug] [Thread-1 (]: On model.archi.test: ROLLBACK
[0m15:00:35.135499 [debug] [Thread-1 (]: Failed to rollback 'model.archi.test'
[0m15:00:35.135499 [debug] [Thread-1 (]: On model.archi.test: Close
[0m15:00:35.142028 [debug] [Thread-1 (]: Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^
[0m15:00:35.143620 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49bdb364-1453-4199-9bd3-99f9295be5f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E4A1CB6E0>]}
[0m15:00:35.144613 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main.test ................................. [[31mERROR[0m in 0.12s]
[0m15:00:35.146021 [debug] [Thread-1 (]: Finished running node model.archi.test
[0m15:00:35.146021 [debug] [Thread-4 (]: Marking all children of 'model.archi.test' to be skipped because of status 'error'.  Reason: Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^.
[0m15:00:35.147910 [debug] [MainThread]: Using duckdb connection "master"
[0m15:00:35.147910 [debug] [MainThread]: On master: BEGIN
[0m15:00:35.148417 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:00:35.157585 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m15:00:35.157585 [debug] [MainThread]: On master: COMMIT
[0m15:00:35.158298 [debug] [MainThread]: Using duckdb connection "master"
[0m15:00:35.158806 [debug] [MainThread]: On master: COMMIT
[0m15:00:35.159314 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:00:35.159314 [debug] [MainThread]: On master: Close
[0m15:00:35.162905 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:00:35.162905 [debug] [MainThread]: Connection 'create_dev_main' was properly closed.
[0m15:00:35.162905 [debug] [MainThread]: Connection 'list_dev_main' was properly closed.
[0m15:00:35.163895 [debug] [MainThread]: Connection 'model.archi.test' was properly closed.
[0m15:00:35.163895 [info ] [MainThread]: 
[0m15:00:35.164888 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.37 seconds (0.37s).
[0m15:00:35.165885 [debug] [MainThread]: Command end result
[0m15:00:35.183505 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:00:35.186227 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:00:35.191788 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:00:35.192297 [info ] [MainThread]: 
[0m15:00:35.192297 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:00:35.193291 [info ] [MainThread]: 
[0m15:00:35.194587 [error] [MainThread]:   Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^
[0m15:00:35.195541 [info ] [MainThread]: 
[0m15:00:35.195541 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:00:35.197522 [debug] [MainThread]: Command `dbt build` failed at 15:00:35.197522 after 1.48 seconds
[0m15:00:35.197522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E4B532B40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E4AC1F8C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E4B1BA3C0>]}
[0m15:00:35.198530 [debug] [MainThread]: Flushing usage events
[0m15:00:36.257207 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:00:56.792808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209E752B170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209EBA1D580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209EBA1F920>]}


============================== 15:00:56.798030 | 311a5b03-e39a-4769-b64e-1e68748d7fbf ==============================
[0m15:00:56.798030 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:00:56.799052 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\Julien\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt build', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:00:57.046173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '311a5b03-e39a-4769-b64e-1e68748d7fbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209EAF85970>]}
[0m15:00:57.111272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '311a5b03-e39a-4769-b64e-1e68748d7fbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209E8ABA4B0>]}
[0m15:00:57.115480 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:00:57.409484 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:00:57.554728 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:00:57.555385 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:00:57.589498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '311a5b03-e39a-4769-b64e-1e68748d7fbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209EBBA1910>]}
[0m15:00:57.660021 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:00:57.661923 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:00:57.710622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '311a5b03-e39a-4769-b64e-1e68748d7fbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209ED043E30>]}
[0m15:00:57.711694 [info ] [MainThread]: Found 1 model, 4 sources, 424 macros
[0m15:00:57.715666 [info ] [MainThread]: 
[0m15:00:57.717171 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:00:57.718135 [info ] [MainThread]: 
[0m15:00:57.718135 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:00:57.720132 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev'
[0m15:00:57.840745 [debug] [ThreadPool]: Using duckdb connection "list_dev"
[0m15:00:57.841289 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dev"'
    
  
  
[0m15:00:57.841289 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:00:57.856614 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:00:57.858771 [debug] [ThreadPool]: On list_dev: Close
[0m15:00:57.862834 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now create_dev_main)
[0m15:00:57.862834 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "main"
"
[0m15:00:57.872284 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:00:57.873305 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dev'
        and type='sqlite'
    
  
[0m15:00:57.873305 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:00:57.892402 [debug] [ThreadPool]: SQL status: OK in 0.019 seconds
[0m15:00:57.893917 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:00:57.894426 [debug] [ThreadPool]: On create_dev_main: BEGIN
[0m15:00:57.894426 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:00:57.895420 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:00:57.895420 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
    
        create schema if not exists "dev"."main"
    
[0m15:00:57.896641 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:00:57.897634 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m15:00:57.897634 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:00:57.898632 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m15:00:57.899682 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:00:57.899682 [debug] [ThreadPool]: On create_dev_main: Close
[0m15:00:57.905754 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev_main'
[0m15:00:57.912550 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m15:00:57.912550 [debug] [ThreadPool]: On list_dev_main: BEGIN
[0m15:00:57.913547 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:00:57.923350 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m15:00:57.924346 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m15:00:57.924346 [debug] [ThreadPool]: On list_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev_main"} */
select
      'dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'dev'
  
[0m15:00:57.971216 [debug] [ThreadPool]: SQL status: OK in 0.046 seconds
[0m15:00:57.972214 [debug] [ThreadPool]: On list_dev_main: ROLLBACK
[0m15:00:57.973719 [debug] [ThreadPool]: Failed to rollback 'list_dev_main'
[0m15:00:57.973719 [debug] [ThreadPool]: On list_dev_main: Close
[0m15:00:57.977286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '311a5b03-e39a-4769-b64e-1e68748d7fbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209ECE8F410>]}
[0m15:00:57.978212 [debug] [MainThread]: Using duckdb connection "master"
[0m15:00:57.978212 [debug] [MainThread]: On master: BEGIN
[0m15:00:57.978212 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:00:57.988415 [debug] [MainThread]: SQL status: OK in 0.010 seconds
[0m15:00:57.988415 [debug] [MainThread]: On master: COMMIT
[0m15:00:57.989412 [debug] [MainThread]: Using duckdb connection "master"
[0m15:00:57.989412 [debug] [MainThread]: On master: COMMIT
[0m15:00:57.989412 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:00:57.989412 [debug] [MainThread]: On master: Close
[0m15:00:57.994743 [debug] [Thread-1 (]: Began running node model.archi.test
[0m15:00:57.995741 [info ] [Thread-1 (]: 1 of 1 START sql view model main.test .......................................... [RUN]
[0m15:00:57.995741 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.test'
[0m15:00:57.996816 [debug] [Thread-1 (]: Began compiling node model.archi.test
[0m15:00:58.006308 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.test"
[0m15:00:58.006308 [debug] [Thread-1 (]: Began executing node model.archi.test
[0m15:00:58.045252 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.test"
[0m15:00:58.046249 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:00:58.046821 [debug] [Thread-1 (]: On model.archi.test: BEGIN
[0m15:00:58.046821 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:00:58.057221 [debug] [Thread-1 (]: SQL status: OK in 0.010 seconds
[0m15:00:58.057221 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:00:58.058260 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "dev"."main"."test__dbt_tmp" as (
    SELECT * FROM "dev"."raw"."raw_commits"
  );

[0m15:00:58.097531 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "dev"."main"."test__dbt_tmp" as (
    SELECT * FROM "dev"."raw"."raw_commits"
  );

[0m15:00:58.097531 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:00:58.097531 [debug] [Thread-1 (]: On model.archi.test: ROLLBACK
[0m15:00:58.103888 [debug] [Thread-1 (]: Failed to rollback 'model.archi.test'
[0m15:00:58.104884 [debug] [Thread-1 (]: On model.archi.test: Close
[0m15:00:58.110412 [debug] [Thread-1 (]: Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "temp.information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^
[0m15:00:58.112439 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '311a5b03-e39a-4769-b64e-1e68748d7fbf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209EAECB140>]}
[0m15:00:58.113404 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main.test ................................. [[31mERROR[0m in 0.11s]
[0m15:00:58.114401 [debug] [Thread-1 (]: Finished running node model.archi.test
[0m15:00:58.114985 [debug] [Thread-4 (]: Marking all children of 'model.archi.test' to be skipped because of status 'error'.  Reason: Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "temp.information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^.
[0m15:00:58.115904 [debug] [MainThread]: Using duckdb connection "master"
[0m15:00:58.116902 [debug] [MainThread]: On master: BEGIN
[0m15:00:58.116902 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:00:58.126710 [debug] [MainThread]: SQL status: OK in 0.010 seconds
[0m15:00:58.127713 [debug] [MainThread]: On master: COMMIT
[0m15:00:58.127713 [debug] [MainThread]: Using duckdb connection "master"
[0m15:00:58.128222 [debug] [MainThread]: On master: COMMIT
[0m15:00:58.128222 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:00:58.129249 [debug] [MainThread]: On master: Close
[0m15:00:58.132306 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:00:58.133220 [debug] [MainThread]: Connection 'create_dev_main' was properly closed.
[0m15:00:58.133220 [debug] [MainThread]: Connection 'list_dev_main' was properly closed.
[0m15:00:58.133220 [debug] [MainThread]: Connection 'model.archi.test' was properly closed.
[0m15:00:58.134238 [info ] [MainThread]: 
[0m15:00:58.134238 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.42 seconds (0.42s).
[0m15:00:58.135823 [debug] [MainThread]: Command end result
[0m15:00:58.153505 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:00:58.156013 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:00:58.162530 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:00:58.163156 [info ] [MainThread]: 
[0m15:00:58.163664 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:00:58.164169 [info ] [MainThread]: 
[0m15:00:58.165166 [error] [MainThread]:   Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "temp.information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^
[0m15:00:58.165804 [info ] [MainThread]: 
[0m15:00:58.166314 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:00:58.167905 [debug] [MainThread]: Command `dbt build` failed at 15:00:58.167309 after 1.51 seconds
[0m15:00:58.167905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209EAE1E1E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209EAE1E120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209EAE1F800>]}
[0m15:00:58.168415 [debug] [MainThread]: Flushing usage events
[0m15:00:59.039973 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:02:22.244175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002925D8A1DC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002925D8A29F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029259B11610>]}


============================== 15:02:22.248872 | 59ed9614-ab69-448b-a375-bb121d2c5e5f ==============================
[0m15:02:22.248872 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:02:22.248872 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\Julien\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:02:22.485283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '59ed9614-ab69-448b-a375-bb121d2c5e5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002925D9288C0>]}
[0m15:02:22.552155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '59ed9614-ab69-448b-a375-bb121d2c5e5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002925ECAA8A0>]}
[0m15:02:22.556142 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:02:22.846306 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:02:22.992698 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:02:22.992698 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:02:23.028721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '59ed9614-ab69-448b-a375-bb121d2c5e5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002925F472FF0>]}
[0m15:02:23.099500 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:02:23.101908 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:02:23.142479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '59ed9614-ab69-448b-a375-bb121d2c5e5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002925FC47AD0>]}
[0m15:02:23.142479 [info ] [MainThread]: Found 1 model, 4 sources, 424 macros
[0m15:02:23.146478 [info ] [MainThread]: 
[0m15:02:23.146478 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:02:23.147494 [info ] [MainThread]: 
[0m15:02:23.148457 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:02:23.149454 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev'
[0m15:02:23.240095 [debug] [ThreadPool]: Using duckdb connection "list_dev"
[0m15:02:23.240627 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dev"'
    
  
  
[0m15:02:23.240627 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:02:23.255560 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m15:02:23.256553 [debug] [ThreadPool]: On list_dev: Close
[0m15:02:23.260648 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now create_dev_main)
[0m15:02:23.261643 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "main"
"
[0m15:02:23.269047 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:02:23.269047 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dev'
        and type='sqlite'
    
  
[0m15:02:23.270043 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:02:23.284464 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m15:02:23.286084 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:02:23.286084 [debug] [ThreadPool]: On create_dev_main: BEGIN
[0m15:02:23.287031 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:02:23.287031 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:02:23.287031 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
    
        create schema if not exists "dev"."main"
    
[0m15:02:23.288028 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:02:23.289025 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m15:02:23.289025 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:02:23.289025 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m15:02:23.290019 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:02:23.290089 [debug] [ThreadPool]: On create_dev_main: Close
[0m15:02:23.293845 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev_main'
[0m15:02:23.300393 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m15:02:23.300393 [debug] [ThreadPool]: On list_dev_main: BEGIN
[0m15:02:23.301120 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:02:23.310933 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m15:02:23.310933 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m15:02:23.310933 [debug] [ThreadPool]: On list_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev_main"} */
select
      'dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'dev'
  
[0m15:02:23.355202 [debug] [ThreadPool]: SQL status: OK in 0.044 seconds
[0m15:02:23.356745 [debug] [ThreadPool]: On list_dev_main: ROLLBACK
[0m15:02:23.358616 [debug] [ThreadPool]: Failed to rollback 'list_dev_main'
[0m15:02:23.359230 [debug] [ThreadPool]: On list_dev_main: Close
[0m15:02:23.363308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '59ed9614-ab69-448b-a375-bb121d2c5e5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002925FC477D0>]}
[0m15:02:23.363308 [debug] [MainThread]: Using duckdb connection "master"
[0m15:02:23.364296 [debug] [MainThread]: On master: BEGIN
[0m15:02:23.364296 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:02:23.374300 [debug] [MainThread]: SQL status: OK in 0.010 seconds
[0m15:02:23.374300 [debug] [MainThread]: On master: COMMIT
[0m15:02:23.375280 [debug] [MainThread]: Using duckdb connection "master"
[0m15:02:23.375861 [debug] [MainThread]: On master: COMMIT
[0m15:02:23.376405 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:02:23.376405 [debug] [MainThread]: On master: Close
[0m15:02:23.380952 [debug] [Thread-1 (]: Began running node model.archi.test
[0m15:02:23.380952 [info ] [Thread-1 (]: 1 of 1 START sql view model main.test .......................................... [RUN]
[0m15:02:23.381949 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.test'
[0m15:02:23.381949 [debug] [Thread-1 (]: Began compiling node model.archi.test
[0m15:02:23.390020 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.test"
[0m15:02:23.391017 [debug] [Thread-1 (]: Began executing node model.archi.test
[0m15:02:23.429877 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.test"
[0m15:02:23.430867 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:02:23.431837 [debug] [Thread-1 (]: On model.archi.test: BEGIN
[0m15:02:23.431837 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:02:23.441502 [debug] [Thread-1 (]: SQL status: OK in 0.010 seconds
[0m15:02:23.442344 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:02:23.442857 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "dev"."main"."test__dbt_tmp" as (
    SELECT * FROM "dev"."raw"."raw_commits"
  );

[0m15:02:23.482707 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "dev"."main"."test__dbt_tmp" as (
    SELECT * FROM "dev"."raw"."raw_commits"
  );

[0m15:02:23.483727 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:02:23.484276 [debug] [Thread-1 (]: On model.archi.test: ROLLBACK
[0m15:02:23.489427 [debug] [Thread-1 (]: Failed to rollback 'model.archi.test'
[0m15:02:23.489427 [debug] [Thread-1 (]: On model.archi.test: Close
[0m15:02:23.496039 [debug] [Thread-1 (]: Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^
[0m15:02:23.497973 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59ed9614-ab69-448b-a375-bb121d2c5e5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002925F892180>]}
[0m15:02:23.498970 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main.test ................................. [[31mERROR[0m in 0.12s]
[0m15:02:23.499893 [debug] [Thread-1 (]: Finished running node model.archi.test
[0m15:02:23.499893 [debug] [Thread-4 (]: Marking all children of 'model.archi.test' to be skipped because of status 'error'.  Reason: Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^.
[0m15:02:23.501801 [debug] [MainThread]: Using duckdb connection "master"
[0m15:02:23.502834 [debug] [MainThread]: On master: BEGIN
[0m15:02:23.502834 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:02:23.513771 [debug] [MainThread]: SQL status: OK in 0.011 seconds
[0m15:02:23.513771 [debug] [MainThread]: On master: COMMIT
[0m15:02:23.514747 [debug] [MainThread]: Using duckdb connection "master"
[0m15:02:23.514747 [debug] [MainThread]: On master: COMMIT
[0m15:02:23.514747 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:02:23.515709 [debug] [MainThread]: On master: Close
[0m15:02:23.518700 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:02:23.518700 [debug] [MainThread]: Connection 'create_dev_main' was properly closed.
[0m15:02:23.518700 [debug] [MainThread]: Connection 'list_dev_main' was properly closed.
[0m15:02:23.518700 [debug] [MainThread]: Connection 'model.archi.test' was properly closed.
[0m15:02:23.519703 [info ] [MainThread]: 
[0m15:02:23.519703 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.37 seconds (0.37s).
[0m15:02:23.520697 [debug] [MainThread]: Command end result
[0m15:02:23.539453 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:02:23.541589 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:02:23.549487 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:02:23.550094 [info ] [MainThread]: 
[0m15:02:23.550727 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:02:23.550727 [info ] [MainThread]: 
[0m15:02:23.551629 [error] [MainThread]:   Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^
[0m15:02:23.552349 [info ] [MainThread]: 
[0m15:02:23.552349 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:02:23.553264 [debug] [MainThread]: Command `dbt build` failed at 15:02:23.553264 after 1.47 seconds
[0m15:02:23.554261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002925E7D02C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002925AC1FB00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002925EBEACF0>]}
[0m15:02:23.554907 [debug] [MainThread]: Flushing usage events
[0m15:02:24.576609 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:08:32.828052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DC420DD490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DC45CD9670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DC45B77AD0>]}


============================== 15:08:32.832038 | d3a4dc69-14cc-40c5-967a-0216a1533e39 ==============================
[0m15:08:32.832038 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:08:32.833096 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:08:33.057886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd3a4dc69-14cc-40c5-967a-0216a1533e39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DC4260A2D0>]}
[0m15:08:33.120954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd3a4dc69-14cc-40c5-967a-0216a1533e39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DC44EA0470>]}
[0m15:08:33.124732 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:08:33.395967 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:08:33.538188 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:08:33.539113 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:08:33.571884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd3a4dc69-14cc-40c5-967a-0216a1533e39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DC46A762A0>]}
[0m15:08:33.640406 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:08:33.642510 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:08:33.682137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd3a4dc69-14cc-40c5-967a-0216a1533e39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DC4724B800>]}
[0m15:08:33.683107 [info ] [MainThread]: Found 1 model, 4 sources, 424 macros
[0m15:08:33.685585 [info ] [MainThread]: 
[0m15:08:33.686522 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:08:33.686522 [info ] [MainThread]: 
[0m15:08:33.687515 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:08:33.688799 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev'
[0m15:08:33.777245 [debug] [ThreadPool]: Using duckdb connection "list_dev"
[0m15:08:33.778243 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dev"'
    
  
  
[0m15:08:33.778243 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:08:33.791403 [debug] [ThreadPool]: SQL status: OK in 0.013 seconds
[0m15:08:33.792400 [debug] [ThreadPool]: On list_dev: Close
[0m15:08:33.795848 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now create_dev_main)
[0m15:08:33.795848 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "main"
"
[0m15:08:33.803054 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:08:33.803054 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dev'
        and type='sqlite'
    
  
[0m15:08:33.804053 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:08:33.819636 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:08:33.820669 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:08:33.821605 [debug] [ThreadPool]: On create_dev_main: BEGIN
[0m15:08:33.821605 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:08:33.821605 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:08:33.822685 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
    
        create schema if not exists "dev"."main"
    
[0m15:08:33.822685 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:08:33.823601 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m15:08:33.824108 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m15:08:33.824108 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m15:08:33.825104 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:08:33.825104 [debug] [ThreadPool]: On create_dev_main: Close
[0m15:08:33.829480 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev_main'
[0m15:08:33.834411 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m15:08:33.834411 [debug] [ThreadPool]: On list_dev_main: BEGIN
[0m15:08:33.835471 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:08:33.842657 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:08:33.843575 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m15:08:33.843575 [debug] [ThreadPool]: On list_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev_main"} */
select
      'dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'dev'
  
[0m15:08:33.888843 [debug] [ThreadPool]: SQL status: OK in 0.044 seconds
[0m15:08:33.889752 [debug] [ThreadPool]: On list_dev_main: ROLLBACK
[0m15:08:33.890750 [debug] [ThreadPool]: Failed to rollback 'list_dev_main'
[0m15:08:33.891748 [debug] [ThreadPool]: On list_dev_main: Close
[0m15:08:33.895604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd3a4dc69-14cc-40c5-967a-0216a1533e39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DC463B9070>]}
[0m15:08:33.896796 [debug] [MainThread]: Using duckdb connection "master"
[0m15:08:33.896796 [debug] [MainThread]: On master: BEGIN
[0m15:08:33.896796 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:08:33.906373 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m15:08:33.906373 [debug] [MainThread]: On master: COMMIT
[0m15:08:33.906882 [debug] [MainThread]: Using duckdb connection "master"
[0m15:08:33.907388 [debug] [MainThread]: On master: COMMIT
[0m15:08:33.907388 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:08:33.907895 [debug] [MainThread]: On master: Close
[0m15:08:33.912388 [debug] [Thread-1 (]: Began running node model.archi.test
[0m15:08:33.912933 [info ] [Thread-1 (]: 1 of 1 START sql view model main.test .......................................... [RUN]
[0m15:08:33.913499 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.test'
[0m15:08:33.914437 [debug] [Thread-1 (]: Began compiling node model.archi.test
[0m15:08:33.921571 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.test"
[0m15:08:33.922569 [debug] [Thread-1 (]: Began executing node model.archi.test
[0m15:08:33.960675 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.test"
[0m15:08:33.961636 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:08:33.962215 [debug] [Thread-1 (]: On model.archi.test: BEGIN
[0m15:08:33.962819 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:08:33.971258 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m15:08:33.972307 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:08:33.972307 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "dev"."main"."test__dbt_tmp" as (
    SELECT * FROM "dev"."raw"."raw_commits"
  );

[0m15:08:34.010134 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "dev"."main"."test__dbt_tmp" as (
    SELECT * FROM "dev"."raw"."raw_commits"
  );

[0m15:08:34.011098 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:08:34.012221 [debug] [Thread-1 (]: On model.archi.test: ROLLBACK
[0m15:08:34.017336 [debug] [Thread-1 (]: Failed to rollback 'model.archi.test'
[0m15:08:34.018340 [debug] [Thread-1 (]: On model.archi.test: Close
[0m15:08:34.024014 [debug] [Thread-1 (]: Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^
[0m15:08:34.025581 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3a4dc69-14cc-40c5-967a-0216a1533e39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DC44ED30E0>]}
[0m15:08:34.025581 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main.test ................................. [[31mERROR[0m in 0.11s]
[0m15:08:34.026557 [debug] [Thread-1 (]: Finished running node model.archi.test
[0m15:08:34.027550 [debug] [Thread-4 (]: Marking all children of 'model.archi.test' to be skipped because of status 'error'.  Reason: Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^.
[0m15:08:34.029186 [debug] [MainThread]: Using duckdb connection "master"
[0m15:08:34.029186 [debug] [MainThread]: On master: BEGIN
[0m15:08:34.029186 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:08:34.038519 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m15:08:34.039104 [debug] [MainThread]: On master: COMMIT
[0m15:08:34.039104 [debug] [MainThread]: Using duckdb connection "master"
[0m15:08:34.039104 [debug] [MainThread]: On master: COMMIT
[0m15:08:34.040023 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:08:34.040023 [debug] [MainThread]: On master: Close
[0m15:08:34.042667 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:08:34.043640 [debug] [MainThread]: Connection 'create_dev_main' was properly closed.
[0m15:08:34.043640 [debug] [MainThread]: Connection 'list_dev_main' was properly closed.
[0m15:08:34.043640 [debug] [MainThread]: Connection 'model.archi.test' was properly closed.
[0m15:08:34.044638 [info ] [MainThread]: 
[0m15:08:34.044638 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.36 seconds (0.36s).
[0m15:08:34.046633 [debug] [MainThread]: Command end result
[0m15:08:34.063173 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:08:34.066338 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:08:34.071870 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:08:34.072378 [info ] [MainThread]: 
[0m15:08:34.072378 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:08:34.073405 [info ] [MainThread]: 
[0m15:08:34.073405 [error] [MainThread]:   Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "information_schema.columns"?
  LINE 5:     SELECT * FROM "dev"."raw"."raw_commits"
                            ^
[0m15:08:34.074658 [info ] [MainThread]: 
[0m15:08:34.075664 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:08:34.076387 [debug] [MainThread]: Command `dbt build` failed at 15:08:34.076387 after 1.41 seconds
[0m15:08:34.077390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DC44EF4B00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DC44EF42C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DC46E4FC50>]}
[0m15:08:34.077390 [debug] [MainThread]: Flushing usage events
[0m15:08:36.829036 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:10:10.365926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF2CF7BE60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF2CF17380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF2D309D30>]}


============================== 15:10:10.370507 | 6a3c590b-d201-43cd-88b9-68b03675b126 ==============================
[0m15:10:10.370507 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:10:10.370507 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt build', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:10:10.607243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6a3c590b-d201-43cd-88b9-68b03675b126', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF2D9785C0>]}
[0m15:10:10.673557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6a3c590b-d201-43cd-88b9-68b03675b126', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF2CE40470>]}
[0m15:10:10.676951 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:10:10.964919 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:10:11.044660 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m15:10:11.045198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6a3c590b-d201-43cd-88b9-68b03675b126', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF2CF7A270>]}
[0m15:10:12.218345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6a3c590b-d201-43cd-88b9-68b03675b126', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF2E61B590>]}
[0m15:10:12.284504 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:10:12.287734 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:10:12.326265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6a3c590b-d201-43cd-88b9-68b03675b126', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF2EB90680>]}
[0m15:10:12.327247 [info ] [MainThread]: Found 1 model, 4 sources, 424 macros
[0m15:10:12.329923 [info ] [MainThread]: 
[0m15:10:12.331319 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:10:12.331319 [info ] [MainThread]: 
[0m15:10:12.332301 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:10:12.333299 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:10:12.459262 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:10:12.460210 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:10:12.460752 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:10:12.478748 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:10:12.479752 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:10:12.483360 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m15:10:12.484614 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m15:10:12.491428 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:10:12.491428 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:10:12.491428 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:10:12.508876 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m15:10:12.510445 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:10:12.510445 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m15:10:12.511454 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:10:12.511454 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:10:12.511998 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m15:10:12.511998 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:10:12.513626 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:10:12.513633 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:10:12.514175 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:10:12.515168 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:10:12.515168 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m15:10:12.519902 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m15:10:12.525564 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:10:12.525564 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m15:10:12.525564 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:10:12.542009 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:10:12.542009 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:10:12.542009 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:10:12.589070 [debug] [ThreadPool]: SQL status: OK in 0.046 seconds
[0m15:10:12.590648 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m15:10:12.591654 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m15:10:12.591654 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m15:10:12.596680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6a3c590b-d201-43cd-88b9-68b03675b126', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF2E382540>]}
[0m15:10:12.597810 [debug] [MainThread]: Using duckdb connection "master"
[0m15:10:12.597810 [debug] [MainThread]: On master: BEGIN
[0m15:10:12.598317 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:10:12.615817 [debug] [MainThread]: SQL status: OK in 0.018 seconds
[0m15:10:12.616810 [debug] [MainThread]: On master: COMMIT
[0m15:10:12.616810 [debug] [MainThread]: Using duckdb connection "master"
[0m15:10:12.616810 [debug] [MainThread]: On master: COMMIT
[0m15:10:12.617807 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:10:12.617807 [debug] [MainThread]: On master: Close
[0m15:10:12.623070 [debug] [Thread-1 (]: Began running node model.archi.test
[0m15:10:12.623070 [info ] [Thread-1 (]: 1 of 1 START sql view model main.test .......................................... [RUN]
[0m15:10:12.624068 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.test'
[0m15:10:12.625065 [debug] [Thread-1 (]: Began compiling node model.archi.test
[0m15:10:12.632606 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.test"
[0m15:10:12.633605 [debug] [Thread-1 (]: Began executing node model.archi.test
[0m15:10:12.673302 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.test"
[0m15:10:12.674300 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:10:12.674300 [debug] [Thread-1 (]: On model.archi.test: BEGIN
[0m15:10:12.674300 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:10:12.692208 [debug] [Thread-1 (]: SQL status: OK in 0.017 seconds
[0m15:10:12.692208 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:10:12.693179 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "pytorch_data"."main"."test__dbt_tmp" as (
    SELECT * FROM "pytorch_data"."raw"."raw_commits"
  );

[0m15:10:12.731056 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "pytorch_data"."main"."test__dbt_tmp" as (
    SELECT * FROM "pytorch_data"."raw"."raw_commits"
  );

[0m15:10:12.731131 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:10:12.731131 [debug] [Thread-1 (]: On model.archi.test: ROLLBACK
[0m15:10:12.737543 [debug] [Thread-1 (]: Failed to rollback 'model.archi.test'
[0m15:10:12.737543 [debug] [Thread-1 (]: On model.archi.test: Close
[0m15:10:12.745587 [debug] [Thread-1 (]: Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pytorch_data.raw_commits"?
  LINE 5:     SELECT * FROM "pytorch_data"."raw"."raw_commits"
                            ^
[0m15:10:12.747310 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6a3c590b-d201-43cd-88b9-68b03675b126', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF2CFA3E30>]}
[0m15:10:12.747855 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main.test ................................. [[31mERROR[0m in 0.12s]
[0m15:10:12.749427 [debug] [Thread-1 (]: Finished running node model.archi.test
[0m15:10:12.750411 [debug] [Thread-4 (]: Marking all children of 'model.archi.test' to be skipped because of status 'error'.  Reason: Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pytorch_data.raw_commits"?
  LINE 5:     SELECT * FROM "pytorch_data"."raw"."raw_commits"
                            ^.
[0m15:10:12.751408 [debug] [MainThread]: Using duckdb connection "master"
[0m15:10:12.752970 [debug] [MainThread]: On master: BEGIN
[0m15:10:12.752970 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:10:12.771591 [debug] [MainThread]: SQL status: OK in 0.019 seconds
[0m15:10:12.772581 [debug] [MainThread]: On master: COMMIT
[0m15:10:12.772581 [debug] [MainThread]: Using duckdb connection "master"
[0m15:10:12.773617 [debug] [MainThread]: On master: COMMIT
[0m15:10:12.773617 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:10:12.774648 [debug] [MainThread]: On master: Close
[0m15:10:12.777829 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:10:12.777829 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m15:10:12.778442 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m15:10:12.778968 [debug] [MainThread]: Connection 'model.archi.test' was properly closed.
[0m15:10:12.778968 [info ] [MainThread]: 
[0m15:10:12.779964 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.45 seconds (0.45s).
[0m15:10:12.780960 [debug] [MainThread]: Command end result
[0m15:10:12.801845 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:10:12.804371 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:10:12.809480 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:10:12.809480 [info ] [MainThread]: 
[0m15:10:12.810472 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:10:12.811468 [info ] [MainThread]: 
[0m15:10:12.811468 [error] [MainThread]:   Runtime Error in model test (models\duckdb\test.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pytorch_data.raw_commits"?
  LINE 5:     SELECT * FROM "pytorch_data"."raw"."raw_commits"
                            ^
[0m15:10:12.812467 [info ] [MainThread]: 
[0m15:10:12.813284 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:10:12.814787 [debug] [MainThread]: Command `dbt build` failed at 15:10:12.814787 after 2.62 seconds
[0m15:10:12.814787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF2C707800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF2D432390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF2D432B40>]}
[0m15:10:12.815785 [debug] [MainThread]: Flushing usage events
[0m15:10:13.944546 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:11:24.299126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F4D8A0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F49F1FC50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F4C9C8E30>]}


============================== 15:11:24.303625 | ac449c91-9e48-46b1-b366-9ec1dcf6ed35 ==============================
[0m15:11:24.303625 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:11:24.304978 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:11:24.543410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ac449c91-9e48-46b1-b366-9ec1dcf6ed35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F4E67BCE0>]}
[0m15:11:24.608424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ac449c91-9e48-46b1-b366-9ec1dcf6ed35', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F4E655790>]}
[0m15:11:24.612471 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:11:24.904621 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:11:25.062345 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m15:11:25.062986 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\sources.yaml
[0m15:11:25.063531 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\test.sql
[0m15:11:25.283339 [error] [MainThread]: Encountered an error:
Compilation Error in model test (models\duckdb\test.sql)
  source() takes exactly two arguments (1 given)
[0m15:11:25.284336 [debug] [MainThread]: Command `dbt build` failed at 15:11:25.284336 after 1.12 seconds
[0m15:11:25.285334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F4DC846B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F4E679730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F4E656150>]}
[0m15:11:25.285334 [debug] [MainThread]: Flushing usage events
[0m15:11:26.307243 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:13:01.560722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022584048140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022580A1D8B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022580A1C740>]}


============================== 15:13:01.565133 | 1fb9e221-1ce8-43e9-a9ce-dbcac9ddebc5 ==============================
[0m15:13:01.565133 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:13:01.565133 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:13:01.795266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1fb9e221-1ce8-43e9-a9ce-dbcac9ddebc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022583681A00>]}
[0m15:13:01.860738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1fb9e221-1ce8-43e9-a9ce-dbcac9ddebc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022583681A00>]}
[0m15:13:01.863829 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:13:02.155272 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:13:02.296469 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m15:13:02.298048 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\sources.yaml
[0m15:13:02.298048 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\test.sql
[0m15:13:02.647138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1fb9e221-1ce8-43e9-a9ce-dbcac9ddebc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022585486180>]}
[0m15:13:02.698821 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:13:02.701324 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:13:02.739805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1fb9e221-1ce8-43e9-a9ce-dbcac9ddebc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022585B6B560>]}
[0m15:13:02.740828 [info ] [MainThread]: Found 1 model, 424 macros
[0m15:13:02.742847 [info ] [MainThread]: 
[0m15:13:02.743844 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:13:02.744815 [info ] [MainThread]: 
[0m15:13:02.744815 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:13:02.745838 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:13:02.836576 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:13:02.836576 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:13:02.837821 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:13:02.857449 [debug] [ThreadPool]: SQL status: OK in 0.019 seconds
[0m15:13:02.858976 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:13:02.862498 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m15:13:02.863788 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m15:13:02.870117 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:13:02.870117 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:13:02.871111 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:13:02.887361 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m15:13:02.888358 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:13:02.889356 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m15:13:02.890392 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:13:02.890392 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:13:02.891350 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m15:13:02.891350 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:13:02.892348 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:13:02.893345 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:13:02.893345 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:13:02.893345 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:13:02.894343 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m15:13:02.898044 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m15:13:02.904776 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:13:02.905769 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m15:13:02.905769 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:13:02.922134 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:13:02.922134 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:13:02.923132 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:13:02.970184 [debug] [ThreadPool]: SQL status: OK in 0.047 seconds
[0m15:13:02.972120 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m15:13:02.973627 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m15:13:02.973680 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m15:13:02.978865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1fb9e221-1ce8-43e9-a9ce-dbcac9ddebc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022585F4C0E0>]}
[0m15:13:02.980061 [debug] [MainThread]: Using duckdb connection "master"
[0m15:13:02.980061 [debug] [MainThread]: On master: BEGIN
[0m15:13:02.980601 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:13:02.996580 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:13:02.997577 [debug] [MainThread]: On master: COMMIT
[0m15:13:02.997577 [debug] [MainThread]: Using duckdb connection "master"
[0m15:13:02.997577 [debug] [MainThread]: On master: COMMIT
[0m15:13:02.998574 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:13:02.998574 [debug] [MainThread]: On master: Close
[0m15:13:03.003599 [debug] [Thread-1 (]: Began running node model.archi.test
[0m15:13:03.004105 [info ] [Thread-1 (]: 1 of 1 START sql view model main.test .......................................... [RUN]
[0m15:13:03.005101 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.test'
[0m15:13:03.005101 [debug] [Thread-1 (]: Began compiling node model.archi.test
[0m15:13:03.012924 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.test"
[0m15:13:03.013433 [debug] [Thread-1 (]: Began executing node model.archi.test
[0m15:13:03.050064 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.test"
[0m15:13:03.051062 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:13:03.051062 [debug] [Thread-1 (]: On model.archi.test: BEGIN
[0m15:13:03.052060 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:13:03.068425 [debug] [Thread-1 (]: SQL status: OK in 0.017 seconds
[0m15:13:03.069423 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:13:03.069423 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "pytorch_data"."main"."test__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m15:13:03.070926 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:13:03.077420 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:13:03.078067 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */
alter view "pytorch_data"."main"."test__dbt_tmp" rename to "test"
[0m15:13:03.078624 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:13:03.088154 [debug] [Thread-1 (]: On model.archi.test: COMMIT
[0m15:13:03.088805 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:13:03.088805 [debug] [Thread-1 (]: On model.archi.test: COMMIT
[0m15:13:03.091361 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:13:03.096344 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:13:03.097373 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */
drop view if exists "pytorch_data"."main"."test__dbt_backup" cascade
[0m15:13:03.097373 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:13:03.099367 [debug] [Thread-1 (]: On model.archi.test: Close
[0m15:13:03.142112 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fb9e221-1ce8-43e9-a9ce-dbcac9ddebc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022585FF0200>]}
[0m15:13:03.142112 [info ] [Thread-1 (]: 1 of 1 OK created sql view model main.test ..................................... [[32mOK[0m in 0.14s]
[0m15:13:03.143246 [debug] [Thread-1 (]: Finished running node model.archi.test
[0m15:13:03.145170 [debug] [MainThread]: Using duckdb connection "master"
[0m15:13:03.145170 [debug] [MainThread]: On master: BEGIN
[0m15:13:03.145170 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:13:03.167641 [debug] [MainThread]: SQL status: OK in 0.022 seconds
[0m15:13:03.168988 [debug] [MainThread]: On master: COMMIT
[0m15:13:03.168988 [debug] [MainThread]: Using duckdb connection "master"
[0m15:13:03.168988 [debug] [MainThread]: On master: COMMIT
[0m15:13:03.169942 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:13:03.169942 [debug] [MainThread]: On master: Close
[0m15:13:03.173460 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:13:03.174474 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m15:13:03.174474 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m15:13:03.174474 [debug] [MainThread]: Connection 'model.archi.test' was properly closed.
[0m15:13:03.175454 [info ] [MainThread]: 
[0m15:13:03.175454 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.43 seconds (0.43s).
[0m15:13:03.176452 [debug] [MainThread]: Command end result
[0m15:13:03.194701 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:13:03.197043 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:13:03.203648 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:13:03.204642 [info ] [MainThread]: 
[0m15:13:03.205223 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:13:03.206237 [info ] [MainThread]: 
[0m15:13:03.206752 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:13:03.208317 [debug] [MainThread]: Command `dbt build` succeeded at 15:13:03.207784 after 1.80 seconds
[0m15:13:03.208317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022584048140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225847003E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225847008C0>]}
[0m15:13:03.209290 [debug] [MainThread]: Flushing usage events
[0m15:13:04.398366 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:13:19.501731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232447871A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002324437B7A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232443786E0>]}


============================== 15:13:19.505736 | ba7ae8da-79aa-4dfb-8c1d-6982c5d31bbc ==============================
[0m15:13:19.505736 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:13:19.506722 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:13:19.731681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ba7ae8da-79aa-4dfb-8c1d-6982c5d31bbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002324372A510>]}
[0m15:13:19.797791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ba7ae8da-79aa-4dfb-8c1d-6982c5d31bbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023243FBC530>]}
[0m15:13:19.801550 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:13:20.090489 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:13:20.228375 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:13:20.229300 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:13:20.254931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ba7ae8da-79aa-4dfb-8c1d-6982c5d31bbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002324524AAB0>]}
[0m15:13:20.308801 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:13:20.312304 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:13:20.334584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ba7ae8da-79aa-4dfb-8c1d-6982c5d31bbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002324572DE50>]}
[0m15:13:20.335550 [info ] [MainThread]: Found 1 model, 424 macros
[0m15:13:20.335550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ba7ae8da-79aa-4dfb-8c1d-6982c5d31bbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023244DBC470>]}
[0m15:13:20.337578 [info ] [MainThread]: 
[0m15:13:20.337578 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:13:20.338395 [info ] [MainThread]: 
[0m15:13:20.338954 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:13:20.339574 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:13:20.434751 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:13:20.434751 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:13:20.435742 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:13:20.455173 [debug] [ThreadPool]: SQL status: OK in 0.019 seconds
[0m15:13:20.456256 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:13:20.459872 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m15:13:20.460806 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m15:13:20.467337 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:13:20.467848 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:13:20.468360 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:13:20.484714 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m15:13:20.486710 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:13:20.487351 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m15:13:20.487854 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:13:20.487963 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:13:20.487963 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m15:13:20.488853 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:13:20.488853 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:13:20.489882 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:13:20.489882 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:13:20.489882 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:13:20.490849 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m15:13:20.494838 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m15:13:20.500396 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:13:20.500396 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m15:13:20.501394 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:13:20.517828 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:13:20.518383 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:13:20.518383 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:13:20.564861 [debug] [ThreadPool]: SQL status: OK in 0.046 seconds
[0m15:13:20.565856 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m15:13:20.567872 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m15:13:20.567872 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m15:13:20.573416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ba7ae8da-79aa-4dfb-8c1d-6982c5d31bbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002324574C890>]}
[0m15:13:20.573416 [debug] [MainThread]: Using duckdb connection "master"
[0m15:13:20.573922 [debug] [MainThread]: On master: BEGIN
[0m15:13:20.574427 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:13:20.590690 [debug] [MainThread]: SQL status: OK in 0.017 seconds
[0m15:13:20.591630 [debug] [MainThread]: On master: COMMIT
[0m15:13:20.592198 [debug] [MainThread]: Using duckdb connection "master"
[0m15:13:20.592198 [debug] [MainThread]: On master: COMMIT
[0m15:13:20.593133 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:13:20.593133 [debug] [MainThread]: On master: Close
[0m15:13:20.598183 [debug] [Thread-1 (]: Began running node model.archi.test
[0m15:13:20.598183 [info ] [Thread-1 (]: 1 of 1 START sql view model main.test .......................................... [RUN]
[0m15:13:20.599117 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.test'
[0m15:13:20.599117 [debug] [Thread-1 (]: Began compiling node model.archi.test
[0m15:13:20.605101 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.test"
[0m15:13:20.606098 [debug] [Thread-1 (]: Began executing node model.archi.test
[0m15:13:20.643253 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.test"
[0m15:13:20.644276 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:13:20.645247 [debug] [Thread-1 (]: On model.archi.test: BEGIN
[0m15:13:20.645247 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:13:20.662026 [debug] [Thread-1 (]: SQL status: OK in 0.017 seconds
[0m15:13:20.663482 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:13:20.663482 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "pytorch_data"."main"."test__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m15:13:20.664468 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:13:20.670670 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:13:20.670670 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */
alter view "pytorch_data"."main"."test" rename to "test__dbt_backup"
[0m15:13:20.671668 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:13:20.673866 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:13:20.673866 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */
alter view "pytorch_data"."main"."test__dbt_tmp" rename to "test"
[0m15:13:20.674802 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:13:20.687902 [debug] [Thread-1 (]: On model.archi.test: COMMIT
[0m15:13:20.687902 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:13:20.688907 [debug] [Thread-1 (]: On model.archi.test: COMMIT
[0m15:13:20.691893 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:13:20.697523 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:13:20.697523 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */
drop view if exists "pytorch_data"."main"."test__dbt_backup" cascade
[0m15:13:20.698699 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:13:20.701627 [debug] [Thread-1 (]: On model.archi.test: Close
[0m15:13:20.739641 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba7ae8da-79aa-4dfb-8c1d-6982c5d31bbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232436CAF30>]}
[0m15:13:20.740716 [info ] [Thread-1 (]: 1 of 1 OK created sql view model main.test ..................................... [[32mOK[0m in 0.14s]
[0m15:13:20.741637 [debug] [Thread-1 (]: Finished running node model.archi.test
[0m15:13:20.743140 [debug] [MainThread]: Using duckdb connection "master"
[0m15:13:20.743140 [debug] [MainThread]: On master: BEGIN
[0m15:13:20.744202 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:13:20.767042 [debug] [MainThread]: SQL status: OK in 0.023 seconds
[0m15:13:20.767042 [debug] [MainThread]: On master: COMMIT
[0m15:13:20.767677 [debug] [MainThread]: Using duckdb connection "master"
[0m15:13:20.767677 [debug] [MainThread]: On master: COMMIT
[0m15:13:20.768291 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:13:20.768291 [debug] [MainThread]: On master: Close
[0m15:13:20.771233 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:13:20.772204 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m15:13:20.772204 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m15:13:20.772204 [debug] [MainThread]: Connection 'model.archi.test' was properly closed.
[0m15:13:20.772204 [info ] [MainThread]: 
[0m15:13:20.773233 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.43 seconds (0.43s).
[0m15:13:20.774230 [debug] [MainThread]: Command end result
[0m15:13:20.791539 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:13:20.793992 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:13:20.800664 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:13:20.800664 [info ] [MainThread]: 
[0m15:13:20.801208 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:13:20.801740 [info ] [MainThread]: 
[0m15:13:20.801740 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:13:20.803838 [debug] [MainThread]: Command `dbt run` succeeded at 15:13:20.803331 after 1.42 seconds
[0m15:13:20.803838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023244831EE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232436A3830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232436A0530>]}
[0m15:13:20.803838 [debug] [MainThread]: Flushing usage events
[0m15:13:21.801861 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:13:53.597800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C70C71D850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C70FFA08C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C70FF7F1D0>]}


============================== 15:13:53.601492 | 75bc9709-66fb-4582-b97b-047cd3261045 ==============================
[0m15:13:53.601492 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:13:53.602489 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:13:53.842500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '75bc9709-66fb-4582-b97b-047cd3261045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C70F32A600>]}
[0m15:13:53.907902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '75bc9709-66fb-4582-b97b-047cd3261045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C710661370>]}
[0m15:13:53.912415 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:13:54.198698 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:13:54.332782 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:13:54.332782 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\test.sql
[0m15:13:54.597655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '75bc9709-66fb-4582-b97b-047cd3261045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C71162F860>]}
[0m15:13:54.650597 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:13:54.653919 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:13:54.694460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '75bc9709-66fb-4582-b97b-047cd3261045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C7118BC6B0>]}
[0m15:13:54.694460 [info ] [MainThread]: Found 1 model, 424 macros
[0m15:13:54.697487 [info ] [MainThread]: 
[0m15:13:54.698335 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:13:54.698335 [info ] [MainThread]: 
[0m15:13:54.699241 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:13:54.700381 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:13:54.794328 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:13:54.794328 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:13:54.795303 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:13:54.815704 [debug] [ThreadPool]: SQL status: OK in 0.020 seconds
[0m15:13:54.816672 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:13:54.821188 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m15:13:54.821188 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m15:13:54.827732 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:13:54.828731 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:13:54.828731 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:13:54.848073 [debug] [ThreadPool]: SQL status: OK in 0.019 seconds
[0m15:13:54.849050 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:13:54.849050 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m15:13:54.850089 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:13:54.850089 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:13:54.851066 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m15:13:54.851066 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:13:54.852034 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:13:54.853063 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:13:54.853063 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:13:54.853063 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:13:54.854065 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m15:13:54.858338 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m15:13:54.864336 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:13:54.865333 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m15:13:54.865333 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:13:54.885294 [debug] [ThreadPool]: SQL status: OK in 0.019 seconds
[0m15:13:54.885294 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:13:54.885294 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:13:55.008563 [debug] [ThreadPool]: SQL status: OK in 0.122 seconds
[0m15:13:55.010643 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m15:13:55.013621 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m15:13:55.014595 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m15:13:55.023465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '75bc9709-66fb-4582-b97b-047cd3261045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C711CCCE00>]}
[0m15:13:55.023465 [debug] [MainThread]: Using duckdb connection "master"
[0m15:13:55.024443 [debug] [MainThread]: On master: BEGIN
[0m15:13:55.024443 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:13:55.047903 [debug] [MainThread]: SQL status: OK in 0.023 seconds
[0m15:13:55.048929 [debug] [MainThread]: On master: COMMIT
[0m15:13:55.049432 [debug] [MainThread]: Using duckdb connection "master"
[0m15:13:55.049439 [debug] [MainThread]: On master: COMMIT
[0m15:13:55.049951 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:13:55.050943 [debug] [MainThread]: On master: Close
[0m15:13:55.055708 [debug] [Thread-1 (]: Began running node model.archi.test
[0m15:13:55.055708 [info ] [Thread-1 (]: 1 of 1 START sql view model main.test .......................................... [RUN]
[0m15:13:55.057267 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.test'
[0m15:13:55.057267 [debug] [Thread-1 (]: Began compiling node model.archi.test
[0m15:13:55.066550 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.test"
[0m15:13:55.067572 [debug] [Thread-1 (]: Began executing node model.archi.test
[0m15:13:55.109631 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.test"
[0m15:13:55.110641 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:13:55.111155 [debug] [Thread-1 (]: On model.archi.test: BEGIN
[0m15:13:55.111155 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:13:55.133119 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m15:13:55.133119 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:13:55.134146 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "pytorch_data"."main"."test__dbt_tmp" as (
    SELECT * FROM <dbt.context.providers.RuntimeSourceResolver object at 0x000002C711E8D4C0>
  );

[0m15:13:55.134903 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "pytorch_data"."main"."test__dbt_tmp" as (
    SELECT * FROM <dbt.context.providers.RuntimeSourceResolver object at 0x000002C711E8D4C0>
  );

[0m15:13:55.135451 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:13:55.135997 [debug] [Thread-1 (]: On model.archi.test: ROLLBACK
[0m15:13:55.141570 [debug] [Thread-1 (]: Failed to rollback 'model.archi.test'
[0m15:13:55.142583 [debug] [Thread-1 (]: On model.archi.test: Close
[0m15:13:55.149713 [debug] [Thread-1 (]: Runtime Error in model test (models\duckdb\test.sql)
  Parser Error: syntax error at or near "<"
[0m15:13:55.152477 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75bc9709-66fb-4582-b97b-047cd3261045', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C711EA2690>]}
[0m15:13:55.152477 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main.test ................................. [[31mERROR[0m in 0.09s]
[0m15:13:55.153470 [debug] [Thread-1 (]: Finished running node model.archi.test
[0m15:13:55.154513 [debug] [Thread-4 (]: Marking all children of 'model.archi.test' to be skipped because of status 'error'.  Reason: Runtime Error in model test (models\duckdb\test.sql)
  Parser Error: syntax error at or near "<".
[0m15:13:55.156084 [debug] [MainThread]: Using duckdb connection "master"
[0m15:13:55.156084 [debug] [MainThread]: On master: BEGIN
[0m15:13:55.156703 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:13:55.174938 [debug] [MainThread]: SQL status: OK in 0.019 seconds
[0m15:13:55.175936 [debug] [MainThread]: On master: COMMIT
[0m15:13:55.175936 [debug] [MainThread]: Using duckdb connection "master"
[0m15:13:55.176900 [debug] [MainThread]: On master: COMMIT
[0m15:13:55.176900 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:13:55.177898 [debug] [MainThread]: On master: Close
[0m15:13:55.181590 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:13:55.182591 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m15:13:55.182591 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m15:13:55.183584 [debug] [MainThread]: Connection 'model.archi.test' was properly closed.
[0m15:13:55.184100 [info ] [MainThread]: 
[0m15:13:55.184100 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.48 seconds (0.48s).
[0m15:13:55.186128 [debug] [MainThread]: Command end result
[0m15:13:55.208700 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:13:55.211691 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:13:55.220720 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:13:55.220720 [info ] [MainThread]: 
[0m15:13:55.221722 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:13:55.222707 [info ] [MainThread]: 
[0m15:13:55.222707 [error] [MainThread]:   Runtime Error in model test (models\duckdb\test.sql)
  Parser Error: syntax error at or near "<"
[0m15:13:55.223705 [info ] [MainThread]: 
[0m15:13:55.224271 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:13:55.225278 [debug] [MainThread]: Command `dbt build` failed at 15:13:55.225278 after 1.75 seconds
[0m15:13:55.226277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C70FF49940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C70FF4BA10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C70FF4A7E0>]}
[0m15:13:55.226277 [debug] [MainThread]: Flushing usage events
[0m15:13:56.266882 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:14:47.669679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273386DD490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002733C6D2B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002733C16E5D0>]}


============================== 15:14:47.673722 | be7f941b-b4ed-4be0-93bc-267bbcf1266f ==============================
[0m15:14:47.673722 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:14:47.674229 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt build', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:14:47.906224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'be7f941b-b4ed-4be0-93bc-267bbcf1266f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002733CB55EE0>]}
[0m15:14:47.974879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'be7f941b-b4ed-4be0-93bc-267bbcf1266f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002733B585490>]}
[0m15:14:47.978288 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:14:48.264564 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:14:48.408047 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:14:48.408047 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\test.sql
[0m15:14:48.619032 [error] [MainThread]: Encountered an error:
Compilation Error in model test (models\duckdb\test.sql)
  source() takes exactly two arguments (1 given)
[0m15:14:48.621169 [debug] [MainThread]: Command `dbt build` failed at 15:14:48.620606 after 1.08 seconds
[0m15:14:48.621169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000273386DD490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002733C117380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002733D526ED0>]}
[0m15:14:48.622109 [debug] [MainThread]: Flushing usage events
[0m15:14:49.773672 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:15:03.422498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200BE9A0D70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200BE3C4260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200BF8789E0>]}


============================== 15:15:03.426411 | 86920777-b205-4610-bb17-c6a224e3f297 ==============================
[0m15:15:03.426411 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:15:03.426411 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:15:03.660474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '86920777-b205-4610-bb17-c6a224e3f297', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200BFF30680>]}
[0m15:15:03.725958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '86920777-b205-4610-bb17-c6a224e3f297', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200BE9F72F0>]}
[0m15:15:03.730131 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:15:04.015229 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:15:04.148998 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:15:04.149994 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\test.sql
[0m15:15:04.416078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '86920777-b205-4610-bb17-c6a224e3f297', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200C0DB2FF0>]}
[0m15:15:04.469002 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:15:04.471512 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:15:04.512861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '86920777-b205-4610-bb17-c6a224e3f297', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200C11B80E0>]}
[0m15:15:04.513374 [info ] [MainThread]: Found 1 model, 424 macros
[0m15:15:04.515525 [info ] [MainThread]: 
[0m15:15:04.515525 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:15:04.516549 [info ] [MainThread]: 
[0m15:15:04.517071 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:15:04.518121 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:15:04.609328 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:15:04.610328 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:15:04.610859 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:15:04.628899 [debug] [ThreadPool]: SQL status: OK in 0.019 seconds
[0m15:15:04.630860 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:15:04.634652 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m15:15:04.635671 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m15:15:04.642917 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:15:04.642917 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:15:04.642917 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:15:04.664243 [debug] [ThreadPool]: SQL status: OK in 0.021 seconds
[0m15:15:04.665220 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:15:04.666217 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m15:15:04.666217 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:15:04.667247 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:15:04.667247 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m15:15:04.668369 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:15:04.668369 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:15:04.669347 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:15:04.669347 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:15:04.670412 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:15:04.670412 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m15:15:04.674845 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m15:15:04.680001 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:15:04.680001 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m15:15:04.680929 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:15:04.696474 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:15:04.697504 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:15:04.697504 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:15:04.751990 [debug] [ThreadPool]: SQL status: OK in 0.054 seconds
[0m15:15:04.754391 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m15:15:04.755384 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m15:15:04.755384 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m15:15:04.761113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '86920777-b205-4610-bb17-c6a224e3f297', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200C0C87B00>]}
[0m15:15:04.761113 [debug] [MainThread]: Using duckdb connection "master"
[0m15:15:04.762025 [debug] [MainThread]: On master: BEGIN
[0m15:15:04.762025 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:15:04.779986 [debug] [MainThread]: SQL status: OK in 0.018 seconds
[0m15:15:04.781006 [debug] [MainThread]: On master: COMMIT
[0m15:15:04.781006 [debug] [MainThread]: Using duckdb connection "master"
[0m15:15:04.781604 [debug] [MainThread]: On master: COMMIT
[0m15:15:04.782115 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:15:04.782115 [debug] [MainThread]: On master: Close
[0m15:15:04.787677 [debug] [Thread-1 (]: Began running node model.archi.test
[0m15:15:04.787677 [info ] [Thread-1 (]: 1 of 1 START sql view model main.test .......................................... [RUN]
[0m15:15:04.788673 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.test'
[0m15:15:04.788673 [debug] [Thread-1 (]: Began compiling node model.archi.test
[0m15:15:04.796222 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.test"
[0m15:15:04.796730 [debug] [Thread-1 (]: Began executing node model.archi.test
[0m15:15:04.835425 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.test"
[0m15:15:04.837386 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:15:04.837386 [debug] [Thread-1 (]: On model.archi.test: BEGIN
[0m15:15:04.837386 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:15:04.855458 [debug] [Thread-1 (]: SQL status: OK in 0.018 seconds
[0m15:15:04.856473 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:15:04.856473 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "pytorch_data"."main"."test__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m15:15:04.858026 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:15:04.863786 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:15:04.864328 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */
alter view "pytorch_data"."main"."test" rename to "test__dbt_backup"
[0m15:15:04.864837 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:15:04.868481 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:15:04.869019 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */
alter view "pytorch_data"."main"."test__dbt_tmp" rename to "test"
[0m15:15:04.870037 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:15:04.883363 [debug] [Thread-1 (]: On model.archi.test: COMMIT
[0m15:15:04.883989 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:15:04.884521 [debug] [Thread-1 (]: On model.archi.test: COMMIT
[0m15:15:04.888123 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:15:04.892134 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:15:04.892134 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */
drop view if exists "pytorch_data"."main"."test__dbt_backup" cascade
[0m15:15:04.893644 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:15:04.895422 [debug] [Thread-1 (]: On model.archi.test: Close
[0m15:15:04.936487 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86920777-b205-4610-bb17-c6a224e3f297', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200C0D48620>]}
[0m15:15:04.937002 [info ] [Thread-1 (]: 1 of 1 OK created sql view model main.test ..................................... [[32mOK[0m in 0.15s]
[0m15:15:04.937513 [debug] [Thread-1 (]: Finished running node model.archi.test
[0m15:15:04.938510 [debug] [MainThread]: Using duckdb connection "master"
[0m15:15:04.939873 [debug] [MainThread]: On master: BEGIN
[0m15:15:04.939873 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:15:04.962454 [debug] [MainThread]: SQL status: OK in 0.023 seconds
[0m15:15:04.963452 [debug] [MainThread]: On master: COMMIT
[0m15:15:04.963452 [debug] [MainThread]: Using duckdb connection "master"
[0m15:15:04.963452 [debug] [MainThread]: On master: COMMIT
[0m15:15:04.964449 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:15:04.964449 [debug] [MainThread]: On master: Close
[0m15:15:04.969860 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:15:04.969860 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m15:15:04.970853 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m15:15:04.971395 [debug] [MainThread]: Connection 'model.archi.test' was properly closed.
[0m15:15:04.971937 [info ] [MainThread]: 
[0m15:15:04.971937 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.45 seconds (0.45s).
[0m15:15:04.973585 [debug] [MainThread]: Command end result
[0m15:15:04.991333 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:15:04.994241 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:15:05.001193 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:15:05.001193 [info ] [MainThread]: 
[0m15:15:05.002105 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:15:05.003081 [info ] [MainThread]: 
[0m15:15:05.003081 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:15:05.004979 [debug] [MainThread]: Command `dbt build` succeeded at 15:15:05.004979 after 1.71 seconds
[0m15:15:05.004979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200BF9448C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200C0629DC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200C0D685F0>]}
[0m15:15:05.005970 [debug] [MainThread]: Flushing usage events
[0m15:15:06.274248 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:16:45.784943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028348849B80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002834C1158B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002834CA03410>]}


============================== 15:16:45.789449 | 5f00e539-a676-4343-9317-086be2a55408 ==============================
[0m15:16:45.789449 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:16:45.789514 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:16:46.025877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5f00e539-a676-4343-9317-086be2a55408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002834B57DB50>]}
[0m15:16:46.090346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5f00e539-a676-4343-9317-086be2a55408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028348EF03B0>]}
[0m15:16:46.093841 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:16:46.379278 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:16:46.521740 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:16:46.522737 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\test.sql
[0m15:16:46.781494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5f00e539-a676-4343-9317-086be2a55408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002834D071C70>]}
[0m15:16:46.831196 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:16:46.834322 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:16:46.872408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5f00e539-a676-4343-9317-086be2a55408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002834DAB8740>]}
[0m15:16:46.873400 [info ] [MainThread]: Found 1 model, 424 macros
[0m15:16:46.875488 [info ] [MainThread]: 
[0m15:16:46.876477 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:16:46.877548 [info ] [MainThread]: 
[0m15:16:46.877548 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:16:46.878544 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:16:46.969065 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:16:46.970062 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:16:46.970570 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:16:46.989945 [debug] [ThreadPool]: SQL status: OK in 0.019 seconds
[0m15:16:46.990971 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:16:46.994851 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m15:16:46.995879 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m15:16:47.002674 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:16:47.002674 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:16:47.003640 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:16:47.021183 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:16:47.022180 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:16:47.022180 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m15:16:47.023177 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:16:47.023177 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:16:47.023177 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m15:16:47.024175 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:16:47.025172 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:16:47.025172 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:16:47.025172 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:16:47.026171 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:16:47.026171 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m15:16:47.031215 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m15:16:47.037285 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:16:47.037285 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m15:16:47.037285 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:16:47.054101 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m15:16:47.055100 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:16:47.055100 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:16:47.100977 [debug] [ThreadPool]: SQL status: OK in 0.046 seconds
[0m15:16:47.102581 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m15:16:47.103541 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m15:16:47.104538 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m15:16:47.109446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5f00e539-a676-4343-9317-086be2a55408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002834D5BC650>]}
[0m15:16:47.110394 [debug] [MainThread]: Using duckdb connection "master"
[0m15:16:47.110394 [debug] [MainThread]: On master: BEGIN
[0m15:16:47.110394 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:16:47.128609 [debug] [MainThread]: SQL status: OK in 0.018 seconds
[0m15:16:47.128609 [debug] [MainThread]: On master: COMMIT
[0m15:16:47.128609 [debug] [MainThread]: Using duckdb connection "master"
[0m15:16:47.129612 [debug] [MainThread]: On master: COMMIT
[0m15:16:47.129612 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:16:47.129612 [debug] [MainThread]: On master: Close
[0m15:16:47.135946 [debug] [Thread-1 (]: Began running node model.archi.test
[0m15:16:47.135946 [info ] [Thread-1 (]: 1 of 1 START sql view model main.test .......................................... [RUN]
[0m15:16:47.136974 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.test'
[0m15:16:47.136974 [debug] [Thread-1 (]: Began compiling node model.archi.test
[0m15:16:47.144939 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.test"
[0m15:16:47.146482 [debug] [Thread-1 (]: Began executing node model.archi.test
[0m15:16:47.183080 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.test"
[0m15:16:47.184717 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:16:47.184717 [debug] [Thread-1 (]: On model.archi.test: BEGIN
[0m15:16:47.185647 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:16:47.202029 [debug] [Thread-1 (]: SQL status: OK in 0.017 seconds
[0m15:16:47.202919 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:16:47.202919 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "pytorch_data"."main"."test__dbt_tmp" as (
    "SELECT * FROM raw_commits
  );

[0m15:16:47.203948 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "pytorch_data"."main"."test__dbt_tmp" as (
    "SELECT * FROM raw_commits
  );

[0m15:16:47.203948 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:16:47.204945 [debug] [Thread-1 (]: On model.archi.test: ROLLBACK
[0m15:16:47.210022 [debug] [Thread-1 (]: Failed to rollback 'model.archi.test'
[0m15:16:47.210022 [debug] [Thread-1 (]: On model.archi.test: Close
[0m15:16:47.217033 [debug] [Thread-1 (]: Runtime Error in model test (models\duckdb\test.sql)
  Parser Error: unterminated quoted identifier at or near ""SELECT * FROM raw_commits
    );
  "
[0m15:16:47.218600 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5f00e539-a676-4343-9317-086be2a55408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002834E007FB0>]}
[0m15:16:47.218600 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main.test ................................. [[31mERROR[0m in 0.08s]
[0m15:16:47.220270 [debug] [Thread-1 (]: Finished running node model.archi.test
[0m15:16:47.220779 [debug] [Thread-4 (]: Marking all children of 'model.archi.test' to be skipped because of status 'error'.  Reason: Runtime Error in model test (models\duckdb\test.sql)
  Parser Error: unterminated quoted identifier at or near ""SELECT * FROM raw_commits
    );
  ".
[0m15:16:47.221773 [debug] [MainThread]: Using duckdb connection "master"
[0m15:16:47.221773 [debug] [MainThread]: On master: BEGIN
[0m15:16:47.221773 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:16:47.242047 [debug] [MainThread]: SQL status: OK in 0.020 seconds
[0m15:16:47.242557 [debug] [MainThread]: On master: COMMIT
[0m15:16:47.242557 [debug] [MainThread]: Using duckdb connection "master"
[0m15:16:47.242557 [debug] [MainThread]: On master: COMMIT
[0m15:16:47.243554 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:16:47.244192 [debug] [MainThread]: On master: Close
[0m15:16:47.247213 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:16:47.247213 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m15:16:47.248206 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m15:16:47.248206 [debug] [MainThread]: Connection 'model.archi.test' was properly closed.
[0m15:16:47.248206 [info ] [MainThread]: 
[0m15:16:47.248206 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.37 seconds (0.37s).
[0m15:16:47.249768 [debug] [MainThread]: Command end result
[0m15:16:47.268272 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:16:47.270760 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:16:47.277331 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:16:47.277840 [info ] [MainThread]: 
[0m15:16:47.278348 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:16:47.278348 [info ] [MainThread]: 
[0m15:16:47.279404 [error] [MainThread]:   Runtime Error in model test (models\duckdb\test.sql)
  Parser Error: unterminated quoted identifier at or near ""SELECT * FROM raw_commits
    );
  "
[0m15:16:47.279404 [info ] [MainThread]: 
[0m15:16:47.280634 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:16:47.281598 [debug] [MainThread]: Command `dbt build` failed at 15:16:47.281598 after 1.66 seconds
[0m15:16:47.282595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002834C17BB00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002834C6FAB40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002834C4D96D0>]}
[0m15:16:47.282595 [debug] [MainThread]: Flushing usage events
[0m15:16:48.119646 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:17:02.890348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF5C17B8F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF5C17A5A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF5C17BD40>]}


============================== 15:17:02.894420 | 1f3b941f-d556-4407-83ef-982066f06dec ==============================
[0m15:17:02.894420 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:17:02.894420 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m15:17:03.120822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1f3b941f-d556-4407-83ef-982066f06dec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF5B5292E0>]}
[0m15:17:03.184613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1f3b941f-d556-4407-83ef-982066f06dec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF5C9BFF80>]}
[0m15:17:03.188653 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:17:03.469064 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:17:03.607325 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 0 files changed.
[0m15:17:03.608229 [debug] [MainThread]: Partial parsing: deleted file: archi://models\duckdb\test.sql
[0m15:17:03.642170 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.duckdb
[0m15:17:03.647319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1f3b941f-d556-4407-83ef-982066f06dec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF5D1B0320>]}
[0m15:17:03.686863 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:17:03.689859 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:17:03.726750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1f3b941f-d556-4407-83ef-982066f06dec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF5D670950>]}
[0m15:17:03.727715 [info ] [MainThread]: Found 424 macros
[0m15:17:03.728712 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m15:17:03.731284 [debug] [MainThread]: Command end result
[0m15:17:03.747348 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:17:03.749391 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:17:03.754433 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:17:03.755523 [debug] [MainThread]: Command `dbt build` succeeded at 15:17:03.755523 after 0.99 seconds
[0m15:17:03.756058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF5C1A3E00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF5881F860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF5BD47560>]}
[0m15:17:03.756607 [debug] [MainThread]: Flushing usage events
[0m15:17:04.830479 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:18:43.395955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4AD81E8D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B03A05C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B03A1130>]}


============================== 15:18:43.400021 | 5a7ecc09-3395-49f6-b6aa-2a22a75c5797 ==============================
[0m15:18:43.400021 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:18:43.401018 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:18:43.634090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5a7ecc09-3395-49f6-b6aa-2a22a75c5797', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B20B4B00>]}
[0m15:18:43.700621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5a7ecc09-3395-49f6-b6aa-2a22a75c5797', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B207B860>]}
[0m15:18:43.705707 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:18:43.993143 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:18:44.105426 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m15:18:44.106423 [debug] [MainThread]: Partial parsing: added file: archi://models\duckdb\test.sql
[0m15:18:44.395591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5a7ecc09-3395-49f6-b6aa-2a22a75c5797', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B2727FE0>]}
[0m15:18:44.448952 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:18:44.451834 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:18:44.491612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5a7ecc09-3395-49f6-b6aa-2a22a75c5797', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B2BB87A0>]}
[0m15:18:44.492121 [info ] [MainThread]: Found 1 model, 424 macros
[0m15:18:44.494654 [info ] [MainThread]: 
[0m15:18:44.495163 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:18:44.496157 [info ] [MainThread]: 
[0m15:18:44.496157 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:18:44.497461 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:18:44.591281 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:18:44.592181 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:18:44.592181 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:18:44.612589 [debug] [ThreadPool]: SQL status: OK in 0.020 seconds
[0m15:18:44.614097 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:18:44.617358 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m15:18:44.617953 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m15:18:44.624845 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:18:44.625877 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:18:44.625877 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:18:44.644568 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:18:44.645566 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:18:44.646073 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m15:18:44.646073 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:18:44.646073 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:18:44.647100 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m15:18:44.647100 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:18:44.648212 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:18:44.648212 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:18:44.648212 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:18:44.649235 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:18:44.649235 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m15:18:44.654273 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m15:18:44.661338 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:18:44.661845 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m15:18:44.661909 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:18:44.679021 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:18:44.680019 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:18:44.680594 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:18:44.736026 [debug] [ThreadPool]: SQL status: OK in 0.055 seconds
[0m15:18:44.737130 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m15:18:44.739054 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m15:18:44.739054 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m15:18:44.744576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a7ecc09-3395-49f6-b6aa-2a22a75c5797', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B2560680>]}
[0m15:18:44.745600 [debug] [MainThread]: Using duckdb connection "master"
[0m15:18:44.745600 [debug] [MainThread]: On master: BEGIN
[0m15:18:44.745600 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:18:44.763774 [debug] [MainThread]: SQL status: OK in 0.018 seconds
[0m15:18:44.763774 [debug] [MainThread]: On master: COMMIT
[0m15:18:44.764768 [debug] [MainThread]: Using duckdb connection "master"
[0m15:18:44.764768 [debug] [MainThread]: On master: COMMIT
[0m15:18:44.764768 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:18:44.765770 [debug] [MainThread]: On master: Close
[0m15:18:44.770622 [debug] [Thread-1 (]: Began running node model.archi.test
[0m15:18:44.771617 [info ] [Thread-1 (]: 1 of 1 START sql view model main.test .......................................... [RUN]
[0m15:18:44.772808 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.test'
[0m15:18:44.772808 [debug] [Thread-1 (]: Began compiling node model.archi.test
[0m15:18:44.779394 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.test"
[0m15:18:44.780402 [debug] [Thread-1 (]: Began executing node model.archi.test
[0m15:18:44.819166 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.test"
[0m15:18:44.819679 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:18:44.820670 [debug] [Thread-1 (]: On model.archi.test: BEGIN
[0m15:18:44.820670 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:18:44.839032 [debug] [Thread-1 (]: SQL status: OK in 0.018 seconds
[0m15:18:44.839032 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:18:44.840022 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */

  
  create view "pytorch_data"."main"."test__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m15:18:44.841025 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:18:44.846683 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:18:44.847226 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */
alter view "pytorch_data"."main"."test" rename to "test__dbt_backup"
[0m15:18:44.847226 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:18:44.849441 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:18:44.850464 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */
alter view "pytorch_data"."main"."test__dbt_tmp" rename to "test"
[0m15:18:44.850464 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:18:44.864161 [debug] [Thread-1 (]: On model.archi.test: COMMIT
[0m15:18:44.864161 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:18:44.865546 [debug] [Thread-1 (]: On model.archi.test: COMMIT
[0m15:18:44.868618 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:18:44.873866 [debug] [Thread-1 (]: Using duckdb connection "model.archi.test"
[0m15:18:44.874867 [debug] [Thread-1 (]: On model.archi.test: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.test"} */
drop view if exists "pytorch_data"."main"."test__dbt_backup" cascade
[0m15:18:44.875375 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:18:44.878457 [debug] [Thread-1 (]: On model.archi.test: Close
[0m15:18:44.916273 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a7ecc09-3395-49f6-b6aa-2a22a75c5797', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B30E2A20>]}
[0m15:18:44.916273 [info ] [Thread-1 (]: 1 of 1 OK created sql view model main.test ..................................... [[32mOK[0m in 0.14s]
[0m15:18:44.917267 [debug] [Thread-1 (]: Finished running node model.archi.test
[0m15:18:44.918492 [debug] [MainThread]: Using duckdb connection "master"
[0m15:18:44.919421 [debug] [MainThread]: On master: BEGIN
[0m15:18:44.919421 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:18:44.943483 [debug] [MainThread]: SQL status: OK in 0.024 seconds
[0m15:18:44.944528 [debug] [MainThread]: On master: COMMIT
[0m15:18:44.945069 [debug] [MainThread]: Using duckdb connection "master"
[0m15:18:44.945069 [debug] [MainThread]: On master: COMMIT
[0m15:18:44.945069 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:18:44.946096 [debug] [MainThread]: On master: Close
[0m15:18:44.949342 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:18:44.949845 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m15:18:44.949851 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m15:18:44.950357 [debug] [MainThread]: Connection 'model.archi.test' was properly closed.
[0m15:18:44.950357 [info ] [MainThread]: 
[0m15:18:44.950865 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.45 seconds (0.45s).
[0m15:18:44.951859 [debug] [MainThread]: Command end result
[0m15:18:44.972352 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:18:44.974932 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:18:44.980445 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:18:44.980445 [info ] [MainThread]: 
[0m15:18:44.981474 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:18:44.981474 [info ] [MainThread]: 
[0m15:18:44.982473 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:18:44.983436 [debug] [MainThread]: Command `dbt build` succeeded at 15:18:44.983436 after 1.75 seconds
[0m15:18:44.984437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B1680620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B17D3B90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B17D3AD0>]}
[0m15:18:44.984995 [debug] [MainThread]: Flushing usage events
[0m15:18:45.899830 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:34:54.733598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DBE4A79A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DBE4A7A750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DBE4BDA540>]}


============================== 15:34:54.737106 | 0f5a3c99-1ffc-486f-b75c-e5a689f9d280 ==============================
[0m15:34:54.737106 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:34:54.738672 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m15:34:54.976422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0f5a3c99-1ffc-486f-b75c-e5a689f9d280', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DBE51A0500>]}
[0m15:34:55.041792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0f5a3c99-1ffc-486f-b75c-e5a689f9d280', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DBE594DA60>]}
[0m15:34:55.046227 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:34:55.332677 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:34:55.402624 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m15:34:55.403489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0f5a3c99-1ffc-486f-b75c-e5a689f9d280', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DBE50EBD10>]}
[0m15:34:56.533249 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.archi.cleancommits' (models\duckdb\cleancommits.sql) depends on a node named 'raw_commits' which was not found
[0m15:34:56.535543 [debug] [MainThread]: Command `dbt build` failed at 15:34:56.534991 after 1.97 seconds
[0m15:34:56.535543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DBE3BA3920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DBE5F645F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DBE5F645C0>]}
[0m15:34:56.536567 [debug] [MainThread]: Flushing usage events
[0m15:34:57.877078 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:35:25.447431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E6FC4FF740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E6FC97B380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E6FF2A3FE0>]}


============================== 15:35:25.451561 | 600744a9-39d5-4546-80fb-e460fdbd68fd ==============================
[0m15:35:25.451561 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:35:25.452068 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt build', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:35:25.690050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '600744a9-39d5-4546-80fb-e460fdbd68fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E6806A74A0>]}
[0m15:35:25.759058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '600744a9-39d5-4546-80fb-e460fdbd68fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E6FC8EAEA0>]}
[0m15:35:25.763020 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:35:26.050325 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:35:26.122695 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m15:35:26.123663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '600744a9-39d5-4546-80fb-e460fdbd68fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E68128F7A0>]}
[0m15:35:27.271460 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.archi.cleancommits' (models\duckdb\cleancommits.sql) depends on a node named 'raw_commits' which was not found
[0m15:35:27.272896 [debug] [MainThread]: Command `dbt build` failed at 15:35:27.272896 after 1.95 seconds
[0m15:35:27.272896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E68046ECC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E68077AD20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002E68163D1C0>]}
[0m15:35:27.273920 [debug] [MainThread]: Flushing usage events
[0m15:35:28.301926 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:35:48.972305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B53112B170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B535E00AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B535E00200>]}


============================== 15:35:48.976791 | 44a0a4ab-bf9d-4c0a-890d-eae90251fb1e ==============================
[0m15:35:48.976791 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:35:48.978411 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:35:49.213459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '44a0a4ab-bf9d-4c0a-890d-eae90251fb1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B535FBB500>]}
[0m15:35:49.281445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '44a0a4ab-bf9d-4c0a-890d-eae90251fb1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B535F28470>]}
[0m15:35:49.284946 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:35:49.573975 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:35:49.645395 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m15:35:49.645395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '44a0a4ab-bf9d-4c0a-890d-eae90251fb1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B53577A120>]}
[0m15:35:50.852123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '44a0a4ab-bf9d-4c0a-890d-eae90251fb1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B536ECF920>]}
[0m15:35:50.908148 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:35:50.911170 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:35:50.986094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '44a0a4ab-bf9d-4c0a-890d-eae90251fb1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B536E772C0>]}
[0m15:35:50.987007 [info ] [MainThread]: Found 4 models, 424 macros
[0m15:35:50.989593 [info ] [MainThread]: 
[0m15:35:50.989593 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:35:50.990622 [info ] [MainThread]: 
[0m15:35:50.991685 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:35:50.996850 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:35:51.086755 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:35:51.086755 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:35:51.087678 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:35:51.107769 [debug] [ThreadPool]: SQL status: OK in 0.020 seconds
[0m15:35:51.109305 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:35:51.113056 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:35:51.113651 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:35:51.120247 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:35:51.120247 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:35:51.121164 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:35:51.143986 [debug] [ThreadPool]: SQL status: OK in 0.023 seconds
[0m15:35:51.146014 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:35:51.146014 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:35:51.146969 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:35:51.146969 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:35:51.148000 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:35:51.148000 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:35:51.149547 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:35:51.149547 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:35:51.150571 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:35:51.154078 [debug] [ThreadPool]: SQL status: OK in 0.003 seconds
[0m15:35:51.154078 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:35:51.192849 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:35:51.199912 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:35:51.199912 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:35:51.199912 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:35:51.223140 [debug] [ThreadPool]: SQL status: OK in 0.023 seconds
[0m15:35:51.223140 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:35:51.224255 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:35:51.271472 [debug] [ThreadPool]: SQL status: OK in 0.048 seconds
[0m15:35:51.273666 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:35:51.274680 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:35:51.275221 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:35:51.279980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '44a0a4ab-bf9d-4c0a-890d-eae90251fb1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B536BE6750>]}
[0m15:35:51.280528 [debug] [MainThread]: Using duckdb connection "master"
[0m15:35:51.280528 [debug] [MainThread]: On master: BEGIN
[0m15:35:51.281522 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:35:51.299556 [debug] [MainThread]: SQL status: OK in 0.018 seconds
[0m15:35:51.299556 [debug] [MainThread]: On master: COMMIT
[0m15:35:51.300499 [debug] [MainThread]: Using duckdb connection "master"
[0m15:35:51.300499 [debug] [MainThread]: On master: COMMIT
[0m15:35:51.301009 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:35:51.301009 [debug] [MainThread]: On master: Close
[0m15:35:51.306050 [debug] [Thread-1 (]: Began running node model.archi.cleancommits
[0m15:35:51.306557 [info ] [Thread-1 (]: 1 of 4 START sql view model main_cleansed.cleancommits ......................... [RUN]
[0m15:35:51.306557 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommits'
[0m15:35:51.307619 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommits
[0m15:35:51.316611 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommits"
[0m15:35:51.317543 [debug] [Thread-1 (]: Began executing node model.archi.cleancommits
[0m15:35:51.351682 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommits"
[0m15:35:51.352676 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:35:51.353642 [debug] [Thread-1 (]: On model.archi.cleancommits: BEGIN
[0m15:35:51.353642 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:35:51.371856 [debug] [Thread-1 (]: SQL status: OK in 0.018 seconds
[0m15:35:51.371856 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:35:51.372835 [debug] [Thread-1 (]: On model.archi.cleancommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        message,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where message is not null  -- Filtrer les commits sans message
)

select
    id,
    author_id,
    message,
    created_at
from raw
  );

[0m15:35:51.373377 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        message,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where message is not null  -- Filtrer les commits sans message
)

select
    id,
    author_id,
    message,
    created_at
from raw
  );

[0m15:35:51.374402 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:35:51.374402 [debug] [Thread-1 (]: On model.archi.cleancommits: ROLLBACK
[0m15:35:51.380871 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommits'
[0m15:35:51.380871 [debug] [Thread-1 (]: On model.archi.cleancommits: Close
[0m15:35:51.386464 [debug] [Thread-1 (]: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 13:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      message,
      created_at
  from raw
    );
  ...
                     ^
[0m15:35:51.388495 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44a0a4ab-bf9d-4c0a-890d-eae90251fb1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B536E52750>]}
[0m15:35:51.389106 [error] [Thread-1 (]: 1 of 4 ERROR creating sql view model main_cleansed.cleancommits ................ [[31mERROR[0m in 0.08s]
[0m15:35:51.389998 [debug] [Thread-1 (]: Finished running node model.archi.cleancommits
[0m15:35:51.389998 [debug] [Thread-1 (]: Began running node model.archi.cleancontributors
[0m15:35:51.391651 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommits' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 13:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      message,
      created_at
  from raw
    );
  ...
                     ^.
[0m15:35:51.391027 [info ] [Thread-1 (]: 2 of 4 START sql view model main_cleansed.cleancontributors .................... [RUN]
[0m15:35:51.392159 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommits, now model.archi.cleancontributors)
[0m15:35:51.393188 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributors
[0m15:35:51.396256 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributors"
[0m15:35:51.397790 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributors
[0m15:35:51.402324 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributors"
[0m15:35:51.403625 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:35:51.404174 [debug] [Thread-1 (]: On model.archi.cleancontributors: BEGIN
[0m15:35:51.404726 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:35:51.423817 [debug] [Thread-1 (]: SQL status: OK in 0.019 seconds
[0m15:35:51.423817 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:35:51.424812 [debug] [Thread-1 (]: On model.archi.cleancontributors: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        email,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where email is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    name,
    email
from raw
  );

[0m15:35:51.425464 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        email,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where email is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    name,
    email
from raw
  );

[0m15:35:51.425972 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:35:51.425972 [debug] [Thread-1 (]: On model.archi.cleancontributors: ROLLBACK
[0m15:35:51.430853 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancontributors'
[0m15:35:51.430853 [debug] [Thread-1 (]: On model.archi.cleancontributors: Close
[0m15:35:51.437354 [debug] [Thread-1 (]: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      email
  from raw
    );
  ...
                     ^
[0m15:35:51.438365 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44a0a4ab-bf9d-4c0a-890d-eae90251fb1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B53800E2D0>]}
[0m15:35:51.438878 [error] [Thread-1 (]: 2 of 4 ERROR creating sql view model main_cleansed.cleancontributors ........... [[31mERROR[0m in 0.05s]
[0m15:35:51.439384 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributors
[0m15:35:51.439384 [debug] [Thread-1 (]: Began running node model.archi.cleanissues
[0m15:35:51.440379 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancontributors' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      email
  from raw
    );
  ...
                     ^.
[0m15:35:51.440379 [info ] [Thread-1 (]: 3 of 4 START sql view model main_cleansed.cleanissues .......................... [RUN]
[0m15:35:51.441300 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributors, now model.archi.cleanissues)
[0m15:35:51.441809 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissues
[0m15:35:51.444248 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissues"
[0m15:35:51.446863 [debug] [Thread-1 (]: Began executing node model.archi.cleanissues
[0m15:35:51.450938 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissues"
[0m15:35:51.450938 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:35:51.452326 [debug] [Thread-1 (]: On model.archi.cleanissues: BEGIN
[0m15:35:51.452875 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:35:51.471148 [debug] [Thread-1 (]: SQL status: OK in 0.019 seconds
[0m15:35:51.471148 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:35:51.472148 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where title is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    author_id,
    created_at
from raw
  );

[0m15:35:51.473146 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where title is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    author_id,
    created_at
from raw
  );

[0m15:35:51.474144 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:35:51.474152 [debug] [Thread-1 (]: On model.archi.cleanissues: ROLLBACK
[0m15:35:51.477828 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanissues'
[0m15:35:51.477828 [debug] [Thread-1 (]: On model.archi.cleanissues: Close
[0m15:35:51.484336 [debug] [Thread-1 (]: Runtime Error in model cleanissues (models\duckdb\cleanissues.sql)
  Binder Error: Referenced column "author_id" not found in FROM clause!
  Candidate bindings: "raw_issues.author_association", "raw_issues.user.gravatar_id", "raw_issues.node_id", "raw_issues.user.node_id"
  LINE 9:         author_id,
                  ^
[0m15:35:51.484879 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44a0a4ab-bf9d-4c0a-890d-eae90251fb1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B53801F170>]}
[0m15:35:51.485422 [error] [Thread-1 (]: 3 of 4 ERROR creating sql view model main_cleansed.cleanissues ................. [[31mERROR[0m in 0.04s]
[0m15:35:51.486413 [debug] [Thread-1 (]: Finished running node model.archi.cleanissues
[0m15:35:51.486413 [debug] [Thread-1 (]: Began running node model.archi.cleanpullrequest
[0m15:35:51.487443 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanissues' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanissues (models\duckdb\cleanissues.sql)
  Binder Error: Referenced column "author_id" not found in FROM clause!
  Candidate bindings: "raw_issues.author_association", "raw_issues.user.gravatar_id", "raw_issues.node_id", "raw_issues.user.node_id"
  LINE 9:         author_id,
                  ^.
[0m15:35:51.486413 [info ] [Thread-1 (]: 4 of 4 START sql view model main_cleansed.cleanpullrequest ..................... [RUN]
[0m15:35:51.488094 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissues, now model.archi.cleanpullrequest)
[0m15:35:51.488094 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpullrequest
[0m15:35:51.490010 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpullrequest"
[0m15:35:51.491518 [debug] [Thread-1 (]: Began executing node model.archi.cleanpullrequest
[0m15:35:51.495728 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpullrequest"
[0m15:35:51.497232 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:35:51.497232 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: BEGIN
[0m15:35:51.498253 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:35:51.517632 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m15:35:51.518638 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:35:51.518638 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where title is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    author_id,
    created_at
from raw
  );

[0m15:35:51.520684 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where title is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    author_id,
    created_at
from raw
  );

[0m15:35:51.520684 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:35:51.521688 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: ROLLBACK
[0m15:35:51.524838 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanpullrequest'
[0m15:35:51.524838 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: Close
[0m15:35:51.532872 [debug] [Thread-1 (]: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced column "author_id" not found in FROM clause!
  Candidate bindings: "raw_pull_requests.author_association", "raw_pull_requests.auto_merge", "raw_pull_requests.node_id"
  LINE 9:         author_id,
                  ^
[0m15:35:51.532872 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '44a0a4ab-bf9d-4c0a-890d-eae90251fb1e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B538038F50>]}
[0m15:35:51.533867 [error] [Thread-1 (]: 4 of 4 ERROR creating sql view model main_cleansed.cleanpullrequest ............ [[31mERROR[0m in 0.04s]
[0m15:35:51.535095 [debug] [Thread-1 (]: Finished running node model.archi.cleanpullrequest
[0m15:35:51.535602 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanpullrequest' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced column "author_id" not found in FROM clause!
  Candidate bindings: "raw_pull_requests.author_association", "raw_pull_requests.auto_merge", "raw_pull_requests.node_id"
  LINE 9:         author_id,
                  ^.
[0m15:35:51.536598 [debug] [MainThread]: Using duckdb connection "master"
[0m15:35:51.537595 [debug] [MainThread]: On master: BEGIN
[0m15:35:51.537595 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:35:51.555600 [debug] [MainThread]: SQL status: OK in 0.018 seconds
[0m15:35:51.555600 [debug] [MainThread]: On master: COMMIT
[0m15:35:51.556557 [debug] [MainThread]: Using duckdb connection "master"
[0m15:35:51.556557 [debug] [MainThread]: On master: COMMIT
[0m15:35:51.556557 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:35:51.557555 [debug] [MainThread]: On master: Close
[0m15:35:51.559549 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:35:51.561023 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:35:51.561023 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:35:51.561990 [debug] [MainThread]: Connection 'model.archi.cleanpullrequest' was properly closed.
[0m15:35:51.561990 [info ] [MainThread]: 
[0m15:35:51.563063 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 0.57 seconds (0.57s).
[0m15:35:51.564981 [debug] [MainThread]: Command end result
[0m15:35:51.584285 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:35:51.586384 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:35:51.592790 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:35:51.592790 [info ] [MainThread]: 
[0m15:35:51.593419 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m15:35:51.594339 [info ] [MainThread]: 
[0m15:35:51.594339 [error] [MainThread]:   Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 13:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      message,
      created_at
  from raw
    );
  ...
                     ^
[0m15:35:51.595323 [info ] [MainThread]: 
[0m15:35:51.596750 [error] [MainThread]:   Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      email
  from raw
    );
  ...
                     ^
[0m15:35:51.597642 [info ] [MainThread]: 
[0m15:35:51.598675 [error] [MainThread]:   Runtime Error in model cleanissues (models\duckdb\cleanissues.sql)
  Binder Error: Referenced column "author_id" not found in FROM clause!
  Candidate bindings: "raw_issues.author_association", "raw_issues.user.gravatar_id", "raw_issues.node_id", "raw_issues.user.node_id"
  LINE 9:         author_id,
                  ^
[0m15:35:51.599637 [info ] [MainThread]: 
[0m15:35:51.599637 [error] [MainThread]:   Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced column "author_id" not found in FROM clause!
  Candidate bindings: "raw_pull_requests.author_association", "raw_pull_requests.auto_merge", "raw_pull_requests.node_id"
  LINE 9:         author_id,
                  ^
[0m15:35:51.600666 [info ] [MainThread]: 
[0m15:35:51.601631 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m15:35:51.602660 [debug] [MainThread]: Command `dbt build` failed at 15:35:51.602660 after 2.75 seconds
[0m15:35:51.602660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B531DDFCB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B535B0AA20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B535EA6B40>]}
[0m15:35:51.603625 [debug] [MainThread]: Flushing usage events
[0m15:35:53.428750 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:38:21.774188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018B9DDDF0E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BA17A3EC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BA1673BF0>]}


============================== 15:38:21.778682 | a8ded849-3635-4868-ae44-4f74bc3db7dd ==============================
[0m15:38:21.778682 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:38:21.778682 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:38:21.991113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a8ded849-3635-4868-ae44-4f74bc3db7dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BA20EDEE0>]}
[0m15:38:22.050426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a8ded849-3635-4868-ae44-4f74bc3db7dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BA0B819D0>]}
[0m15:38:22.053301 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:38:22.307162 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:38:22.426172 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 4 files changed.
[0m15:38:22.426172 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleancommits.sql
[0m15:38:22.426172 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleancontributors.sql
[0m15:38:22.427167 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleanpullrequest.sql
[0m15:38:22.427167 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleanissues.sql
[0m15:38:22.674856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a8ded849-3635-4868-ae44-4f74bc3db7dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BA2E2FF20>]}
[0m15:38:22.723105 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:38:22.725101 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:38:22.759216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a8ded849-3635-4868-ae44-4f74bc3db7dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BA30CC110>]}
[0m15:38:22.760161 [info ] [MainThread]: Found 4 models, 424 macros
[0m15:38:22.762271 [info ] [MainThread]: 
[0m15:38:22.762271 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:38:22.763204 [info ] [MainThread]: 
[0m15:38:22.764201 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:38:22.768887 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:38:22.850620 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:38:22.850620 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:38:22.851147 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:38:22.871656 [debug] [ThreadPool]: SQL status: OK in 0.020 seconds
[0m15:38:22.872276 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:38:22.876376 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:38:22.876919 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:38:22.882504 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:38:22.882504 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:38:22.882504 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:38:22.899342 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m15:38:22.901334 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:38:22.901334 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:38:22.902331 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:38:22.902331 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:38:22.902331 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:38:22.903329 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:38:22.904326 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:38:22.904326 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:38:22.904326 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:38:22.905323 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:38:22.905323 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:38:22.909832 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:38:22.914433 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:38:22.914433 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:38:22.914433 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:38:22.930980 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:38:22.930980 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:38:22.930980 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:38:22.974463 [debug] [ThreadPool]: SQL status: OK in 0.042 seconds
[0m15:38:22.975548 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:38:22.976541 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:38:22.977175 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:38:22.980813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a8ded849-3635-4868-ae44-4f74bc3db7dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BA2E13B90>]}
[0m15:38:22.981723 [debug] [MainThread]: Using duckdb connection "master"
[0m15:38:22.981723 [debug] [MainThread]: On master: BEGIN
[0m15:38:22.982230 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:38:22.997710 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:38:22.997710 [debug] [MainThread]: On master: COMMIT
[0m15:38:22.998707 [debug] [MainThread]: Using duckdb connection "master"
[0m15:38:22.998707 [debug] [MainThread]: On master: COMMIT
[0m15:38:22.999705 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:38:22.999705 [debug] [MainThread]: On master: Close
[0m15:38:23.004994 [debug] [Thread-1 (]: Began running node model.archi.cleancommits
[0m15:38:23.005699 [info ] [Thread-1 (]: 1 of 4 START sql view model main_cleansed.cleancommits ......................... [RUN]
[0m15:38:23.006659 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommits'
[0m15:38:23.006659 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommits
[0m15:38:23.012822 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommits"
[0m15:38:23.014331 [debug] [Thread-1 (]: Began executing node model.archi.cleancommits
[0m15:38:23.044525 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommits"
[0m15:38:23.045066 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:38:23.045066 [debug] [Thread-1 (]: On model.archi.cleancommits: BEGIN
[0m15:38:23.046090 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:38:23.061388 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:38:23.062427 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:38:23.062427 [debug] [Thread-1 (]: On model.archi.cleancommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where message is not null  -- Filtrer les commits sans message
)

select
    id,
    author_id,
    created_at
from raw
  );

[0m15:38:23.063387 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where message is not null  -- Filtrer les commits sans message
)

select
    id,
    author_id,
    created_at
from raw
  );

[0m15:38:23.064399 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:38:23.064399 [debug] [Thread-1 (]: On model.archi.cleancommits: ROLLBACK
[0m15:38:23.070863 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommits'
[0m15:38:23.070863 [debug] [Thread-1 (]: On model.archi.cleancommits: Close
[0m15:38:23.076636 [debug] [Thread-1 (]: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 12:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^
[0m15:38:23.078210 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8ded849-3635-4868-ae44-4f74bc3db7dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BA36154F0>]}
[0m15:38:23.078848 [error] [Thread-1 (]: 1 of 4 ERROR creating sql view model main_cleansed.cleancommits ................ [[31mERROR[0m in 0.07s]
[0m15:38:23.079393 [debug] [Thread-1 (]: Finished running node model.archi.cleancommits
[0m15:38:23.079937 [debug] [Thread-1 (]: Began running node model.archi.cleancontributors
[0m15:38:23.080930 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommits' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 12:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^.
[0m15:38:23.079937 [info ] [Thread-1 (]: 2 of 4 START sql view model main_cleansed.cleancontributors .................... [RUN]
[0m15:38:23.081572 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommits, now model.archi.cleancontributors)
[0m15:38:23.082117 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributors
[0m15:38:23.084106 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributors"
[0m15:38:23.085138 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributors
[0m15:38:23.089157 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributors"
[0m15:38:23.090123 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:38:23.090123 [debug] [Thread-1 (]: On model.archi.cleancontributors: BEGIN
[0m15:38:23.090123 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:23.108001 [debug] [Thread-1 (]: SQL status: OK in 0.018 seconds
[0m15:38:23.108999 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:38:23.109606 [debug] [Thread-1 (]: On model.archi.cleancontributors: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        raw_contributors.html_url,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where email is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    name,
    email
from raw
  );

[0m15:38:23.110534 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        raw_contributors.html_url,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where email is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    name,
    email
from raw
  );

[0m15:38:23.110534 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:38:23.110534 [debug] [Thread-1 (]: On model.archi.cleancontributors: ROLLBACK
[0m15:38:23.113495 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancontributors'
[0m15:38:23.114530 [debug] [Thread-1 (]: On model.archi.cleancontributors: Close
[0m15:38:23.120202 [debug] [Thread-1 (]: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      email
  from raw
    );
  ...
                     ^
[0m15:38:23.120715 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8ded849-3635-4868-ae44-4f74bc3db7dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BA36DBAD0>]}
[0m15:38:23.121708 [error] [Thread-1 (]: 2 of 4 ERROR creating sql view model main_cleansed.cleancontributors ........... [[31mERROR[0m in 0.04s]
[0m15:38:23.122462 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributors
[0m15:38:23.122462 [debug] [Thread-1 (]: Began running node model.archi.cleanissues
[0m15:38:23.124030 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancontributors' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      email
  from raw
    );
  ...
                     ^.
[0m15:38:23.123016 [info ] [Thread-1 (]: 3 of 4 START sql view model main_cleansed.cleanissues .......................... [RUN]
[0m15:38:23.124030 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributors, now model.archi.cleanissues)
[0m15:38:23.124669 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissues
[0m15:38:23.126232 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissues"
[0m15:38:23.127757 [debug] [Thread-1 (]: Began executing node model.archi.cleanissues
[0m15:38:23.130385 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissues"
[0m15:38:23.131020 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:38:23.131527 [debug] [Thread-1 (]: On model.archi.cleanissues: BEGIN
[0m15:38:23.131527 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:23.147929 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:38:23.147929 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:38:23.148923 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_issues.user.node_i,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where title is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    author_id,
    created_at
from raw
  );

[0m15:38:23.149921 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_issues.user.node_i,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where title is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    author_id,
    created_at
from raw
  );

[0m15:38:23.149926 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:38:23.150434 [debug] [Thread-1 (]: On model.archi.cleanissues: ROLLBACK
[0m15:38:23.153523 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanissues'
[0m15:38:23.154492 [debug] [Thread-1 (]: On model.archi.cleanissues: Close
[0m15:38:23.159476 [debug] [Thread-1 (]: Runtime Error in model cleanissues (models\duckdb\cleanissues.sql)
  Binder Error: Table "raw_issues" does not have a column named "user"
  LINE 9:         raw_issues.user.node_i,
                  ^
[0m15:38:23.159476 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8ded849-3635-4868-ae44-4f74bc3db7dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BA280A4E0>]}
[0m15:38:23.160469 [error] [Thread-1 (]: 3 of 4 ERROR creating sql view model main_cleansed.cleanissues ................. [[31mERROR[0m in 0.04s]
[0m15:38:23.161706 [debug] [Thread-1 (]: Finished running node model.archi.cleanissues
[0m15:38:23.161800 [debug] [Thread-1 (]: Began running node model.archi.cleanpullrequest
[0m15:38:23.162730 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanissues' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanissues (models\duckdb\cleanissues.sql)
  Binder Error: Table "raw_issues" does not have a column named "user"
  LINE 9:         raw_issues.user.node_i,
                  ^.
[0m15:38:23.161800 [info ] [Thread-1 (]: 4 of 4 START sql view model main_cleansed.cleanpullrequest ..................... [RUN]
[0m15:38:23.162730 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissues, now model.archi.cleanpullrequest)
[0m15:38:23.163729 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpullrequest
[0m15:38:23.165873 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpullrequest"
[0m15:38:23.166406 [debug] [Thread-1 (]: Began executing node model.archi.cleanpullrequest
[0m15:38:23.169441 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpullrequest"
[0m15:38:23.170210 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:38:23.171192 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: BEGIN
[0m15:38:23.171192 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:23.187520 [debug] [Thread-1 (]: SQL status: OK in 0.017 seconds
[0m15:38:23.188548 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:38:23.188548 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_pull_requests.node_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where title is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    author_id,
    created_at
from raw
  );

[0m15:38:23.189921 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_pull_requests.node_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where title is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    author_id,
    created_at
from raw
  );

[0m15:38:23.189921 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:38:23.190845 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: ROLLBACK
[0m15:38:23.193443 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanpullrequest'
[0m15:38:23.193443 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: Close
[0m15:38:23.199347 [debug] [Thread-1 (]: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced column "author_id" not found in FROM clause!
  Candidate bindings: "raw.node_id", "raw.created_at"
  LINE 19:     author_id,
               ^
[0m15:38:23.199988 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8ded849-3635-4868-ae44-4f74bc3db7dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BA3617A70>]}
[0m15:38:23.200581 [error] [Thread-1 (]: 4 of 4 ERROR creating sql view model main_cleansed.cleanpullrequest ............ [[31mERROR[0m in 0.04s]
[0m15:38:23.200581 [debug] [Thread-1 (]: Finished running node model.archi.cleanpullrequest
[0m15:38:23.201510 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanpullrequest' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced column "author_id" not found in FROM clause!
  Candidate bindings: "raw.node_id", "raw.created_at"
  LINE 19:     author_id,
               ^.
[0m15:38:23.203525 [debug] [MainThread]: Using duckdb connection "master"
[0m15:38:23.203525 [debug] [MainThread]: On master: BEGIN
[0m15:38:23.204546 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:38:23.219768 [debug] [MainThread]: SQL status: OK in 0.015 seconds
[0m15:38:23.219768 [debug] [MainThread]: On master: COMMIT
[0m15:38:23.220742 [debug] [MainThread]: Using duckdb connection "master"
[0m15:38:23.220742 [debug] [MainThread]: On master: COMMIT
[0m15:38:23.220742 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:38:23.221775 [debug] [MainThread]: On master: Close
[0m15:38:23.224731 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:38:23.225239 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:38:23.225746 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:38:23.225746 [debug] [MainThread]: Connection 'model.archi.cleanpullrequest' was properly closed.
[0m15:38:23.225746 [info ] [MainThread]: 
[0m15:38:23.226740 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m15:38:23.227738 [debug] [MainThread]: Command end result
[0m15:38:23.245366 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:38:23.247899 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:38:23.252852 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:38:23.254308 [info ] [MainThread]: 
[0m15:38:23.254308 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m15:38:23.255302 [info ] [MainThread]: 
[0m15:38:23.255302 [error] [MainThread]:   Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 12:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^
[0m15:38:23.256333 [info ] [MainThread]: 
[0m15:38:23.257217 [error] [MainThread]:   Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      email
  from raw
    );
  ...
                     ^
[0m15:38:23.257217 [info ] [MainThread]: 
[0m15:38:23.258214 [error] [MainThread]:   Runtime Error in model cleanissues (models\duckdb\cleanissues.sql)
  Binder Error: Table "raw_issues" does not have a column named "user"
  LINE 9:         raw_issues.user.node_i,
                  ^
[0m15:38:23.259025 [info ] [MainThread]: 
[0m15:38:23.259622 [error] [MainThread]:   Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced column "author_id" not found in FROM clause!
  Candidate bindings: "raw.node_id", "raw.created_at"
  LINE 19:     author_id,
               ^
[0m15:38:23.259622 [info ] [MainThread]: 
[0m15:38:23.260527 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m15:38:23.261525 [debug] [MainThread]: Command `dbt build` failed at 15:38:23.261525 after 1.64 seconds
[0m15:38:23.261525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BA1C9F860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BA1DEAB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018BA0E68A40>]}
[0m15:38:23.262522 [debug] [MainThread]: Flushing usage events
[0m15:38:25.176003 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:39:20.753072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A07496F4D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A078AFD7F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A078AFD490>]}


============================== 15:39:20.757156 | 5b8a5d81-599d-4db4-853d-f8e52e10edd4 ==============================
[0m15:39:20.757156 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:39:20.757744 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt build', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:39:20.967329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b8a5d81-599d-4db4-853d-f8e52e10edd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A078786BD0>]}
[0m15:39:21.024217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b8a5d81-599d-4db4-853d-f8e52e10edd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A078C76F90>]}
[0m15:39:21.028612 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:39:21.290013 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:39:21.421197 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m15:39:21.421197 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleancontributors.sql
[0m15:39:21.421197 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleanissues.sql
[0m15:39:21.422221 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleanpullrequest.sql
[0m15:39:21.663002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b8a5d81-599d-4db4-853d-f8e52e10edd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A0799C22A0>]}
[0m15:39:21.711432 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:39:21.713072 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:39:21.749386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b8a5d81-599d-4db4-853d-f8e52e10edd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A079ECC230>]}
[0m15:39:21.750369 [info ] [MainThread]: Found 4 models, 424 macros
[0m15:39:21.751959 [info ] [MainThread]: 
[0m15:39:21.752905 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:39:21.752905 [info ] [MainThread]: 
[0m15:39:21.753899 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:39:21.758312 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:39:21.839270 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:39:21.839813 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:39:21.839813 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:39:21.857547 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m15:39:21.858167 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:39:21.862188 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:39:21.862188 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:39:21.869422 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:39:21.869962 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:39:21.869962 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:39:21.885875 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:39:21.887740 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:39:21.887740 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:39:21.888738 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:39:21.888738 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:39:21.888738 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:39:21.888738 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:39:21.889771 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:39:21.890733 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:39:21.890733 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:39:21.891273 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:39:21.891273 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:39:21.896598 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:39:21.902630 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:39:21.902630 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:39:21.902630 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:39:21.919631 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m15:39:21.920543 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:39:21.920543 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:39:21.963313 [debug] [ThreadPool]: SQL status: OK in 0.042 seconds
[0m15:39:21.964309 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:39:21.965891 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:39:21.966399 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:39:21.970996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b8a5d81-599d-4db4-853d-f8e52e10edd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A079C84200>]}
[0m15:39:21.970996 [debug] [MainThread]: Using duckdb connection "master"
[0m15:39:21.970996 [debug] [MainThread]: On master: BEGIN
[0m15:39:21.971990 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:39:21.987509 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:39:21.987509 [debug] [MainThread]: On master: COMMIT
[0m15:39:21.987509 [debug] [MainThread]: Using duckdb connection "master"
[0m15:39:21.988507 [debug] [MainThread]: On master: COMMIT
[0m15:39:21.988507 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:39:21.988507 [debug] [MainThread]: On master: Close
[0m15:39:21.993494 [debug] [Thread-1 (]: Began running node model.archi.cleancommits
[0m15:39:21.993494 [info ] [Thread-1 (]: 1 of 4 START sql view model main_cleansed.cleancommits ......................... [RUN]
[0m15:39:21.994491 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommits'
[0m15:39:21.995148 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommits
[0m15:39:22.001651 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommits"
[0m15:39:22.002649 [debug] [Thread-1 (]: Began executing node model.archi.cleancommits
[0m15:39:22.031948 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommits"
[0m15:39:22.032455 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:39:22.033451 [debug] [Thread-1 (]: On model.archi.cleancommits: BEGIN
[0m15:39:22.033451 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:39:22.049154 [debug] [Thread-1 (]: SQL status: OK in 0.015 seconds
[0m15:39:22.049672 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:39:22.049672 [debug] [Thread-1 (]: On model.archi.cleancommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where message is not null  -- Filtrer les commits sans message
)

select
    id,
    author_id,
    created_at
from raw
  );

[0m15:39:22.051174 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where message is not null  -- Filtrer les commits sans message
)

select
    id,
    author_id,
    created_at
from raw
  );

[0m15:39:22.051174 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:39:22.051705 [debug] [Thread-1 (]: On model.archi.cleancommits: ROLLBACK
[0m15:39:22.056239 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommits'
[0m15:39:22.056239 [debug] [Thread-1 (]: On model.archi.cleancommits: Close
[0m15:39:22.061361 [debug] [Thread-1 (]: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 12:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^
[0m15:39:22.063865 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b8a5d81-599d-4db4-853d-f8e52e10edd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A078DB8A40>]}
[0m15:39:22.064862 [error] [Thread-1 (]: 1 of 4 ERROR creating sql view model main_cleansed.cleancommits ................ [[31mERROR[0m in 0.07s]
[0m15:39:22.064862 [debug] [Thread-1 (]: Finished running node model.archi.cleancommits
[0m15:39:22.066261 [debug] [Thread-1 (]: Began running node model.archi.cleancontributors
[0m15:39:22.066323 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommits' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 12:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^.
[0m15:39:22.067254 [info ] [Thread-1 (]: 2 of 4 START sql view model main_cleansed.cleancontributors .................... [RUN]
[0m15:39:22.067254 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommits, now model.archi.cleancontributors)
[0m15:39:22.068284 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributors
[0m15:39:22.069623 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributors"
[0m15:39:22.070925 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributors
[0m15:39:22.073434 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributors"
[0m15:39:22.074463 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:39:22.074463 [debug] [Thread-1 (]: On model.archi.cleancontributors: BEGIN
[0m15:39:22.074463 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:39:22.090094 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:39:22.091091 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:39:22.091091 [debug] [Thread-1 (]: On model.archi.cleancontributors: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        raw_contributors.html_url,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where email is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    name,
    raw_contributors.html_url
from raw
  );

[0m15:39:22.092674 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        raw_contributors.html_url,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where email is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    name,
    raw_contributors.html_url
from raw
  );

[0m15:39:22.092674 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:39:22.092674 [debug] [Thread-1 (]: On model.archi.cleancontributors: ROLLBACK
[0m15:39:22.095733 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancontributors'
[0m15:39:22.096713 [debug] [Thread-1 (]: On model.archi.cleancontributors: Close
[0m15:39:22.102204 [debug] [Thread-1 (]: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      raw_contributors.html_url
  from raw
    );
  ...
                     ^
[0m15:39:22.102775 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b8a5d81-599d-4db4-853d-f8e52e10edd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A07A52AB70>]}
[0m15:39:22.103705 [error] [Thread-1 (]: 2 of 4 ERROR creating sql view model main_cleansed.cleancontributors ........... [[31mERROR[0m in 0.04s]
[0m15:39:22.103705 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributors
[0m15:39:22.104735 [debug] [Thread-1 (]: Began running node model.archi.cleanissues
[0m15:39:22.105744 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancontributors' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      raw_contributors.html_url
  from raw
    );
  ...
                     ^.
[0m15:39:22.104735 [info ] [Thread-1 (]: 3 of 4 START sql view model main_cleansed.cleanissues .......................... [RUN]
[0m15:39:22.106312 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributors, now model.archi.cleanissues)
[0m15:39:22.106312 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissues
[0m15:39:22.109925 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissues"
[0m15:39:22.109925 [debug] [Thread-1 (]: Began executing node model.archi.cleanissues
[0m15:39:22.113380 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissues"
[0m15:39:22.113380 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:39:22.114357 [debug] [Thread-1 (]: On model.archi.cleanissues: BEGIN
[0m15:39:22.115239 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:39:22.130058 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:39:22.131069 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:39:22.131069 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_issues.user.node_i,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where title is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    raw_issues.user.node_i,
    created_at
from raw
  );

[0m15:39:22.132664 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_issues.user.node_i,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where title is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    raw_issues.user.node_i,
    created_at
from raw
  );

[0m15:39:22.132664 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:39:22.133657 [debug] [Thread-1 (]: On model.archi.cleanissues: ROLLBACK
[0m15:39:22.135899 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanissues'
[0m15:39:22.136897 [debug] [Thread-1 (]: On model.archi.cleanissues: Close
[0m15:39:22.141391 [debug] [Thread-1 (]: Runtime Error in model cleanissues (models\duckdb\cleanissues.sql)
  Binder Error: Table "raw_issues" does not have a column named "user"
  LINE 9:         raw_issues.user.node_i,
                  ^
[0m15:39:22.142534 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b8a5d81-599d-4db4-853d-f8e52e10edd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A07A4BAF90>]}
[0m15:39:22.143041 [error] [Thread-1 (]: 3 of 4 ERROR creating sql view model main_cleansed.cleanissues ................. [[31mERROR[0m in 0.04s]
[0m15:39:22.143603 [debug] [Thread-1 (]: Finished running node model.archi.cleanissues
[0m15:39:22.143603 [debug] [Thread-1 (]: Began running node model.archi.cleanpullrequest
[0m15:39:22.144543 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanissues' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanissues (models\duckdb\cleanissues.sql)
  Binder Error: Table "raw_issues" does not have a column named "user"
  LINE 9:         raw_issues.user.node_i,
                  ^.
[0m15:39:22.144543 [info ] [Thread-1 (]: 4 of 4 START sql view model main_cleansed.cleanpullrequest ..................... [RUN]
[0m15:39:22.145540 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissues, now model.archi.cleanpullrequest)
[0m15:39:22.145540 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpullrequest
[0m15:39:22.147425 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpullrequest"
[0m15:39:22.149226 [debug] [Thread-1 (]: Began executing node model.archi.cleanpullrequest
[0m15:39:22.151739 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpullrequest"
[0m15:39:22.152722 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:39:22.152722 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: BEGIN
[0m15:39:22.152722 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:39:22.169639 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:39:22.169639 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:39:22.170637 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_pull_requests.node_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where title is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    raw_pull_requests.node_id,
    created_at
from raw
  );

[0m15:39:22.171185 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_pull_requests.node_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where title is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    raw_pull_requests.node_id,
    created_at
from raw
  );

[0m15:39:22.172139 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:39:22.172139 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: ROLLBACK
[0m15:39:22.175675 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanpullrequest'
[0m15:39:22.175675 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: Close
[0m15:39:22.180717 [debug] [Thread-1 (]: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^
[0m15:39:22.181721 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b8a5d81-599d-4db4-853d-f8e52e10edd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A07A4B4650>]}
[0m15:39:22.182751 [error] [Thread-1 (]: 4 of 4 ERROR creating sql view model main_cleansed.cleanpullrequest ............ [[31mERROR[0m in 0.04s]
[0m15:39:22.182751 [debug] [Thread-1 (]: Finished running node model.archi.cleanpullrequest
[0m15:39:22.183745 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanpullrequest' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^.
[0m15:39:22.185017 [debug] [MainThread]: Using duckdb connection "master"
[0m15:39:22.185017 [debug] [MainThread]: On master: BEGIN
[0m15:39:22.185017 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:39:22.201575 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:39:22.201575 [debug] [MainThread]: On master: COMMIT
[0m15:39:22.202572 [debug] [MainThread]: Using duckdb connection "master"
[0m15:39:22.202572 [debug] [MainThread]: On master: COMMIT
[0m15:39:22.202572 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:39:22.203570 [debug] [MainThread]: On master: Close
[0m15:39:22.206768 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:39:22.206768 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:39:22.206768 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:39:22.206768 [debug] [MainThread]: Connection 'model.archi.cleanpullrequest' was properly closed.
[0m15:39:22.207765 [info ] [MainThread]: 
[0m15:39:22.207765 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 0.45 seconds (0.45s).
[0m15:39:22.209764 [debug] [MainThread]: Command end result
[0m15:39:22.225701 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:39:22.227029 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:39:22.232990 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:39:22.233937 [info ] [MainThread]: 
[0m15:39:22.233937 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m15:39:22.234934 [info ] [MainThread]: 
[0m15:39:22.234934 [error] [MainThread]:   Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 12:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^
[0m15:39:22.236527 [info ] [MainThread]: 
[0m15:39:22.236527 [error] [MainThread]:   Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      raw_contributors.html_url
  from raw
    );
  ...
                     ^
[0m15:39:22.237469 [info ] [MainThread]: 
[0m15:39:22.238435 [error] [MainThread]:   Runtime Error in model cleanissues (models\duckdb\cleanissues.sql)
  Binder Error: Table "raw_issues" does not have a column named "user"
  LINE 9:         raw_issues.user.node_i,
                  ^
[0m15:39:22.238435 [info ] [MainThread]: 
[0m15:39:22.239433 [error] [MainThread]:   Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^
[0m15:39:22.239940 [info ] [MainThread]: 
[0m15:39:22.240483 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m15:39:22.241510 [debug] [MainThread]: Command `dbt build` failed at 15:39:22.241510 after 1.60 seconds
[0m15:39:22.241510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A078BEA7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A078C03DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A078C00200>]}
[0m15:39:22.242504 [debug] [MainThread]: Flushing usage events
[0m15:39:23.115160 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:40:22.704940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3CEF7290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3D2B95E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3DC46FC0>]}


============================== 15:40:22.708780 | 6be22791-696a-4aa7-86ab-9731cce3f860 ==============================
[0m15:40:22.708780 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:40:22.709777 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:40:22.918053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6be22791-696a-4aa7-86ab-9731cce3f860', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3CF282F0>]}
[0m15:40:22.975853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6be22791-696a-4aa7-86ab-9731cce3f860', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3A69B2C0>]}
[0m15:40:22.979416 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:40:23.235218 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:40:23.365509 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:40:23.365509 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:40:23.390381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6be22791-696a-4aa7-86ab-9731cce3f860', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3E5B9430>]}
[0m15:40:23.441078 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:40:23.442161 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:40:23.478075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6be22791-696a-4aa7-86ab-9731cce3f860', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3F0414F0>]}
[0m15:40:23.478075 [info ] [MainThread]: Found 4 models, 424 macros
[0m15:40:23.481147 [info ] [MainThread]: 
[0m15:40:23.481147 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:40:23.482064 [info ] [MainThread]: 
[0m15:40:23.482064 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:40:23.486312 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:40:23.571899 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:40:23.572894 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:40:23.572894 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:40:23.590572 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:40:23.591973 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:40:23.595068 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:40:23.596417 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:40:23.602322 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:40:23.602890 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:40:23.603399 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:40:23.619373 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:40:23.619883 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:40:23.620875 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:40:23.621480 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:40:23.621988 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:40:23.621988 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:40:23.621988 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:40:23.622984 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:40:23.623988 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:40:23.623988 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:40:23.624496 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:40:23.625004 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:40:23.629085 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:40:23.634180 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:40:23.634688 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:40:23.635195 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:40:23.650468 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:40:23.650468 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:40:23.651466 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:40:23.694398 [debug] [ThreadPool]: SQL status: OK in 0.043 seconds
[0m15:40:23.695480 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:40:23.696510 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:40:23.696510 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:40:23.700777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6be22791-696a-4aa7-86ab-9731cce3f860', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3E524B00>]}
[0m15:40:23.701843 [debug] [MainThread]: Using duckdb connection "master"
[0m15:40:23.702352 [debug] [MainThread]: On master: BEGIN
[0m15:40:23.702352 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:40:23.718283 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:40:23.719208 [debug] [MainThread]: On master: COMMIT
[0m15:40:23.719208 [debug] [MainThread]: Using duckdb connection "master"
[0m15:40:23.719208 [debug] [MainThread]: On master: COMMIT
[0m15:40:23.720222 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:40:23.720222 [debug] [MainThread]: On master: Close
[0m15:40:23.725169 [debug] [Thread-1 (]: Began running node model.archi.cleancommits
[0m15:40:23.726108 [info ] [Thread-1 (]: 1 of 4 START sql view model main_cleansed.cleancommits ......................... [RUN]
[0m15:40:23.726108 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommits'
[0m15:40:23.727106 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommits
[0m15:40:23.734106 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommits"
[0m15:40:23.735100 [debug] [Thread-1 (]: Began executing node model.archi.cleancommits
[0m15:40:23.765886 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommits"
[0m15:40:23.766866 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:40:23.766866 [debug] [Thread-1 (]: On model.archi.cleancommits: BEGIN
[0m15:40:23.767946 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:40:23.783497 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:40:23.783497 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:40:23.784495 [debug] [Thread-1 (]: On model.archi.cleancommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where message is not null  -- Filtrer les commits sans message
)

select
    id,
    author_id,
    created_at
from raw
  );

[0m15:40:23.785523 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where message is not null  -- Filtrer les commits sans message
)

select
    id,
    author_id,
    created_at
from raw
  );

[0m15:40:23.786081 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:40:23.786704 [debug] [Thread-1 (]: On model.archi.cleancommits: ROLLBACK
[0m15:40:23.791648 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommits'
[0m15:40:23.792264 [debug] [Thread-1 (]: On model.archi.cleancommits: Close
[0m15:40:23.797808 [debug] [Thread-1 (]: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 12:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^
[0m15:40:23.799314 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6be22791-696a-4aa7-86ab-9731cce3f860', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3CED2F60>]}
[0m15:40:23.799314 [error] [Thread-1 (]: 1 of 4 ERROR creating sql view model main_cleansed.cleancommits ................ [[31mERROR[0m in 0.07s]
[0m15:40:23.801000 [debug] [Thread-1 (]: Finished running node model.archi.cleancommits
[0m15:40:23.801000 [debug] [Thread-1 (]: Began running node model.archi.cleancontributors
[0m15:40:23.801567 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommits' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 12:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^.
[0m15:40:23.801567 [info ] [Thread-1 (]: 2 of 4 START sql view model main_cleansed.cleancontributors .................... [RUN]
[0m15:40:23.802502 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommits, now model.archi.cleancontributors)
[0m15:40:23.802502 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributors
[0m15:40:23.806001 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributors"
[0m15:40:23.806690 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributors
[0m15:40:23.809602 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributors"
[0m15:40:23.810168 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:40:23.810168 [debug] [Thread-1 (]: On model.archi.cleancontributors: BEGIN
[0m15:40:23.810168 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:40:23.826832 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:40:23.827830 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:40:23.827830 [debug] [Thread-1 (]: On model.archi.cleancontributors: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        raw_contributors.html_url,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where email is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    name,
    raw_contributors.html_url
from raw
  );

[0m15:40:23.828906 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        raw_contributors.html_url,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where email is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    name,
    raw_contributors.html_url
from raw
  );

[0m15:40:23.828906 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:40:23.829824 [debug] [Thread-1 (]: On model.archi.cleancontributors: ROLLBACK
[0m15:40:23.832834 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancontributors'
[0m15:40:23.832834 [debug] [Thread-1 (]: On model.archi.cleancontributors: Close
[0m15:40:23.838888 [debug] [Thread-1 (]: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      raw_contributors.html_url
  from raw
    );
  ...
                     ^
[0m15:40:23.838888 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6be22791-696a-4aa7-86ab-9731cce3f860', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3F68FE60>]}
[0m15:40:23.839881 [error] [Thread-1 (]: 2 of 4 ERROR creating sql view model main_cleansed.cleancontributors ........... [[31mERROR[0m in 0.04s]
[0m15:40:23.840879 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributors
[0m15:40:23.841539 [debug] [Thread-1 (]: Began running node model.archi.cleanissues
[0m15:40:23.842382 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancontributors' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      raw_contributors.html_url
  from raw
    );
  ...
                     ^.
[0m15:40:23.841539 [info ] [Thread-1 (]: 3 of 4 START sql view model main_cleansed.cleanissues .......................... [RUN]
[0m15:40:23.842382 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributors, now model.archi.cleanissues)
[0m15:40:23.843379 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissues
[0m15:40:23.845463 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissues"
[0m15:40:23.845463 [debug] [Thread-1 (]: Began executing node model.archi.cleanissues
[0m15:40:23.848686 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissues"
[0m15:40:23.848686 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:40:23.849586 [debug] [Thread-1 (]: On model.archi.cleanissues: BEGIN
[0m15:40:23.849586 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:40:23.865754 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:40:23.865771 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:40:23.865771 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_issues.user.node_i,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where title is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    raw_issues.user.node_i,
    created_at
from raw
  );

[0m15:40:23.866754 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_issues.user.node_i,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where title is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    raw_issues.user.node_i,
    created_at
from raw
  );

[0m15:40:23.867752 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:40:23.867752 [debug] [Thread-1 (]: On model.archi.cleanissues: ROLLBACK
[0m15:40:23.871329 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanissues'
[0m15:40:23.871329 [debug] [Thread-1 (]: On model.archi.cleanissues: Close
[0m15:40:23.876867 [debug] [Thread-1 (]: Runtime Error in model cleanissues (models\duckdb\cleanissues.sql)
  Binder Error: Table "raw_issues" does not have a column named "user"
  LINE 9:         raw_issues.user.node_i,
                  ^
[0m15:40:23.877788 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6be22791-696a-4aa7-86ab-9731cce3f860', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3F79BC80>]}
[0m15:40:23.877788 [error] [Thread-1 (]: 3 of 4 ERROR creating sql view model main_cleansed.cleanissues ................. [[31mERROR[0m in 0.04s]
[0m15:40:23.879368 [debug] [Thread-1 (]: Finished running node model.archi.cleanissues
[0m15:40:23.879368 [debug] [Thread-1 (]: Began running node model.archi.cleanpullrequest
[0m15:40:23.879925 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanissues' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanissues (models\duckdb\cleanissues.sql)
  Binder Error: Table "raw_issues" does not have a column named "user"
  LINE 9:         raw_issues.user.node_i,
                  ^.
[0m15:40:23.879925 [info ] [Thread-1 (]: 4 of 4 START sql view model main_cleansed.cleanpullrequest ..................... [RUN]
[0m15:40:23.880870 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissues, now model.archi.cleanpullrequest)
[0m15:40:23.880870 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpullrequest
[0m15:40:23.883373 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpullrequest"
[0m15:40:23.883373 [debug] [Thread-1 (]: Began executing node model.archi.cleanpullrequest
[0m15:40:23.885870 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpullrequest"
[0m15:40:23.886867 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:40:23.886867 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: BEGIN
[0m15:40:23.887866 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:40:23.903765 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:40:23.904274 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:40:23.904780 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_pull_requests.node_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where title is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    raw_pull_requests.node_id,
    created_at
from raw
  );

[0m15:40:23.905799 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_pull_requests.node_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where title is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    raw_pull_requests.node_id,
    created_at
from raw
  );

[0m15:40:23.906795 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:40:23.907379 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: ROLLBACK
[0m15:40:23.910392 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanpullrequest'
[0m15:40:23.910392 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: Close
[0m15:40:23.915909 [debug] [Thread-1 (]: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^
[0m15:40:23.916417 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6be22791-696a-4aa7-86ab-9731cce3f860', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3F7B2CC0>]}
[0m15:40:23.916417 [error] [Thread-1 (]: 4 of 4 ERROR creating sql view model main_cleansed.cleanpullrequest ............ [[31mERROR[0m in 0.04s]
[0m15:40:23.917412 [debug] [Thread-1 (]: Finished running node model.archi.cleanpullrequest
[0m15:40:23.917412 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanpullrequest' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^.
[0m15:40:23.918608 [debug] [MainThread]: Using duckdb connection "master"
[0m15:40:23.919602 [debug] [MainThread]: On master: BEGIN
[0m15:40:23.919602 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:40:23.935269 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:40:23.935269 [debug] [MainThread]: On master: COMMIT
[0m15:40:23.935269 [debug] [MainThread]: Using duckdb connection "master"
[0m15:40:23.936267 [debug] [MainThread]: On master: COMMIT
[0m15:40:23.936267 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:40:23.936267 [debug] [MainThread]: On master: Close
[0m15:40:23.940488 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:40:23.940488 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:40:23.941405 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:40:23.941405 [debug] [MainThread]: Connection 'model.archi.cleanpullrequest' was properly closed.
[0m15:40:23.941405 [info ] [MainThread]: 
[0m15:40:23.942402 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m15:40:23.943519 [debug] [MainThread]: Command end result
[0m15:40:23.960091 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:40:23.962117 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:40:23.967750 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:40:23.968395 [info ] [MainThread]: 
[0m15:40:23.968395 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m15:40:23.969326 [info ] [MainThread]: 
[0m15:40:23.969326 [error] [MainThread]:   Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 12:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^
[0m15:40:23.970314 [info ] [MainThread]: 
[0m15:40:23.971281 [error] [MainThread]:   Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      raw_contributors.html_url
  from raw
    );
  ...
                     ^
[0m15:40:23.971793 [info ] [MainThread]: 
[0m15:40:23.972785 [error] [MainThread]:   Runtime Error in model cleanissues (models\duckdb\cleanissues.sql)
  Binder Error: Table "raw_issues" does not have a column named "user"
  LINE 9:         raw_issues.user.node_i,
                  ^
[0m15:40:23.973783 [info ] [MainThread]: 
[0m15:40:23.973783 [error] [MainThread]:   Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^
[0m15:40:23.974780 [info ] [MainThread]: 
[0m15:40:23.974780 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
[0m15:40:23.975879 [debug] [MainThread]: Command `dbt build` failed at 15:40:23.975879 after 1.42 seconds
[0m15:40:23.976822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3E1EAB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3E1EACF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F3E1EA7B0>]}
[0m15:40:23.976822 [debug] [MainThread]: Flushing usage events
[0m15:40:25.135614 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:40:59.063574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD676FEC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD676EED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD676E660>]}


============================== 15:40:59.067076 | 8b3aa0de-5ea4-4bdc-ab12-c0529a3f11af ==============================
[0m15:40:59.067076 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:40:59.067644 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt build', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:40:59.278104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8b3aa0de-5ea4-4bdc-ab12-c0529a3f11af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD6E77680>]}
[0m15:40:59.337347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8b3aa0de-5ea4-4bdc-ab12-c0529a3f11af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD6EAA570>]}
[0m15:40:59.341281 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:40:59.605715 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:40:59.725179 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:40:59.726203 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleanissues.sql
[0m15:40:59.963216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8b3aa0de-5ea4-4bdc-ab12-c0529a3f11af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD7E33F50>]}
[0m15:41:00.011335 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:41:00.013892 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:41:00.049585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8b3aa0de-5ea4-4bdc-ab12-c0529a3f11af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD7FE50A0>]}
[0m15:41:00.049585 [info ] [MainThread]: Found 4 models, 424 macros
[0m15:41:00.052086 [info ] [MainThread]: 
[0m15:41:00.052086 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:41:00.053082 [info ] [MainThread]: 
[0m15:41:00.053082 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:41:00.058514 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:41:00.140697 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:41:00.140697 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:41:00.140697 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:41:00.159239 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:41:00.159802 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:41:00.163816 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:41:00.164359 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:41:00.170451 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:41:00.170451 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:41:00.170451 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:41:00.186914 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:41:00.187910 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:41:00.187910 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:41:00.188906 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:41:00.188906 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:41:00.189966 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:41:00.190475 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:41:00.190994 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:41:00.191978 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:41:00.191978 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:41:00.191978 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:41:00.192976 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:41:00.196484 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:41:00.201573 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:41:00.201573 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:41:00.201573 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:41:00.217722 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:41:00.217722 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:41:00.218719 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:41:00.261303 [debug] [ThreadPool]: SQL status: OK in 0.042 seconds
[0m15:41:00.262448 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:41:00.263543 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:41:00.263543 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:41:00.267676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8b3aa0de-5ea4-4bdc-ab12-c0529a3f11af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD6EEF1D0>]}
[0m15:41:00.268963 [debug] [MainThread]: Using duckdb connection "master"
[0m15:41:00.268963 [debug] [MainThread]: On master: BEGIN
[0m15:41:00.268963 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:41:00.284442 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:41:00.285439 [debug] [MainThread]: On master: COMMIT
[0m15:41:00.285439 [debug] [MainThread]: Using duckdb connection "master"
[0m15:41:00.286073 [debug] [MainThread]: On master: COMMIT
[0m15:41:00.286615 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:41:00.286615 [debug] [MainThread]: On master: Close
[0m15:41:00.292079 [debug] [Thread-1 (]: Began running node model.archi.cleancommits
[0m15:41:00.292079 [info ] [Thread-1 (]: 1 of 4 START sql view model main_cleansed.cleancommits ......................... [RUN]
[0m15:41:00.292964 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommits'
[0m15:41:00.292964 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommits
[0m15:41:00.299975 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommits"
[0m15:41:00.300972 [debug] [Thread-1 (]: Began executing node model.archi.cleancommits
[0m15:41:00.330694 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommits"
[0m15:41:00.331690 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:41:00.331690 [debug] [Thread-1 (]: On model.archi.cleancommits: BEGIN
[0m15:41:00.331690 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:41:00.347247 [debug] [Thread-1 (]: SQL status: OK in 0.015 seconds
[0m15:41:00.348275 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:41:00.348275 [debug] [Thread-1 (]: On model.archi.cleancommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where message is not null  -- Filtrer les commits sans message
)

select
    id,
    author_id,
    created_at
from raw
  );

[0m15:41:00.349818 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where message is not null  -- Filtrer les commits sans message
)

select
    id,
    author_id,
    created_at
from raw
  );

[0m15:41:00.349818 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:41:00.350362 [debug] [Thread-1 (]: On model.archi.cleancommits: ROLLBACK
[0m15:41:00.354725 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommits'
[0m15:41:00.354725 [debug] [Thread-1 (]: On model.archi.cleancommits: Close
[0m15:41:00.361072 [debug] [Thread-1 (]: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 12:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^
[0m15:41:00.363102 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b3aa0de-5ea4-4bdc-ab12-c0529a3f11af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD86A4B00>]}
[0m15:41:00.363644 [error] [Thread-1 (]: 1 of 4 ERROR creating sql view model main_cleansed.cleancommits ................ [[31mERROR[0m in 0.07s]
[0m15:41:00.364637 [debug] [Thread-1 (]: Finished running node model.archi.cleancommits
[0m15:41:00.364637 [debug] [Thread-1 (]: Began running node model.archi.cleancontributors
[0m15:41:00.365645 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommits' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 12:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^.
[0m15:41:00.364637 [info ] [Thread-1 (]: 2 of 4 START sql view model main_cleansed.cleancontributors .................... [RUN]
[0m15:41:00.366382 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommits, now model.archi.cleancontributors)
[0m15:41:00.366891 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributors
[0m15:41:00.368396 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributors"
[0m15:41:00.369909 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributors
[0m15:41:00.372428 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributors"
[0m15:41:00.373425 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:41:00.373991 [debug] [Thread-1 (]: On model.archi.cleancontributors: BEGIN
[0m15:41:00.373991 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:41:00.390230 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:41:00.390776 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:41:00.390776 [debug] [Thread-1 (]: On model.archi.cleancontributors: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        raw_contributors.html_url,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where email is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    name,
    raw_contributors.html_url
from raw
  );

[0m15:41:00.391800 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        raw_contributors.html_url,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where email is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    name,
    raw_contributors.html_url
from raw
  );

[0m15:41:00.392430 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:41:00.392981 [debug] [Thread-1 (]: On model.archi.cleancontributors: ROLLBACK
[0m15:41:00.396006 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancontributors'
[0m15:41:00.396006 [debug] [Thread-1 (]: On model.archi.cleancontributors: Close
[0m15:41:00.401736 [debug] [Thread-1 (]: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      raw_contributors.html_url
  from raw
    );
  ...
                     ^
[0m15:41:00.402376 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b3aa0de-5ea4-4bdc-ab12-c0529a3f11af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD86A8950>]}
[0m15:41:00.402968 [error] [Thread-1 (]: 2 of 4 ERROR creating sql view model main_cleansed.cleancontributors ........... [[31mERROR[0m in 0.04s]
[0m15:41:00.403479 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributors
[0m15:41:00.404502 [debug] [Thread-1 (]: Began running node model.archi.cleanissues
[0m15:41:00.404502 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancontributors' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      raw_contributors.html_url
  from raw
    );
  ...
                     ^.
[0m15:41:00.404502 [info ] [Thread-1 (]: 3 of 4 START sql view model main_cleansed.cleanissues .......................... [RUN]
[0m15:41:00.405661 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributors, now model.archi.cleanissues)
[0m15:41:00.405661 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissues
[0m15:41:00.408653 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissues"
[0m15:41:00.409223 [debug] [Thread-1 (]: Began executing node model.archi.cleanissues
[0m15:41:00.412729 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissues"
[0m15:41:00.413658 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:41:00.413658 [debug] [Thread-1 (]: On model.archi.cleanissues: BEGIN
[0m15:41:00.414655 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:41:00.430284 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:41:00.431283 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:41:00.431283 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where title is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    created_at
from raw
  );

[0m15:41:00.431793 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:41:00.437801 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:41:00.438378 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */
alter view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" rename to "cleanissues"
[0m15:41:00.438378 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:41:00.447797 [debug] [Thread-1 (]: On model.archi.cleanissues: COMMIT
[0m15:41:00.448821 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:41:00.448821 [debug] [Thread-1 (]: On model.archi.cleanissues: COMMIT
[0m15:41:00.451423 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m15:41:00.456437 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:41:00.457286 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissues__dbt_backup" cascade
[0m15:41:00.457795 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:41:00.459795 [debug] [Thread-1 (]: On model.archi.cleanissues: Close
[0m15:41:00.493356 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b3aa0de-5ea4-4bdc-ab12-c0529a3f11af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD3209850>]}
[0m15:41:00.493881 [info ] [Thread-1 (]: 3 of 4 OK created sql view model main_cleansed.cleanissues ..................... [[32mOK[0m in 0.09s]
[0m15:41:00.494861 [debug] [Thread-1 (]: Finished running node model.archi.cleanissues
[0m15:41:00.494861 [debug] [Thread-1 (]: Began running node model.archi.cleanpullrequest
[0m15:41:00.494861 [info ] [Thread-1 (]: 4 of 4 START sql view model main_cleansed.cleanpullrequest ..................... [RUN]
[0m15:41:00.496378 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissues, now model.archi.cleanpullrequest)
[0m15:41:00.496378 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpullrequest
[0m15:41:00.498457 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpullrequest"
[0m15:41:00.499453 [debug] [Thread-1 (]: Began executing node model.archi.cleanpullrequest
[0m15:41:00.502177 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpullrequest"
[0m15:41:00.503172 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:41:00.503172 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: BEGIN
[0m15:41:00.503172 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:41:00.525164 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m15:41:00.525672 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:41:00.525672 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_pull_requests.node_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where title is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    raw_pull_requests.node_id,
    created_at
from raw
  );

[0m15:41:00.526667 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_pull_requests.node_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where title is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    raw_pull_requests.node_id,
    created_at
from raw
  );

[0m15:41:00.527425 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:41:00.527933 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: ROLLBACK
[0m15:41:00.530390 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanpullrequest'
[0m15:41:00.530390 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: Close
[0m15:41:00.535886 [debug] [Thread-1 (]: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^
[0m15:41:00.535886 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b3aa0de-5ea4-4bdc-ab12-c0529a3f11af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD8622690>]}
[0m15:41:00.536884 [error] [Thread-1 (]: 4 of 4 ERROR creating sql view model main_cleansed.cleanpullrequest ............ [[31mERROR[0m in 0.04s]
[0m15:41:00.537943 [debug] [Thread-1 (]: Finished running node model.archi.cleanpullrequest
[0m15:41:00.538038 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanpullrequest' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^.
[0m15:41:00.538943 [debug] [MainThread]: Using duckdb connection "master"
[0m15:41:00.539948 [debug] [MainThread]: On master: BEGIN
[0m15:41:00.539948 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:41:00.556574 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:41:00.556574 [debug] [MainThread]: On master: COMMIT
[0m15:41:00.557572 [debug] [MainThread]: Using duckdb connection "master"
[0m15:41:00.557572 [debug] [MainThread]: On master: COMMIT
[0m15:41:00.557572 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:41:00.558569 [debug] [MainThread]: On master: Close
[0m15:41:00.561573 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:41:00.561573 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:41:00.561573 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:41:00.562564 [debug] [MainThread]: Connection 'model.archi.cleanpullrequest' was properly closed.
[0m15:41:00.562564 [info ] [MainThread]: 
[0m15:41:00.563073 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 0.51 seconds (0.51s).
[0m15:41:00.564607 [debug] [MainThread]: Command end result
[0m15:41:00.581694 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:41:00.583626 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:41:00.590617 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:41:00.590617 [info ] [MainThread]: 
[0m15:41:00.591605 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m15:41:00.591605 [info ] [MainThread]: 
[0m15:41:00.592665 [error] [MainThread]:   Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 12:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^
[0m15:41:00.593174 [info ] [MainThread]: 
[0m15:41:00.594094 [error] [MainThread]:   Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "email" not found in FROM clause!
  Candidate bindings: "raw_contributors.html_url", "raw_contributors.site_admin", "raw_contributors.user_view_type", "raw_contributors.organizations_url", "raw_contributors.received_events_url"
  LINE 12:     where email is not null  -- Filtrer les contributeurs sans email
  )
  
  select
      id,
      name,
      raw_contributors.html_url
  from raw
    );
  ...
                     ^
[0m15:41:00.594638 [info ] [MainThread]: 
[0m15:41:00.595147 [error] [MainThread]:   Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^
[0m15:41:00.596140 [info ] [MainThread]: 
[0m15:41:00.596140 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=3 SKIP=0 TOTAL=4
[0m15:41:00.597403 [debug] [MainThread]: Command `dbt build` failed at 15:41:00.597403 after 1.65 seconds
[0m15:41:00.597403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD6CFD8E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD6CFEB70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EAD6CFC8C0>]}
[0m15:41:00.598398 [debug] [MainThread]: Flushing usage events
[0m15:41:01.363513 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:41:54.539823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020234BE3A40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020238B49DF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020238B4A300>]}


============================== 15:41:54.544316 | ff4ceb49-7475-46c6-8884-5f5ea4ee6f8f ==============================
[0m15:41:54.544316 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:41:54.544825 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt build', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:41:54.756267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ff4ceb49-7475-46c6-8884-5f5ea4ee6f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020237F241A0>]}
[0m15:41:54.814097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ff4ceb49-7475-46c6-8884-5f5ea4ee6f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202395B5040>]}
[0m15:41:54.818167 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:41:55.072815 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:41:55.201707 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m15:41:55.202213 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleancommits.sql
[0m15:41:55.202213 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleancontributors.sql
[0m15:41:55.444945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ff4ceb49-7475-46c6-8884-5f5ea4ee6f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023A232B70>]}
[0m15:41:55.492794 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:41:55.494840 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:41:55.530597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ff4ceb49-7475-46c6-8884-5f5ea4ee6f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023A4D0710>]}
[0m15:41:55.530597 [info ] [MainThread]: Found 4 models, 424 macros
[0m15:41:55.532785 [info ] [MainThread]: 
[0m15:41:55.532785 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:41:55.533777 [info ] [MainThread]: 
[0m15:41:55.534612 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:41:55.539082 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:41:55.619989 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:41:55.620997 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:41:55.621570 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:41:55.640659 [debug] [ThreadPool]: SQL status: OK in 0.019 seconds
[0m15:41:55.642225 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:41:55.645823 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:41:55.645823 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:41:55.651882 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:41:55.651882 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:41:55.652463 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:41:55.668329 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:41:55.669327 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:41:55.669327 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:41:55.670292 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:41:55.670292 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:41:55.671297 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:41:55.671862 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:41:55.672863 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:41:55.673413 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:41:55.673413 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:41:55.673924 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:41:55.673924 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:41:55.678864 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:41:55.683551 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:41:55.683551 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:41:55.683551 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:41:55.700189 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:41:55.700189 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:41:55.700189 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:41:55.742344 [debug] [ThreadPool]: SQL status: OK in 0.041 seconds
[0m15:41:55.743345 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:41:55.744343 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:41:55.744983 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:41:55.749095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ff4ceb49-7475-46c6-8884-5f5ea4ee6f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023A29C650>]}
[0m15:41:55.749095 [debug] [MainThread]: Using duckdb connection "master"
[0m15:41:55.750123 [debug] [MainThread]: On master: BEGIN
[0m15:41:55.750123 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:41:55.766417 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:41:55.766417 [debug] [MainThread]: On master: COMMIT
[0m15:41:55.766417 [debug] [MainThread]: Using duckdb connection "master"
[0m15:41:55.767414 [debug] [MainThread]: On master: COMMIT
[0m15:41:55.767478 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:41:55.767478 [debug] [MainThread]: On master: Close
[0m15:41:55.772401 [debug] [Thread-1 (]: Began running node model.archi.cleancommits
[0m15:41:55.773398 [info ] [Thread-1 (]: 1 of 4 START sql view model main_cleansed.cleancommits ......................... [RUN]
[0m15:41:55.773398 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommits'
[0m15:41:55.774405 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommits
[0m15:41:55.780895 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommits"
[0m15:41:55.781401 [debug] [Thread-1 (]: Began executing node model.archi.cleancommits
[0m15:41:55.811661 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommits"
[0m15:41:55.812659 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:41:55.812659 [debug] [Thread-1 (]: On model.archi.cleancommits: BEGIN
[0m15:41:55.813657 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:41:55.829517 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:41:55.830514 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:41:55.830514 [debug] [Thread-1 (]: On model.archi.cleancommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where id is not null  -- Filtrer les commits sans message
)

select
    id,
    author_id,
    created_at
from raw
  );

[0m15:41:55.832112 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where id is not null  -- Filtrer les commits sans message
)

select
    id,
    author_id,
    created_at
from raw
  );

[0m15:41:55.832112 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:41:55.833027 [debug] [Thread-1 (]: On model.archi.cleancommits: ROLLBACK
[0m15:41:55.837541 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommits'
[0m15:41:55.838463 [debug] [Thread-1 (]: On model.archi.cleancommits: Close
[0m15:41:55.844029 [debug] [Thread-1 (]: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "id" not found in FROM clause!
  Candidate bindings: "raw_commits.committer.id", "raw_commits.node_id"
  LINE 12:     where id is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^
[0m15:41:55.845023 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff4ceb49-7475-46c6-8884-5f5ea4ee6f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020237ECBAA0>]}
[0m15:41:55.845023 [error] [Thread-1 (]: 1 of 4 ERROR creating sql view model main_cleansed.cleancommits ................ [[31mERROR[0m in 0.07s]
[0m15:41:55.846342 [debug] [Thread-1 (]: Finished running node model.archi.cleancommits
[0m15:41:55.847348 [debug] [Thread-1 (]: Began running node model.archi.cleancontributors
[0m15:41:55.847974 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommits' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "id" not found in FROM clause!
  Candidate bindings: "raw_commits.committer.id", "raw_commits.node_id"
  LINE 12:     where id is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^.
[0m15:41:55.847348 [info ] [Thread-1 (]: 2 of 4 START sql view model main_cleansed.cleancontributors .................... [RUN]
[0m15:41:55.848516 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommits, now model.archi.cleancontributors)
[0m15:41:55.848516 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributors
[0m15:41:55.851087 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributors"
[0m15:41:55.851628 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributors
[0m15:41:55.855145 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributors"
[0m15:41:55.855652 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:41:55.855652 [debug] [Thread-1 (]: On model.archi.cleancontributors: BEGIN
[0m15:41:55.856679 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:41:55.871702 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:41:55.872699 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:41:55.872699 [debug] [Thread-1 (]: On model.archi.cleancontributors: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        raw_contributors.html_url,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where raw_contributors.html_url is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    name,
    raw_contributors.html_url
from raw
  );

[0m15:41:55.873696 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        raw_contributors.html_url,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where raw_contributors.html_url is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    name,
    raw_contributors.html_url
from raw
  );

[0m15:41:55.874702 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:41:55.874702 [debug] [Thread-1 (]: On model.archi.cleancontributors: ROLLBACK
[0m15:41:55.877194 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancontributors'
[0m15:41:55.878191 [debug] [Thread-1 (]: On model.archi.cleancontributors: Close
[0m15:41:55.883683 [debug] [Thread-1 (]: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "name" not found in FROM clause!
  Candidate bindings: "raw_contributors.node_id", "raw_contributors.starred_url", "raw_contributors.type"
  LINE 8:         name,
                  ^
[0m15:41:55.883683 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff4ceb49-7475-46c6-8884-5f5ea4ee6f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023AB2AD80>]}
[0m15:41:55.884681 [error] [Thread-1 (]: 2 of 4 ERROR creating sql view model main_cleansed.cleancontributors ........... [[31mERROR[0m in 0.04s]
[0m15:41:55.885803 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributors
[0m15:41:55.885803 [debug] [Thread-1 (]: Began running node model.archi.cleanissues
[0m15:41:55.886310 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancontributors' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "name" not found in FROM clause!
  Candidate bindings: "raw_contributors.node_id", "raw_contributors.starred_url", "raw_contributors.type"
  LINE 8:         name,
                  ^.
[0m15:41:55.886310 [info ] [Thread-1 (]: 3 of 4 START sql view model main_cleansed.cleanissues .......................... [RUN]
[0m15:41:55.887306 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributors, now model.archi.cleanissues)
[0m15:41:55.887306 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissues
[0m15:41:55.889826 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissues"
[0m15:41:55.890823 [debug] [Thread-1 (]: Began executing node model.archi.cleanissues
[0m15:41:55.894969 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissues"
[0m15:41:55.895963 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:41:55.895963 [debug] [Thread-1 (]: On model.archi.cleanissues: BEGIN
[0m15:41:55.895963 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:41:55.912156 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:41:55.912156 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:41:55.913154 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where title is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    created_at
from raw
  );

[0m15:41:55.913154 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:41:55.919407 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:41:55.919407 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */
alter view "pytorch_data"."main_cleansed"."cleanissues" rename to "cleanissues__dbt_backup"
[0m15:41:55.920319 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:41:55.922314 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:41:55.923341 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */
alter view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" rename to "cleanissues"
[0m15:41:55.923341 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:41:55.935478 [debug] [Thread-1 (]: On model.archi.cleanissues: COMMIT
[0m15:41:55.935478 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:41:55.935987 [debug] [Thread-1 (]: On model.archi.cleanissues: COMMIT
[0m15:41:55.938976 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:41:55.944201 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:41:55.944201 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissues__dbt_backup" cascade
[0m15:41:55.945810 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:41:55.947800 [debug] [Thread-1 (]: On model.archi.cleanissues: Close
[0m15:41:55.981825 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff4ceb49-7475-46c6-8884-5f5ea4ee6f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023AB2A540>]}
[0m15:41:55.982822 [info ] [Thread-1 (]: 3 of 4 OK created sql view model main_cleansed.cleanissues ..................... [[32mOK[0m in 0.09s]
[0m15:41:55.983819 [debug] [Thread-1 (]: Finished running node model.archi.cleanissues
[0m15:41:55.983819 [debug] [Thread-1 (]: Began running node model.archi.cleanpullrequest
[0m15:41:55.984816 [info ] [Thread-1 (]: 4 of 4 START sql view model main_cleansed.cleanpullrequest ..................... [RUN]
[0m15:41:55.984816 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissues, now model.archi.cleanpullrequest)
[0m15:41:55.985814 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpullrequest
[0m15:41:55.987997 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpullrequest"
[0m15:41:55.988937 [debug] [Thread-1 (]: Began executing node model.archi.cleanpullrequest
[0m15:41:55.990933 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpullrequest"
[0m15:41:55.991990 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:41:55.991990 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: BEGIN
[0m15:41:55.992928 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:41:56.013186 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m15:41:56.014173 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:41:56.014774 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_pull_requests.node_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where title is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    raw_pull_requests.node_id,
    created_at
from raw
  );

[0m15:41:56.015407 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_pull_requests.node_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where title is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    raw_pull_requests.node_id,
    created_at
from raw
  );

[0m15:41:56.016339 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:41:56.016339 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: ROLLBACK
[0m15:41:56.018847 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanpullrequest'
[0m15:41:56.019909 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: Close
[0m15:41:56.025122 [debug] [Thread-1 (]: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^
[0m15:41:56.025122 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff4ceb49-7475-46c6-8884-5f5ea4ee6f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023AB511C0>]}
[0m15:41:56.026115 [error] [Thread-1 (]: 4 of 4 ERROR creating sql view model main_cleansed.cleanpullrequest ............ [[31mERROR[0m in 0.04s]
[0m15:41:56.027195 [debug] [Thread-1 (]: Finished running node model.archi.cleanpullrequest
[0m15:41:56.027195 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanpullrequest' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^.
[0m15:41:56.029107 [debug] [MainThread]: Using duckdb connection "master"
[0m15:41:56.029107 [debug] [MainThread]: On master: BEGIN
[0m15:41:56.030106 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:41:56.045581 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:41:56.046513 [debug] [MainThread]: On master: COMMIT
[0m15:41:56.046513 [debug] [MainThread]: Using duckdb connection "master"
[0m15:41:56.046513 [debug] [MainThread]: On master: COMMIT
[0m15:41:56.047594 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:41:56.047594 [debug] [MainThread]: On master: Close
[0m15:41:56.050503 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:41:56.050503 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:41:56.051501 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:41:56.051501 [debug] [MainThread]: Connection 'model.archi.cleanpullrequest' was properly closed.
[0m15:41:56.051501 [info ] [MainThread]: 
[0m15:41:56.052498 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 0.52 seconds (0.52s).
[0m15:41:56.054001 [debug] [MainThread]: Command end result
[0m15:41:56.071135 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:41:56.073129 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:41:56.079308 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:41:56.079308 [info ] [MainThread]: 
[0m15:41:56.079308 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m15:41:56.080312 [info ] [MainThread]: 
[0m15:41:56.080820 [error] [MainThread]:   Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "id" not found in FROM clause!
  Candidate bindings: "raw_commits.committer.id", "raw_commits.node_id"
  LINE 12:     where id is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^
[0m15:41:56.081815 [info ] [MainThread]: 
[0m15:41:56.082436 [error] [MainThread]:   Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "name" not found in FROM clause!
  Candidate bindings: "raw_contributors.node_id", "raw_contributors.starred_url", "raw_contributors.type"
  LINE 8:         name,
                  ^
[0m15:41:56.082943 [info ] [MainThread]: 
[0m15:41:56.082943 [error] [MainThread]:   Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^
[0m15:41:56.083938 [info ] [MainThread]: 
[0m15:41:56.084506 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=3 SKIP=0 TOTAL=4
[0m15:41:56.085014 [debug] [MainThread]: Command `dbt build` failed at 15:41:56.085014 after 1.66 seconds
[0m15:41:56.086008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202383646B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023AB31DF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202394C7BC0>]}
[0m15:41:56.086008 [debug] [MainThread]: Flushing usage events
[0m15:41:56.890475 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:42:32.940872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C97DDF72C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C97EDB88C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C97F0D1D30>]}


============================== 15:42:32.944731 | 687298c0-882e-419c-84d2-f8dae96b1715 ==============================
[0m15:42:32.944731 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:42:32.945718 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt build', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:42:33.157088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '687298c0-882e-419c-84d2-f8dae96b1715', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C97FA2BAD0>]}
[0m15:42:33.216087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '687298c0-882e-419c-84d2-f8dae96b1715', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C97F3C5A60>]}
[0m15:42:33.220038 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:42:33.488012 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:42:33.616684 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:42:33.617192 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleancommits.sql
[0m15:42:33.853417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '687298c0-882e-419c-84d2-f8dae96b1715', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C900133EF0>]}
[0m15:42:33.900356 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:42:33.902351 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:42:33.937376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '687298c0-882e-419c-84d2-f8dae96b1715', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9004E5340>]}
[0m15:42:33.938379 [info ] [MainThread]: Found 4 models, 424 macros
[0m15:42:33.940188 [info ] [MainThread]: 
[0m15:42:33.941107 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:42:33.941107 [info ] [MainThread]: 
[0m15:42:33.942104 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:42:33.946201 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:42:34.030847 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:42:34.030847 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:42:34.030847 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:42:34.051291 [debug] [ThreadPool]: SQL status: OK in 0.020 seconds
[0m15:42:34.052286 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:42:34.056407 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:42:34.056407 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:42:34.061733 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:42:34.062740 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:42:34.062740 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:42:34.079574 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m15:42:34.080597 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:42:34.080597 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:42:34.082099 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:42:34.082099 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:42:34.083094 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:42:34.083094 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:42:34.084397 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:42:34.084905 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:42:34.084905 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:42:34.085454 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:42:34.085961 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:42:34.089948 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:42:34.094442 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:42:34.094442 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:42:34.095011 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:42:34.111625 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:42:34.113172 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:42:34.114166 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:42:34.154805 [debug] [ThreadPool]: SQL status: OK in 0.041 seconds
[0m15:42:34.157295 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:42:34.158290 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:42:34.158841 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:42:34.162370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '687298c0-882e-419c-84d2-f8dae96b1715', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C97E4BC530>]}
[0m15:42:34.163363 [debug] [MainThread]: Using duckdb connection "master"
[0m15:42:34.163363 [debug] [MainThread]: On master: BEGIN
[0m15:42:34.163363 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:42:34.179249 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:42:34.180245 [debug] [MainThread]: On master: COMMIT
[0m15:42:34.180245 [debug] [MainThread]: Using duckdb connection "master"
[0m15:42:34.180245 [debug] [MainThread]: On master: COMMIT
[0m15:42:34.181242 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:42:34.181242 [debug] [MainThread]: On master: Close
[0m15:42:34.186306 [debug] [Thread-1 (]: Began running node model.archi.cleancommits
[0m15:42:34.186306 [info ] [Thread-1 (]: 1 of 4 START sql view model main_cleansed.cleancommits ......................... [RUN]
[0m15:42:34.187302 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommits'
[0m15:42:34.187302 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommits
[0m15:42:34.194035 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommits"
[0m15:42:34.195031 [debug] [Thread-1 (]: Began executing node model.archi.cleancommits
[0m15:42:34.224090 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommits"
[0m15:42:34.225096 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:42:34.225096 [debug] [Thread-1 (]: On model.archi.cleancommits: BEGIN
[0m15:42:34.225604 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:42:34.242186 [debug] [Thread-1 (]: SQL status: OK in 0.017 seconds
[0m15:42:34.242695 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:42:34.242695 [debug] [Thread-1 (]: On model.archi.cleancommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where raw_commits.committer.id is not null  -- Filtrer les commits sans message
)

select
    id,
    author_id,
    created_at
from raw
  );

[0m15:42:34.243204 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where raw_commits.committer.id is not null  -- Filtrer les commits sans message
)

select
    id,
    author_id,
    created_at
from raw
  );

[0m15:42:34.244487 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:42:34.244994 [debug] [Thread-1 (]: On model.archi.cleancommits: ROLLBACK
[0m15:42:34.250202 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommits'
[0m15:42:34.250202 [debug] [Thread-1 (]: On model.archi.cleancommits: Close
[0m15:42:34.256216 [debug] [Thread-1 (]: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Table "raw_commits" does not have a column named "committer"
  LINE 12:     where raw_commits.committer.id is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^
[0m15:42:34.257213 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '687298c0-882e-419c-84d2-f8dae96b1715', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9001300E0>]}
[0m15:42:34.258211 [error] [Thread-1 (]: 1 of 4 ERROR creating sql view model main_cleansed.cleancommits ................ [[31mERROR[0m in 0.07s]
[0m15:42:34.258719 [debug] [Thread-1 (]: Finished running node model.archi.cleancommits
[0m15:42:34.258719 [debug] [Thread-1 (]: Began running node model.archi.cleancontributors
[0m15:42:34.260262 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommits' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Table "raw_commits" does not have a column named "committer"
  LINE 12:     where raw_commits.committer.id is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^.
[0m15:42:34.259753 [info ] [Thread-1 (]: 2 of 4 START sql view model main_cleansed.cleancontributors .................... [RUN]
[0m15:42:34.260807 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommits, now model.archi.cleancontributors)
[0m15:42:34.260807 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributors
[0m15:42:34.262833 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributors"
[0m15:42:34.263831 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributors
[0m15:42:34.268021 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributors"
[0m15:42:34.268021 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:42:34.269018 [debug] [Thread-1 (]: On model.archi.cleancontributors: BEGIN
[0m15:42:34.269637 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:42:34.285869 [debug] [Thread-1 (]: SQL status: OK in 0.017 seconds
[0m15:42:34.285869 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:42:34.285869 [debug] [Thread-1 (]: On model.archi.cleancontributors: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        raw_contributors.html_url,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where raw_contributors.html_url is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    name,
    raw_contributors.html_url
from raw
  );

[0m15:42:34.287407 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        raw_contributors.html_url,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where raw_contributors.html_url is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    name,
    raw_contributors.html_url
from raw
  );

[0m15:42:34.288309 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:42:34.288309 [debug] [Thread-1 (]: On model.archi.cleancontributors: ROLLBACK
[0m15:42:34.291317 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancontributors'
[0m15:42:34.291317 [debug] [Thread-1 (]: On model.archi.cleancontributors: Close
[0m15:42:34.296899 [debug] [Thread-1 (]: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "name" not found in FROM clause!
  Candidate bindings: "raw_contributors.node_id", "raw_contributors.starred_url", "raw_contributors.type"
  LINE 8:         name,
                  ^
[0m15:42:34.296899 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '687298c0-882e-419c-84d2-f8dae96b1715', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C901619040>]}
[0m15:42:34.297900 [error] [Thread-1 (]: 2 of 4 ERROR creating sql view model main_cleansed.cleancontributors ........... [[31mERROR[0m in 0.04s]
[0m15:42:34.299402 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributors
[0m15:42:34.299969 [debug] [Thread-1 (]: Began running node model.archi.cleanissues
[0m15:42:34.300478 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancontributors' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "name" not found in FROM clause!
  Candidate bindings: "raw_contributors.node_id", "raw_contributors.starred_url", "raw_contributors.type"
  LINE 8:         name,
                  ^.
[0m15:42:34.300478 [info ] [Thread-1 (]: 3 of 4 START sql view model main_cleansed.cleanissues .......................... [RUN]
[0m15:42:34.301472 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributors, now model.archi.cleanissues)
[0m15:42:34.302094 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissues
[0m15:42:34.303596 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissues"
[0m15:42:34.305096 [debug] [Thread-1 (]: Began executing node model.archi.cleanissues
[0m15:42:34.309128 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissues"
[0m15:42:34.310124 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:42:34.310124 [debug] [Thread-1 (]: On model.archi.cleanissues: BEGIN
[0m15:42:34.311504 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:42:34.326927 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:42:34.327781 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:42:34.327781 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where title is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    created_at
from raw
  );

[0m15:42:34.328288 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:42:34.334818 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:42:34.334818 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */
alter view "pytorch_data"."main_cleansed"."cleanissues" rename to "cleanissues__dbt_backup"
[0m15:42:34.335822 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:42:34.338436 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:42:34.338436 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */
alter view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" rename to "cleanissues"
[0m15:42:34.339431 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:42:34.351148 [debug] [Thread-1 (]: On model.archi.cleanissues: COMMIT
[0m15:42:34.351148 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:42:34.352086 [debug] [Thread-1 (]: On model.archi.cleanissues: COMMIT
[0m15:42:34.355082 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:42:34.360067 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:42:34.360067 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissues__dbt_backup" cascade
[0m15:42:34.361064 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:42:34.363059 [debug] [Thread-1 (]: On model.archi.cleanissues: Close
[0m15:42:34.397647 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '687298c0-882e-419c-84d2-f8dae96b1715', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C9000212E0>]}
[0m15:42:34.398160 [info ] [Thread-1 (]: 3 of 4 OK created sql view model main_cleansed.cleanissues ..................... [[32mOK[0m in 0.10s]
[0m15:42:34.398160 [debug] [Thread-1 (]: Finished running node model.archi.cleanissues
[0m15:42:34.399164 [debug] [Thread-1 (]: Began running node model.archi.cleanpullrequest
[0m15:42:34.399714 [info ] [Thread-1 (]: 4 of 4 START sql view model main_cleansed.cleanpullrequest ..................... [RUN]
[0m15:42:34.400223 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissues, now model.archi.cleanpullrequest)
[0m15:42:34.400223 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpullrequest
[0m15:42:34.402735 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpullrequest"
[0m15:42:34.403725 [debug] [Thread-1 (]: Began executing node model.archi.cleanpullrequest
[0m15:42:34.406382 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpullrequest"
[0m15:42:34.406891 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:42:34.407886 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: BEGIN
[0m15:42:34.407886 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:42:34.428901 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m15:42:34.428901 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:42:34.429897 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_pull_requests.node_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where title is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    raw_pull_requests.node_id,
    created_at
from raw
  );

[0m15:42:34.430991 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_pull_requests.node_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where title is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    raw_pull_requests.node_id,
    created_at
from raw
  );

[0m15:42:34.430991 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:42:34.431896 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: ROLLBACK
[0m15:42:34.435684 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanpullrequest'
[0m15:42:34.435684 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: Close
[0m15:42:34.441121 [debug] [Thread-1 (]: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^
[0m15:42:34.442119 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '687298c0-882e-419c-84d2-f8dae96b1715', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C901606C60>]}
[0m15:42:34.442690 [error] [Thread-1 (]: 4 of 4 ERROR creating sql view model main_cleansed.cleanpullrequest ............ [[31mERROR[0m in 0.04s]
[0m15:42:34.442690 [debug] [Thread-1 (]: Finished running node model.archi.cleanpullrequest
[0m15:42:34.443624 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanpullrequest' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^.
[0m15:42:34.444716 [debug] [MainThread]: Using duckdb connection "master"
[0m15:42:34.444716 [debug] [MainThread]: On master: BEGIN
[0m15:42:34.445618 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:42:34.461612 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:42:34.461612 [debug] [MainThread]: On master: COMMIT
[0m15:42:34.461612 [debug] [MainThread]: Using duckdb connection "master"
[0m15:42:34.462609 [debug] [MainThread]: On master: COMMIT
[0m15:42:34.462609 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:42:34.462609 [debug] [MainThread]: On master: Close
[0m15:42:34.466763 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:42:34.466763 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:42:34.467674 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:42:34.467674 [debug] [MainThread]: Connection 'model.archi.cleanpullrequest' was properly closed.
[0m15:42:34.467674 [info ] [MainThread]: 
[0m15:42:34.468671 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 0.53 seconds (0.53s).
[0m15:42:34.469668 [debug] [MainThread]: Command end result
[0m15:42:34.487202 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:42:34.489709 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:42:34.495285 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:42:34.495285 [info ] [MainThread]: 
[0m15:42:34.496346 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m15:42:34.496346 [info ] [MainThread]: 
[0m15:42:34.497342 [error] [MainThread]:   Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Table "raw_commits" does not have a column named "committer"
  LINE 12:     where raw_commits.committer.id is not null  -- Filtrer les commits sans message
  )
  
  select
      id,
      author_id,
      created_at
  from raw
    );
  ...
                     ^
[0m15:42:34.498379 [info ] [MainThread]: 
[0m15:42:34.498921 [error] [MainThread]:   Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "name" not found in FROM clause!
  Candidate bindings: "raw_contributors.node_id", "raw_contributors.starred_url", "raw_contributors.type"
  LINE 8:         name,
                  ^
[0m15:42:34.498921 [info ] [MainThread]: 
[0m15:42:34.500617 [error] [MainThread]:   Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 19:     raw_pull_requests.node_id,
               ^
[0m15:42:34.501126 [info ] [MainThread]: 
[0m15:42:34.501126 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=3 SKIP=0 TOTAL=4
[0m15:42:34.502754 [debug] [MainThread]: Command `dbt build` failed at 15:42:34.502754 after 1.67 seconds
[0m15:42:34.503261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C97F333440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C97FF949B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C97F3A6180>]}
[0m15:42:34.503261 [debug] [MainThread]: Flushing usage events
[0m15:42:35.473529 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:42:58.014852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EDD041490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EE096D9A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EE096E6F0>]}


============================== 15:42:58.019517 | 1d06916b-12af-43e4-addc-2d9e31ff4f8d ==============================
[0m15:42:58.019517 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:42:58.020023 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m15:42:58.227061 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1d06916b-12af-43e4-addc-2d9e31ff4f8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EDFD29190>]}
[0m15:42:58.285185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1d06916b-12af-43e4-addc-2d9e31ff4f8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EE04AD700>]}
[0m15:42:58.289189 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:42:58.560752 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:42:58.689009 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 4 files changed.
[0m15:42:58.689737 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleanissues.sql
[0m15:42:58.690244 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleancontributors.sql
[0m15:42:58.690244 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleanpullrequest.sql
[0m15:42:58.690244 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleancommits.sql
[0m15:42:58.936614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1d06916b-12af-43e4-addc-2d9e31ff4f8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EE1877AA0>]}
[0m15:42:58.985847 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:42:58.988266 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:42:59.024303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1d06916b-12af-43e4-addc-2d9e31ff4f8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EE22D07A0>]}
[0m15:42:59.024826 [info ] [MainThread]: Found 4 models, 424 macros
[0m15:42:59.027053 [info ] [MainThread]: 
[0m15:42:59.027053 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:42:59.027992 [info ] [MainThread]: 
[0m15:42:59.027992 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:42:59.032486 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:42:59.116860 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:42:59.116860 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:42:59.117893 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:42:59.135261 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:42:59.137148 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:42:59.140889 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:42:59.140889 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:42:59.146823 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:42:59.147374 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:42:59.147374 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:42:59.163339 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:42:59.164917 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:42:59.165492 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:42:59.165492 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:42:59.165492 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:42:59.166420 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:42:59.166420 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:42:59.167417 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:42:59.168009 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:42:59.168009 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:42:59.168524 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:42:59.168524 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:42:59.173500 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:42:59.177994 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:42:59.177994 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:42:59.178992 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:42:59.194919 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:42:59.194919 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:42:59.194919 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:42:59.237513 [debug] [ThreadPool]: SQL status: OK in 0.041 seconds
[0m15:42:59.238055 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:42:59.239678 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:42:59.240185 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:42:59.244347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1d06916b-12af-43e4-addc-2d9e31ff4f8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EE10EF230>]}
[0m15:42:59.244854 [debug] [MainThread]: Using duckdb connection "master"
[0m15:42:59.245361 [debug] [MainThread]: On master: BEGIN
[0m15:42:59.245361 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:42:59.261295 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:42:59.261295 [debug] [MainThread]: On master: COMMIT
[0m15:42:59.262292 [debug] [MainThread]: Using duckdb connection "master"
[0m15:42:59.262292 [debug] [MainThread]: On master: COMMIT
[0m15:42:59.262292 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:42:59.263290 [debug] [MainThread]: On master: Close
[0m15:42:59.267994 [debug] [Thread-1 (]: Began running node model.archi.cleancommits
[0m15:42:59.267994 [info ] [Thread-1 (]: 1 of 4 START sql view model main_cleansed.cleancommits ......................... [RUN]
[0m15:42:59.268988 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommits'
[0m15:42:59.268988 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommits
[0m15:42:59.275646 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommits"
[0m15:42:59.277277 [debug] [Thread-1 (]: Began executing node model.archi.cleancommits
[0m15:42:59.305567 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommits"
[0m15:42:59.306951 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:42:59.307945 [debug] [Thread-1 (]: On model.archi.cleancommits: BEGIN
[0m15:42:59.307945 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:42:59.324743 [debug] [Thread-1 (]: SQL status: OK in 0.017 seconds
[0m15:42:59.324743 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommits"
[0m15:42:59.325950 [debug] [Thread-1 (]: On model.archi.cleancommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
)

select
    id,
    author_id,
    created_at
from raw
  );

[0m15:42:59.326865 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommits"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommits__dbt_tmp" as (
    with raw as (
    select
        id,
        author_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
)

select
    id,
    author_id,
    created_at
from raw
  );

[0m15:42:59.326865 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:42:59.327863 [debug] [Thread-1 (]: On model.archi.cleancommits: ROLLBACK
[0m15:42:59.332447 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommits'
[0m15:42:59.332447 [debug] [Thread-1 (]: On model.archi.cleancommits: Close
[0m15:42:59.338935 [debug] [Thread-1 (]: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "id" not found in FROM clause!
  Candidate bindings: "raw_commits.committer.id", "raw_commits.node_id"
  LINE 7:         id,
                  ^
[0m15:42:59.340446 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1d06916b-12af-43e4-addc-2d9e31ff4f8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EE2040A40>]}
[0m15:42:59.340446 [error] [Thread-1 (]: 1 of 4 ERROR creating sql view model main_cleansed.cleancommits ................ [[31mERROR[0m in 0.07s]
[0m15:42:59.342136 [debug] [Thread-1 (]: Finished running node model.archi.cleancommits
[0m15:42:59.342136 [debug] [Thread-1 (]: Began running node model.archi.cleancontributors
[0m15:42:59.342643 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommits' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "id" not found in FROM clause!
  Candidate bindings: "raw_commits.committer.id", "raw_commits.node_id"
  LINE 7:         id,
                  ^.
[0m15:42:59.342643 [info ] [Thread-1 (]: 2 of 4 START sql view model main_cleansed.cleancontributors .................... [RUN]
[0m15:42:59.343638 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommits, now model.archi.cleancontributors)
[0m15:42:59.344409 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributors
[0m15:42:59.345911 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributors"
[0m15:42:59.346912 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributors
[0m15:42:59.351042 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributors"
[0m15:42:59.352154 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:42:59.352154 [debug] [Thread-1 (]: On model.archi.cleancontributors: BEGIN
[0m15:42:59.352154 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:42:59.368321 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:42:59.368321 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributors"
[0m15:42:59.369318 [debug] [Thread-1 (]: On model.archi.cleancontributors: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        raw_contributors.html_url,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
)

select
    id,
    name,
    raw_contributors.html_url
from raw
  );

[0m15:42:59.369318 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributors"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributors__dbt_tmp" as (
    with raw as (
    select
        id,
        name,
        raw_contributors.html_url,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
)

select
    id,
    name,
    raw_contributors.html_url
from raw
  );

[0m15:42:59.370973 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:42:59.371479 [debug] [Thread-1 (]: On model.archi.cleancontributors: ROLLBACK
[0m15:42:59.374493 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancontributors'
[0m15:42:59.374493 [debug] [Thread-1 (]: On model.archi.cleancontributors: Close
[0m15:42:59.379663 [debug] [Thread-1 (]: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "name" not found in FROM clause!
  Candidate bindings: "raw_contributors.node_id", "raw_contributors.starred_url", "raw_contributors.type"
  LINE 8:         name,
                  ^
[0m15:42:59.380638 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1d06916b-12af-43e4-addc-2d9e31ff4f8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EE28D4890>]}
[0m15:42:59.380638 [error] [Thread-1 (]: 2 of 4 ERROR creating sql view model main_cleansed.cleancontributors ........... [[31mERROR[0m in 0.04s]
[0m15:42:59.381713 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributors
[0m15:42:59.381713 [debug] [Thread-1 (]: Began running node model.archi.cleanissues
[0m15:42:59.383488 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancontributors' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "name" not found in FROM clause!
  Candidate bindings: "raw_contributors.node_id", "raw_contributors.starred_url", "raw_contributors.type"
  LINE 8:         name,
                  ^.
[0m15:42:59.382707 [info ] [Thread-1 (]: 3 of 4 START sql view model main_cleansed.cleanissues .......................... [RUN]
[0m15:42:59.383993 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributors, now model.archi.cleanissues)
[0m15:42:59.384502 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissues
[0m15:42:59.386511 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissues"
[0m15:42:59.387508 [debug] [Thread-1 (]: Began executing node model.archi.cleanissues
[0m15:42:59.391014 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissues"
[0m15:42:59.392025 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:42:59.392025 [debug] [Thread-1 (]: On model.archi.cleanissues: BEGIN
[0m15:42:59.392942 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:42:59.409027 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:42:59.409027 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:42:59.410021 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
)

select
    id,
    title,
    created_at
from raw
  );

[0m15:42:59.410021 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:42:59.416133 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:42:59.416133 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */
alter view "pytorch_data"."main_cleansed"."cleanissues" rename to "cleanissues__dbt_backup"
[0m15:42:59.417126 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:42:59.419744 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:42:59.420754 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */
alter view "pytorch_data"."main_cleansed"."cleanissues__dbt_tmp" rename to "cleanissues"
[0m15:42:59.420754 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:42:59.431709 [debug] [Thread-1 (]: On model.archi.cleanissues: COMMIT
[0m15:42:59.432707 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:42:59.432707 [debug] [Thread-1 (]: On model.archi.cleanissues: COMMIT
[0m15:42:59.436035 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:42:59.441104 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissues"
[0m15:42:59.441104 [debug] [Thread-1 (]: On model.archi.cleanissues: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissues"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissues__dbt_backup" cascade
[0m15:42:59.442731 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:42:59.444808 [debug] [Thread-1 (]: On model.archi.cleanissues: Close
[0m15:42:59.478379 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1d06916b-12af-43e4-addc-2d9e31ff4f8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EDD4094F0>]}
[0m15:42:59.479885 [info ] [Thread-1 (]: 3 of 4 OK created sql view model main_cleansed.cleanissues ..................... [[32mOK[0m in 0.09s]
[0m15:42:59.479949 [debug] [Thread-1 (]: Finished running node model.archi.cleanissues
[0m15:42:59.480879 [debug] [Thread-1 (]: Began running node model.archi.cleanpullrequest
[0m15:42:59.480879 [info ] [Thread-1 (]: 4 of 4 START sql view model main_cleansed.cleanpullrequest ..................... [RUN]
[0m15:42:59.481960 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissues, now model.archi.cleanpullrequest)
[0m15:42:59.481960 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpullrequest
[0m15:42:59.483871 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpullrequest"
[0m15:42:59.484869 [debug] [Thread-1 (]: Began executing node model.archi.cleanpullrequest
[0m15:42:59.488265 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpullrequest"
[0m15:42:59.489075 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:42:59.489584 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: BEGIN
[0m15:42:59.489584 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:42:59.510679 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m15:42:59.511222 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpullrequest"
[0m15:42:59.511222 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_pull_requests.node_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
)

select
    id,
    title,
    raw_pull_requests.node_id,
    created_at
from raw
  );

[0m15:42:59.512245 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpullrequest"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpullrequest__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        raw_pull_requests.node_id,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
)

select
    id,
    title,
    raw_pull_requests.node_id,
    created_at
from raw
  );

[0m15:42:59.512245 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:42:59.513251 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: ROLLBACK
[0m15:42:59.516323 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanpullrequest'
[0m15:42:59.516826 [debug] [Thread-1 (]: On model.archi.cleanpullrequest: Close
[0m15:42:59.523363 [debug] [Thread-1 (]: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 18:     raw_pull_requests.node_id,
               ^
[0m15:42:59.523874 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1d06916b-12af-43e4-addc-2d9e31ff4f8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EE27D9040>]}
[0m15:42:59.523874 [error] [Thread-1 (]: 4 of 4 ERROR creating sql view model main_cleansed.cleanpullrequest ............ [[31mERROR[0m in 0.04s]
[0m15:42:59.524867 [debug] [Thread-1 (]: Finished running node model.archi.cleanpullrequest
[0m15:42:59.525661 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanpullrequest' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 18:     raw_pull_requests.node_id,
               ^.
[0m15:42:59.526625 [debug] [MainThread]: Using duckdb connection "master"
[0m15:42:59.526625 [debug] [MainThread]: On master: BEGIN
[0m15:42:59.526625 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:42:59.543017 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:42:59.544047 [debug] [MainThread]: On master: COMMIT
[0m15:42:59.544047 [debug] [MainThread]: Using duckdb connection "master"
[0m15:42:59.544047 [debug] [MainThread]: On master: COMMIT
[0m15:42:59.545060 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:42:59.545060 [debug] [MainThread]: On master: Close
[0m15:42:59.548174 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:42:59.548682 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:42:59.548682 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:42:59.549210 [debug] [MainThread]: Connection 'model.archi.cleanpullrequest' was properly closed.
[0m15:42:59.549716 [info ] [MainThread]: 
[0m15:42:59.550280 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 0.52 seconds (0.52s).
[0m15:42:59.551218 [debug] [MainThread]: Command end result
[0m15:42:59.569690 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:42:59.572682 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:42:59.577611 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:42:59.578600 [info ] [MainThread]: 
[0m15:42:59.578600 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m15:42:59.579568 [info ] [MainThread]: 
[0m15:42:59.579568 [error] [MainThread]:   Runtime Error in model cleancommits (models\duckdb\cleancommits.sql)
  Binder Error: Referenced column "id" not found in FROM clause!
  Candidate bindings: "raw_commits.committer.id", "raw_commits.node_id"
  LINE 7:         id,
                  ^
[0m15:42:59.580566 [info ] [MainThread]: 
[0m15:42:59.580566 [error] [MainThread]:   Runtime Error in model cleancontributors (models\duckdb\cleancontributors.sql)
  Binder Error: Referenced column "name" not found in FROM clause!
  Candidate bindings: "raw_contributors.node_id", "raw_contributors.starred_url", "raw_contributors.type"
  LINE 8:         name,
                  ^
[0m15:42:59.581592 [info ] [MainThread]: 
[0m15:42:59.582561 [error] [MainThread]:   Runtime Error in model cleanpullrequest (models\duckdb\cleanpullrequest.sql)
  Binder Error: Referenced table "raw_pull_requests" not found!
  Candidate tables: "raw"
  LINE 18:     raw_pull_requests.node_id,
               ^
[0m15:42:59.582561 [info ] [MainThread]: 
[0m15:42:59.583557 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=3 SKIP=0 TOTAL=4
[0m15:42:59.584555 [debug] [MainThread]: Command `dbt build` failed at 15:42:59.584555 after 1.68 seconds
[0m15:42:59.585177 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EDD041490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EE096DA30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EE096E6F0>]}
[0m15:42:59.585685 [debug] [MainThread]: Flushing usage events
[0m15:43:00.452710 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:46:49.477054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025927E49E80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025927E49280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025927E48DD0>]}


============================== 15:46:49.481093 | ca0fc9ba-ab2a-4620-8f1c-611cbdfb26c0 ==============================
[0m15:46:49.481093 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:46:49.482018 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:46:49.688510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ca0fc9ba-ab2a-4620-8f1c-611cbdfb26c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002592852F020>]}
[0m15:46:49.747886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ca0fc9ba-ab2a-4620-8f1c-611cbdfb26c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025925FF7500>]}
[0m15:46:49.752038 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:46:50.002313 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:46:50.129629 [debug] [MainThread]: Partial parsing enabled: 4 files deleted, 1 files added, 0 files changed.
[0m15:46:50.130628 [debug] [MainThread]: Partial parsing: added file: archi://models\duckdb\cleancommit.sql
[0m15:46:50.130628 [debug] [MainThread]: Partial parsing: deleted file: archi://models\duckdb\cleancontributors.sql
[0m15:46:50.130628 [debug] [MainThread]: Partial parsing: deleted file: archi://models\duckdb\cleanissues.sql
[0m15:46:50.131627 [debug] [MainThread]: Partial parsing: deleted file: archi://models\duckdb\cleanpullrequest.sql
[0m15:46:50.131627 [debug] [MainThread]: Partial parsing: deleted file: archi://models\duckdb\cleancommits.sql
[0m15:46:50.364268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ca0fc9ba-ab2a-4620-8f1c-611cbdfb26c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025929552FF0>]}
[0m15:46:50.411737 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:46:50.413768 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:46:50.448374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca0fc9ba-ab2a-4620-8f1c-611cbdfb26c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259299B8980>]}
[0m15:46:50.448374 [info ] [MainThread]: Found 1 model, 424 macros
[0m15:46:50.450991 [info ] [MainThread]: 
[0m15:46:50.451978 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:46:50.451978 [info ] [MainThread]: 
[0m15:46:50.452959 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:46:50.453501 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:46:50.539430 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:46:50.539972 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:46:50.539972 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:46:50.559778 [debug] [ThreadPool]: SQL status: OK in 0.020 seconds
[0m15:46:50.560799 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:46:50.564451 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:46:50.564451 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:46:50.572044 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:46:50.572044 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:46:50.572553 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:46:50.591268 [debug] [ThreadPool]: SQL status: OK in 0.019 seconds
[0m15:46:50.592307 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:46:50.593262 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:46:50.593262 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:46:50.593262 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:46:50.593262 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:46:50.594260 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:46:50.595259 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:46:50.595259 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:46:50.595259 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:46:50.596255 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:46:50.596255 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:46:50.599852 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:46:50.605323 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:46:50.605323 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:46:50.606406 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:46:50.622480 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:46:50.622480 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:46:50.623055 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:46:50.664113 [debug] [ThreadPool]: SQL status: OK in 0.041 seconds
[0m15:46:50.666093 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:46:50.667219 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:46:50.667219 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:46:50.671666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ca0fc9ba-ab2a-4620-8f1c-611cbdfb26c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025928D72540>]}
[0m15:46:50.672664 [debug] [MainThread]: Using duckdb connection "master"
[0m15:46:50.672664 [debug] [MainThread]: On master: BEGIN
[0m15:46:50.672664 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:46:50.689307 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:46:50.689307 [debug] [MainThread]: On master: COMMIT
[0m15:46:50.690239 [debug] [MainThread]: Using duckdb connection "master"
[0m15:46:50.690239 [debug] [MainThread]: On master: COMMIT
[0m15:46:50.690239 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:46:50.691235 [debug] [MainThread]: On master: Close
[0m15:46:50.695755 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m15:46:50.695755 [info ] [Thread-1 (]: 1 of 1 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m15:46:50.697316 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m15:46:50.697316 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m15:46:50.704879 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m15:46:50.704879 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m15:46:50.739243 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m15:46:50.740237 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:46:50.740237 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m15:46:50.740237 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:46:50.756425 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:46:50.757423 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:46:50.757932 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        commit.author.name,
        commit.author.date,
        commit.url,
        author.id,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where message is not null  -- Filtrer les commits sans message
)

select
    commit.author.name,
    commit.author.date,
    commit.url,
    author.id,
from raw
  );

[0m15:46:50.758925 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        commit.author.name,
        commit.author.date,
        commit.url,
        author.id,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where message is not null  -- Filtrer les commits sans message
)

select
    commit.author.name,
    commit.author.date,
    commit.url,
    author.id,
from raw
  );

[0m15:46:50.758925 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:46:50.758925 [debug] [Thread-1 (]: On model.archi.cleancommit: ROLLBACK
[0m15:46:50.763424 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommit'
[0m15:46:50.764426 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m15:46:50.769967 [debug] [Thread-1 (]: Runtime Error in model cleancommit (models\duckdb\cleancommit.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 13:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      commit.author.name,
      commit.author.date,
      commit.url,
      author.id,
  from raw
    );
  ...
                     ^
[0m15:46:50.772466 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca0fc9ba-ab2a-4620-8f1c-611cbdfb26c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025925FCAA80>]}
[0m15:46:50.772466 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main_cleansed.cleancommit ................. [[31mERROR[0m in 0.07s]
[0m15:46:50.773464 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m15:46:50.773464 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommit' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommit (models\duckdb\cleancommit.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 13:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      commit.author.name,
      commit.author.date,
      commit.url,
      author.id,
  from raw
    );
  ...
                     ^.
[0m15:46:50.774701 [debug] [MainThread]: Using duckdb connection "master"
[0m15:46:50.775712 [debug] [MainThread]: On master: BEGIN
[0m15:46:50.775712 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:46:50.792265 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:46:50.792265 [debug] [MainThread]: On master: COMMIT
[0m15:46:50.792816 [debug] [MainThread]: Using duckdb connection "master"
[0m15:46:50.792816 [debug] [MainThread]: On master: COMMIT
[0m15:46:50.792816 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:46:50.793840 [debug] [MainThread]: On master: Close
[0m15:46:50.796340 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:46:50.797338 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:46:50.797338 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:46:50.797846 [debug] [MainThread]: Connection 'model.archi.cleancommit' was properly closed.
[0m15:46:50.797846 [info ] [MainThread]: 
[0m15:46:50.797846 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.34 seconds (0.34s).
[0m15:46:50.799460 [debug] [MainThread]: Command end result
[0m15:46:50.815347 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:46:50.818409 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:46:50.823889 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:46:50.823889 [info ] [MainThread]: 
[0m15:46:50.825252 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:46:50.825252 [info ] [MainThread]: 
[0m15:46:50.826226 [error] [MainThread]:   Runtime Error in model cleancommit (models\duckdb\cleancommit.sql)
  Binder Error: Referenced column "message" not found in FROM clause!
  Candidate bindings: "raw_commits.sha"
  LINE 13:     where message is not null  -- Filtrer les commits sans message
  )
  
  select
      commit.author.name,
      commit.author.date,
      commit.url,
      author.id,
  from raw
    );
  ...
                     ^
[0m15:46:50.827226 [info ] [MainThread]: 
[0m15:46:50.827226 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:46:50.828222 [debug] [MainThread]: Command `dbt build` failed at 15:46:50.828222 after 1.50 seconds
[0m15:46:50.829219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025925662C30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259283D3A10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259283D0BF0>]}
[0m15:46:50.829219 [debug] [MainThread]: Flushing usage events
[0m15:46:51.729716 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:47:06.769166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000265C866F7D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000265C8A87140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000265C8A86E40>]}


============================== 15:47:06.773156 | 43277805-c3be-431d-bcbc-cee6a50a710f ==============================
[0m15:47:06.773156 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:47:06.773156 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:47:06.983065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '43277805-c3be-431d-bcbc-cee6a50a710f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000265C510A660>]}
[0m15:47:07.041012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '43277805-c3be-431d-bcbc-cee6a50a710f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000265C7EDCE00>]}
[0m15:47:07.045593 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:47:07.296960 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:47:07.416333 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:47:07.416333 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleancommit.sql
[0m15:47:07.651823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '43277805-c3be-431d-bcbc-cee6a50a710f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000265C9E55190>]}
[0m15:47:07.699497 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:47:07.701563 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:47:07.738309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '43277805-c3be-431d-bcbc-cee6a50a710f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000265CA0B8740>]}
[0m15:47:07.738309 [info ] [MainThread]: Found 1 model, 424 macros
[0m15:47:07.740222 [info ] [MainThread]: 
[0m15:47:07.741251 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:47:07.741795 [info ] [MainThread]: 
[0m15:47:07.741795 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:47:07.743408 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:47:07.825223 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:47:07.825223 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:47:07.825854 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:07.843796 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:47:07.845379 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:47:07.849346 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:47:07.849346 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:47:07.855370 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:47:07.855370 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:47:07.855370 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:47:07.873457 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:47:07.874454 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:47:07.875468 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:47:07.875976 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:47:07.875976 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:47:07.875976 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:47:07.876973 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:47:07.877977 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:47:07.878485 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:47:07.878485 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:47:07.878485 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:47:07.879482 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:47:07.884099 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:47:07.889693 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:47:07.889693 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:47:07.890318 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:07.907413 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m15:47:07.907413 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:47:07.907413 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:47:07.950272 [debug] [ThreadPool]: SQL status: OK in 0.042 seconds
[0m15:47:07.951716 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:47:07.953642 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:47:07.953642 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:47:07.958556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43277805-c3be-431d-bcbc-cee6a50a710f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000265C9E9B9E0>]}
[0m15:47:07.958632 [debug] [MainThread]: Using duckdb connection "master"
[0m15:47:07.958632 [debug] [MainThread]: On master: BEGIN
[0m15:47:07.958632 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:47:07.975262 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:47:07.975262 [debug] [MainThread]: On master: COMMIT
[0m15:47:07.975262 [debug] [MainThread]: Using duckdb connection "master"
[0m15:47:07.976290 [debug] [MainThread]: On master: COMMIT
[0m15:47:07.976290 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:47:07.976290 [debug] [MainThread]: On master: Close
[0m15:47:07.982345 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m15:47:07.983240 [info ] [Thread-1 (]: 1 of 1 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m15:47:07.984237 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m15:47:07.984237 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m15:47:07.991380 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m15:47:07.992314 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m15:47:08.025276 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m15:47:08.026271 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:47:08.026409 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m15:47:08.026938 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:47:08.043413 [debug] [Thread-1 (]: SQL status: OK in 0.017 seconds
[0m15:47:08.044410 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:47:08.044410 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        commit.author.name,
        commit.author.date,
        commit.url,
        author.id,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where author.id is not null  -- Filtrer les commits sans message
)

select
    commit.author.name,
    commit.author.date,
    commit.url,
    author.id,
from raw
  );

[0m15:47:08.045871 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        commit.author.name,
        commit.author.date,
        commit.url,
        author.id,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where author.id is not null  -- Filtrer les commits sans message
)

select
    commit.author.name,
    commit.author.date,
    commit.url,
    author.id,
from raw
  );

[0m15:47:08.045871 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:47:08.046781 [debug] [Thread-1 (]: On model.archi.cleancommit: ROLLBACK
[0m15:47:08.051413 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommit'
[0m15:47:08.051413 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m15:47:08.057292 [debug] [Thread-1 (]: Runtime Error in model cleancommit (models\duckdb\cleancommit.sql)
  Binder Error: Referenced table "author" not found!
  Candidate tables: "raw_commits"
  LINE 13:     where author.id is not null  -- Filtrer les commits sans message
  )
  
  select
      commit.author.name,
      commit.author.date,
      commit.url,
      author.id,
  from raw
    );
  ...
                     ^
[0m15:47:08.058862 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43277805-c3be-431d-bcbc-cee6a50a710f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000265CA6A3FE0>]}
[0m15:47:08.058862 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main_cleansed.cleancommit ................. [[31mERROR[0m in 0.07s]
[0m15:47:08.059895 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m15:47:08.060556 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommit' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommit (models\duckdb\cleancommit.sql)
  Binder Error: Referenced table "author" not found!
  Candidate tables: "raw_commits"
  LINE 13:     where author.id is not null  -- Filtrer les commits sans message
  )
  
  select
      commit.author.name,
      commit.author.date,
      commit.url,
      author.id,
  from raw
    );
  ...
                     ^.
[0m15:47:08.062090 [debug] [MainThread]: Using duckdb connection "master"
[0m15:47:08.062090 [debug] [MainThread]: On master: BEGIN
[0m15:47:08.062090 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:47:08.078514 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:47:08.079130 [debug] [MainThread]: On master: COMMIT
[0m15:47:08.079636 [debug] [MainThread]: Using duckdb connection "master"
[0m15:47:08.079636 [debug] [MainThread]: On master: COMMIT
[0m15:47:08.079636 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:47:08.079636 [debug] [MainThread]: On master: Close
[0m15:47:08.083704 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:47:08.084211 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:47:08.084211 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:47:08.084718 [debug] [MainThread]: Connection 'model.archi.cleancommit' was properly closed.
[0m15:47:08.085282 [info ] [MainThread]: 
[0m15:47:08.085804 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.34 seconds (0.34s).
[0m15:47:08.086310 [debug] [MainThread]: Command end result
[0m15:47:08.103031 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:47:08.105551 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:47:08.110721 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:47:08.111228 [info ] [MainThread]: 
[0m15:47:08.111228 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:47:08.112224 [info ] [MainThread]: 
[0m15:47:08.112810 [error] [MainThread]:   Runtime Error in model cleancommit (models\duckdb\cleancommit.sql)
  Binder Error: Referenced table "author" not found!
  Candidate tables: "raw_commits"
  LINE 13:     where author.id is not null  -- Filtrer les commits sans message
  )
  
  select
      commit.author.name,
      commit.author.date,
      commit.url,
      author.id,
  from raw
    );
  ...
                     ^
[0m15:47:08.114311 [info ] [MainThread]: 
[0m15:47:08.114892 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:47:08.115879 [debug] [MainThread]: Command `dbt build` failed at 15:47:08.115879 after 1.46 seconds
[0m15:47:08.116877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000265C8A87140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000265C8A86E40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000265C77ECC50>]}
[0m15:47:08.116877 [debug] [MainThread]: Flushing usage events
[0m15:47:09.244892 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:47:24.190353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023646F8C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023646FCE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202369D0C80>]}


============================== 15:47:24.195410 | b7116060-2742-4f50-aafd-14d95774f151 ==============================
[0m15:47:24.195410 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:47:24.196364 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m15:47:24.408302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b7116060-2742-4f50-aafd-14d95774f151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020235A2A450>]}
[0m15:47:24.467035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b7116060-2742-4f50-aafd-14d95774f151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202360FC980>]}
[0m15:47:24.471072 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:47:24.734356 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:47:24.867430 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:47:24.867986 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleancommit.sql
[0m15:47:25.100668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b7116060-2742-4f50-aafd-14d95774f151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202378A2B70>]}
[0m15:47:25.147200 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:47:25.149200 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:47:25.183655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b7116060-2742-4f50-aafd-14d95774f151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020237DBC740>]}
[0m15:47:25.183655 [info ] [MainThread]: Found 1 model, 424 macros
[0m15:47:25.186162 [info ] [MainThread]: 
[0m15:47:25.186733 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:47:25.186733 [info ] [MainThread]: 
[0m15:47:25.187664 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:47:25.187664 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:47:25.270458 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:47:25.271452 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:47:25.271452 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:25.289539 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:47:25.290535 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:47:25.295383 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:47:25.295442 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:47:25.301868 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:47:25.301868 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:47:25.301868 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:47:25.317556 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:47:25.319066 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:47:25.319066 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:47:25.320061 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:47:25.320061 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:47:25.320709 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:47:25.321217 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:47:25.321725 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:47:25.321725 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:47:25.321725 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:47:25.322719 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:47:25.322719 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:47:25.327218 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:47:25.331840 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:47:25.331840 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:47:25.332895 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:25.347593 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m15:47:25.348638 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:47:25.348638 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:47:25.389458 [debug] [ThreadPool]: SQL status: OK in 0.041 seconds
[0m15:47:25.391453 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:47:25.392468 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:47:25.392468 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:47:25.397574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b7116060-2742-4f50-aafd-14d95774f151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023781E510>]}
[0m15:47:25.398469 [debug] [MainThread]: Using duckdb connection "master"
[0m15:47:25.398469 [debug] [MainThread]: On master: BEGIN
[0m15:47:25.398469 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:47:25.414023 [debug] [MainThread]: SQL status: OK in 0.015 seconds
[0m15:47:25.415021 [debug] [MainThread]: On master: COMMIT
[0m15:47:25.415021 [debug] [MainThread]: Using duckdb connection "master"
[0m15:47:25.415021 [debug] [MainThread]: On master: COMMIT
[0m15:47:25.416018 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:47:25.416568 [debug] [MainThread]: On master: Close
[0m15:47:25.421016 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m15:47:25.421016 [info ] [Thread-1 (]: 1 of 1 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m15:47:25.422014 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m15:47:25.422014 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m15:47:25.429354 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m15:47:25.429976 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m15:47:25.462503 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m15:47:25.463505 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:47:25.464015 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m15:47:25.464015 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:47:25.480039 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:47:25.480039 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:47:25.481036 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        commit.author.name,
        commit.author.date,
        commit.url,
        author.id,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    commit.author.name,
    commit.author.date,
    commit.url,
    author.id,
from raw
  );

[0m15:47:25.482038 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        commit.author.name,
        commit.author.date,
        commit.url,
        author.id,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    commit.author.name,
    commit.author.date,
    commit.url,
    author.id,
from raw
  );

[0m15:47:25.482547 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:47:25.482547 [debug] [Thread-1 (]: On model.archi.cleancommit: ROLLBACK
[0m15:47:25.487596 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommit'
[0m15:47:25.487596 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m15:47:25.494348 [debug] [Thread-1 (]: Runtime Error in model cleancommit (models\duckdb\cleancommit.sql)
  Binder Error: Referenced table "commit" not found!
  Candidate tables: "raw_commits"
  LINE 7:         commit.author.name,
                  ^
[0m15:47:25.495897 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7116060-2742-4f50-aafd-14d95774f151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202355CB020>]}
[0m15:47:25.496955 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main_cleansed.cleancommit ................. [[31mERROR[0m in 0.07s]
[0m15:47:25.496955 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m15:47:25.498311 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommit' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommit (models\duckdb\cleancommit.sql)
  Binder Error: Referenced table "commit" not found!
  Candidate tables: "raw_commits"
  LINE 7:         commit.author.name,
                  ^.
[0m15:47:25.499177 [debug] [MainThread]: Using duckdb connection "master"
[0m15:47:25.500172 [debug] [MainThread]: On master: BEGIN
[0m15:47:25.500172 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:47:25.516164 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:47:25.517161 [debug] [MainThread]: On master: COMMIT
[0m15:47:25.517161 [debug] [MainThread]: Using duckdb connection "master"
[0m15:47:25.517161 [debug] [MainThread]: On master: COMMIT
[0m15:47:25.518158 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:47:25.518158 [debug] [MainThread]: On master: Close
[0m15:47:25.521329 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:47:25.521956 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:47:25.521956 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:47:25.521956 [debug] [MainThread]: Connection 'model.archi.cleancommit' was properly closed.
[0m15:47:25.521956 [info ] [MainThread]: 
[0m15:47:25.522896 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.34 seconds (0.34s).
[0m15:47:25.524496 [debug] [MainThread]: Command end result
[0m15:47:25.539979 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:47:25.542060 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:47:25.548512 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:47:25.548512 [info ] [MainThread]: 
[0m15:47:25.548512 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:47:25.549992 [info ] [MainThread]: 
[0m15:47:25.550501 [error] [MainThread]:   Runtime Error in model cleancommit (models\duckdb\cleancommit.sql)
  Binder Error: Referenced table "commit" not found!
  Candidate tables: "raw_commits"
  LINE 7:         commit.author.name,
                  ^
[0m15:47:25.550501 [info ] [MainThread]: 
[0m15:47:25.551494 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:47:25.552725 [debug] [MainThread]: Command `dbt build` failed at 15:47:25.552725 after 1.47 seconds
[0m15:47:25.552725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202369FD3A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202369FDF70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202355F4B60>]}
[0m15:47:25.552725 [debug] [MainThread]: Flushing usage events
[0m15:47:26.422239 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:47:43.934299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C5C09F5610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C5C09CCA10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C5C09F5DC0>]}


============================== 15:47:43.937306 | 695f9788-87b8-493c-b61d-981d67492255 ==============================
[0m15:47:43.937306 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:47:43.939073 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m15:47:44.144731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '695f9788-87b8-493c-b61d-981d67492255', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C5C1F616D0>]}
[0m15:47:44.203279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '695f9788-87b8-493c-b61d-981d67492255', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C5C0E852B0>]}
[0m15:47:44.206785 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:47:44.458774 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:47:44.590169 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:47:44.591165 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleancommit.sql
[0m15:47:44.825254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '695f9788-87b8-493c-b61d-981d67492255', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C5C2D672C0>]}
[0m15:47:44.871155 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:47:44.873203 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:47:44.908952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '695f9788-87b8-493c-b61d-981d67492255', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C5C33BC7A0>]}
[0m15:47:44.909950 [info ] [MainThread]: Found 1 model, 424 macros
[0m15:47:44.912426 [info ] [MainThread]: 
[0m15:47:44.912426 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:47:44.913422 [info ] [MainThread]: 
[0m15:47:44.913422 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:47:44.914780 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:47:44.998056 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:47:44.999058 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:47:44.999058 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:45.017138 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:47:45.017769 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:47:45.020849 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:47:45.021803 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:47:45.028379 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:47:45.028379 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:47:45.028379 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:47:45.045369 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:47:45.046407 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:47:45.046407 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:47:45.046949 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:47:45.046949 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:47:45.046949 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:47:45.047977 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:47:45.048979 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:47:45.048979 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:47:45.049528 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:47:45.049528 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:47:45.049528 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:47:45.054016 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:47:45.058654 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:47:45.058654 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:47:45.060153 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:45.075151 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:47:45.076138 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:47:45.076138 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:47:45.117610 [debug] [ThreadPool]: SQL status: OK in 0.041 seconds
[0m15:47:45.119116 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:47:45.120113 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:47:45.120113 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:47:45.124587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '695f9788-87b8-493c-b61d-981d67492255', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C5C33D5490>]}
[0m15:47:45.125584 [debug] [MainThread]: Using duckdb connection "master"
[0m15:47:45.125584 [debug] [MainThread]: On master: BEGIN
[0m15:47:45.125584 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:47:45.141480 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:47:45.142477 [debug] [MainThread]: On master: COMMIT
[0m15:47:45.142477 [debug] [MainThread]: Using duckdb connection "master"
[0m15:47:45.142477 [debug] [MainThread]: On master: COMMIT
[0m15:47:45.143796 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:47:45.143796 [debug] [MainThread]: On master: Close
[0m15:47:45.148442 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m15:47:45.149471 [info ] [Thread-1 (]: 1 of 1 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m15:47:45.149471 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m15:47:45.150729 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m15:47:45.156738 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m15:47:45.157243 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m15:47:45.190401 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m15:47:45.191429 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:47:45.191931 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m15:47:45.192441 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:47:45.209641 [debug] [Thread-1 (]: SQL status: OK in 0.017 seconds
[0m15:47:45.210461 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:47:45.210974 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    commit.author.name,
    commit.author.date,
    commit.url,
    author.id,
from raw
  );

[0m15:47:45.211967 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    commit.author.name,
    commit.author.date,
    commit.url,
    author.id,
from raw
  );

[0m15:47:45.211967 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:47:45.211967 [debug] [Thread-1 (]: On model.archi.cleancommit: ROLLBACK
[0m15:47:45.217005 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommit'
[0m15:47:45.217513 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m15:47:45.222037 [debug] [Thread-1 (]: Runtime Error in model cleancommit (models\duckdb\cleancommit.sql)
  Binder Error: Referenced table "commit" not found!
  Candidate tables: "raw"
  LINE 17:     commit.author.name,
               ^
[0m15:47:45.224075 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '695f9788-87b8-493c-b61d-981d67492255', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C5C37A5B80>]}
[0m15:47:45.225071 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main_cleansed.cleancommit ................. [[31mERROR[0m in 0.07s]
[0m15:47:45.226069 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m15:47:45.226069 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommit' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommit (models\duckdb\cleancommit.sql)
  Binder Error: Referenced table "commit" not found!
  Candidate tables: "raw"
  LINE 17:     commit.author.name,
               ^.
[0m15:47:45.228063 [debug] [MainThread]: Using duckdb connection "master"
[0m15:47:45.228063 [debug] [MainThread]: On master: BEGIN
[0m15:47:45.228063 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:47:45.245068 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:47:45.245068 [debug] [MainThread]: On master: COMMIT
[0m15:47:45.245068 [debug] [MainThread]: Using duckdb connection "master"
[0m15:47:45.246065 [debug] [MainThread]: On master: COMMIT
[0m15:47:45.246572 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:47:45.246607 [debug] [MainThread]: On master: Close
[0m15:47:45.249596 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:47:45.249596 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:47:45.250591 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:47:45.250692 [debug] [MainThread]: Connection 'model.archi.cleancommit' was properly closed.
[0m15:47:45.250692 [info ] [MainThread]: 
[0m15:47:45.251556 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.34 seconds (0.34s).
[0m15:47:45.251556 [debug] [MainThread]: Command end result
[0m15:47:45.268618 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:47:45.270817 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:47:45.275890 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:47:45.276867 [info ] [MainThread]: 
[0m15:47:45.276867 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:47:45.277864 [info ] [MainThread]: 
[0m15:47:45.277864 [error] [MainThread]:   Runtime Error in model cleancommit (models\duckdb\cleancommit.sql)
  Binder Error: Referenced table "commit" not found!
  Candidate tables: "raw"
  LINE 17:     commit.author.name,
               ^
[0m15:47:45.278862 [info ] [MainThread]: 
[0m15:47:45.278862 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:47:45.279860 [debug] [MainThread]: Command `dbt build` failed at 15:47:45.279860 after 1.46 seconds
[0m15:47:45.280858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C5C1CA23F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C5C03C7860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C5C2B0B590>]}
[0m15:47:45.280858 [debug] [MainThread]: Flushing usage events
[0m15:47:45.889466 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:48:10.436646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E56FF9550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E56FFA930>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E56FD39E0>]}


============================== 15:48:10.441154 | a66b428b-ceb6-4a3b-b55e-250b7d862c26 ==============================
[0m15:48:10.441154 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:48:10.442138 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt build', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:48:10.647258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a66b428b-ceb6-4a3b-b55e-250b7d862c26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E5602A690>]}
[0m15:48:10.706583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a66b428b-ceb6-4a3b-b55e-250b7d862c26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E57945790>]}
[0m15:48:10.710319 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:48:10.963794 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:48:11.094499 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:48:11.094499 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleancommit.sql
[0m15:48:11.326327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a66b428b-ceb6-4a3b-b55e-250b7d862c26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E57F53500>]}
[0m15:48:11.372851 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:48:11.374846 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:48:11.410101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a66b428b-ceb6-4a3b-b55e-250b7d862c26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E583BC9B0>]}
[0m15:48:11.411071 [info ] [MainThread]: Found 1 model, 424 macros
[0m15:48:11.413085 [info ] [MainThread]: 
[0m15:48:11.413085 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:48:11.414081 [info ] [MainThread]: 
[0m15:48:11.414081 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:48:11.415261 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:48:11.497033 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:48:11.497033 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:48:11.498060 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:48:11.516343 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:48:11.517350 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:48:11.520334 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:48:11.521700 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:48:11.528078 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:48:11.528078 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:48:11.528078 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:48:11.545123 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:48:11.546022 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:48:11.547015 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:48:11.547015 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:48:11.548009 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:48:11.548009 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:48:11.548009 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:48:11.549024 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:48:11.549024 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:48:11.550021 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:48:11.550021 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:48:11.550021 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:48:11.554791 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:48:11.559302 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:48:11.559302 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:48:11.560729 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:48:11.575090 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m15:48:11.576088 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:48:11.576595 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:48:11.617696 [debug] [ThreadPool]: SQL status: OK in 0.041 seconds
[0m15:48:11.619587 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:48:11.620581 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:48:11.620581 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:48:11.625571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a66b428b-ceb6-4a3b-b55e-250b7d862c26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E57D09640>]}
[0m15:48:11.625571 [debug] [MainThread]: Using duckdb connection "master"
[0m15:48:11.626533 [debug] [MainThread]: On master: BEGIN
[0m15:48:11.626533 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:48:11.641567 [debug] [MainThread]: SQL status: OK in 0.015 seconds
[0m15:48:11.642565 [debug] [MainThread]: On master: COMMIT
[0m15:48:11.642565 [debug] [MainThread]: Using duckdb connection "master"
[0m15:48:11.642565 [debug] [MainThread]: On master: COMMIT
[0m15:48:11.642565 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:48:11.644005 [debug] [MainThread]: On master: Close
[0m15:48:11.648236 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m15:48:11.649263 [info ] [Thread-1 (]: 1 of 1 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m15:48:11.650229 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m15:48:11.650229 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m15:48:11.657580 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m15:48:11.657630 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m15:48:11.690906 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m15:48:11.691932 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:48:11.691932 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m15:48:11.692939 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:48:11.708453 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:48:11.708453 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:48:11.709450 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m15:48:11.709450 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:48:11.716109 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:48:11.716109 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m15:48:11.717138 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:48:11.726510 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m15:48:11.726510 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:48:11.727538 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m15:48:11.730500 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:48:11.735683 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:48:11.735683 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m15:48:11.736686 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:48:11.738250 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m15:48:11.775049 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a66b428b-ceb6-4a3b-b55e-250b7d862c26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E588EB500>]}
[0m15:48:11.776046 [info ] [Thread-1 (]: 1 of 1 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.12s]
[0m15:48:11.777417 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m15:48:11.778315 [debug] [MainThread]: Using duckdb connection "master"
[0m15:48:11.778315 [debug] [MainThread]: On master: BEGIN
[0m15:48:11.778315 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:48:11.800196 [debug] [MainThread]: SQL status: OK in 0.022 seconds
[0m15:48:11.801194 [debug] [MainThread]: On master: COMMIT
[0m15:48:11.801194 [debug] [MainThread]: Using duckdb connection "master"
[0m15:48:11.801194 [debug] [MainThread]: On master: COMMIT
[0m15:48:11.802191 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:48:11.802191 [debug] [MainThread]: On master: Close
[0m15:48:11.805034 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:48:11.806032 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:48:11.806032 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:48:11.806540 [debug] [MainThread]: Connection 'model.archi.cleancommit' was properly closed.
[0m15:48:11.807046 [info ] [MainThread]: 
[0m15:48:11.807046 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.39 seconds (0.39s).
[0m15:48:11.808042 [debug] [MainThread]: Command end result
[0m15:48:11.824025 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:48:11.827014 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:48:11.832013 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:48:11.833011 [info ] [MainThread]: 
[0m15:48:11.833011 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:48:11.834562 [info ] [MainThread]: 
[0m15:48:11.834562 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:48:11.835457 [debug] [MainThread]: Command `dbt build` succeeded at 15:48:11.835457 after 1.51 seconds
[0m15:48:11.836454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E51DBFF50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E57E58860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E55BECD10>]}
[0m15:48:11.836454 [debug] [MainThread]: Flushing usage events
[0m15:48:12.818987 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:50:27.463785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA5DEDFA70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA610812E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA61083020>]}


============================== 15:50:27.467774 | fb323e0d-6b2e-458f-8a3f-d5ac7feb8245 ==============================
[0m15:50:27.467774 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:50:27.468777 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m15:50:27.678815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fb323e0d-6b2e-458f-8a3f-d5ac7feb8245', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA610290A0>]}
[0m15:50:27.737001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fb323e0d-6b2e-458f-8a3f-d5ac7feb8245', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA6212F3B0>]}
[0m15:50:27.741117 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:50:27.989874 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:50:28.106777 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m15:50:28.106777 [debug] [MainThread]: Partial parsing: added file: archi://models\duckdb\cleancontributor.sql
[0m15:50:28.337815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fb323e0d-6b2e-458f-8a3f-d5ac7feb8245', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA62F574A0>]}
[0m15:50:28.383954 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:50:28.386402 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:50:28.421580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fb323e0d-6b2e-458f-8a3f-d5ac7feb8245', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA633BC6E0>]}
[0m15:50:28.422577 [info ] [MainThread]: Found 2 models, 424 macros
[0m15:50:28.424104 [info ] [MainThread]: 
[0m15:50:28.425144 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:50:28.425144 [info ] [MainThread]: 
[0m15:50:28.426203 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:50:28.429612 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:50:28.514399 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:50:28.514399 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:50:28.515397 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:50:28.532973 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:50:28.534983 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:50:28.538483 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:50:28.539511 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:50:28.545368 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:50:28.545368 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:50:28.545368 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:50:28.561901 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:50:28.562929 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:50:28.562929 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:50:28.562929 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:50:28.562929 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:50:28.564453 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:50:28.564453 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:50:28.565385 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:50:28.565385 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:50:28.565385 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:50:28.566391 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:50:28.566391 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:50:28.571681 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:50:28.576372 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:50:28.576372 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:50:28.577372 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:50:28.593457 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:50:28.593997 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:50:28.593997 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:50:28.636461 [debug] [ThreadPool]: SQL status: OK in 0.042 seconds
[0m15:50:28.637457 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:50:28.639452 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:50:28.639452 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:50:28.643979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fb323e0d-6b2e-458f-8a3f-d5ac7feb8245', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA5E6AB7A0>]}
[0m15:50:28.644945 [debug] [MainThread]: Using duckdb connection "master"
[0m15:50:28.644945 [debug] [MainThread]: On master: BEGIN
[0m15:50:28.644945 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:50:28.661590 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m15:50:28.661590 [debug] [MainThread]: On master: COMMIT
[0m15:50:28.661590 [debug] [MainThread]: Using duckdb connection "master"
[0m15:50:28.662495 [debug] [MainThread]: On master: COMMIT
[0m15:50:28.663002 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:50:28.663002 [debug] [MainThread]: On master: Close
[0m15:50:28.667796 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m15:50:28.668303 [info ] [Thread-1 (]: 1 of 2 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m15:50:28.668303 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m15:50:28.669298 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m15:50:28.676860 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m15:50:28.677404 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m15:50:28.706933 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m15:50:28.707960 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:50:28.707960 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m15:50:28.708984 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:50:28.724600 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:50:28.725609 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:50:28.725609 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m15:50:28.726605 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:50:28.732281 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:50:28.732281 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m15:50:28.732281 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:50:28.735715 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:50:28.735715 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m15:50:28.736712 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:50:28.749209 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m15:50:28.749209 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:50:28.749209 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m15:50:28.753337 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:50:28.757448 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:50:28.758475 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m15:50:28.759974 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:50:28.762546 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m15:50:28.798574 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb323e0d-6b2e-458f-8a3f-d5ac7feb8245', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA62977530>]}
[0m15:50:28.799571 [info ] [Thread-1 (]: 1 of 2 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.13s]
[0m15:50:28.800569 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m15:50:28.800569 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m15:50:28.801566 [info ] [Thread-1 (]: 2 of 2 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m15:50:28.802562 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m15:50:28.802562 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m15:50:28.805071 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m15:50:28.806069 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m15:50:28.810071 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m15:50:28.811069 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:50:28.811621 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m15:50:28.812197 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:50:28.833136 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m15:50:28.833136 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:50:28.834581 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m15:50:28.834581 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:50:28.838023 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:50:28.838023 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m15:50:28.839067 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:50:28.839577 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m15:50:28.840602 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:50:28.840602 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m15:50:28.843115 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m15:50:28.844701 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:50:28.845724 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m15:50:28.845724 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:50:28.847270 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m15:50:28.882076 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb323e0d-6b2e-458f-8a3f-d5ac7feb8245', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA639D8320>]}
[0m15:50:28.882982 [info ] [Thread-1 (]: 2 of 2 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.08s]
[0m15:50:28.883949 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m15:50:28.884994 [debug] [MainThread]: Using duckdb connection "master"
[0m15:50:28.885502 [debug] [MainThread]: On master: BEGIN
[0m15:50:28.885582 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:50:28.907537 [debug] [MainThread]: SQL status: OK in 0.022 seconds
[0m15:50:28.907537 [debug] [MainThread]: On master: COMMIT
[0m15:50:28.908045 [debug] [MainThread]: Using duckdb connection "master"
[0m15:50:28.908045 [debug] [MainThread]: On master: COMMIT
[0m15:50:28.908045 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:50:28.909039 [debug] [MainThread]: On master: Close
[0m15:50:28.912196 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:50:28.912196 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:50:28.912196 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:50:28.913194 [debug] [MainThread]: Connection 'model.archi.cleancontributor' was properly closed.
[0m15:50:28.913194 [info ] [MainThread]: 
[0m15:50:28.913194 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.49 seconds (0.49s).
[0m15:50:28.914394 [debug] [MainThread]: Command end result
[0m15:50:28.929883 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:50:28.931385 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:50:28.937385 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:50:28.937385 [info ] [MainThread]: 
[0m15:50:28.938383 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:50:28.938383 [info ] [MainThread]: 
[0m15:50:28.939729 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:50:28.940710 [debug] [MainThread]: Command `dbt build` succeeded at 15:50:28.940710 after 1.63 seconds
[0m15:50:28.940710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA61FD3830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA61C483B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA61C49490>]}
[0m15:50:28.941707 [debug] [MainThread]: Flushing usage events
[0m15:50:29.799249 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:58:57.425211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020CF7986E70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020CF6AA0800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020CF6AA3AD0>]}


============================== 15:58:57.429362 | d4c55e34-3892-4a20-b84b-b66ce83c281b ==============================
[0m15:58:57.429362 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:58:57.430364 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:58:57.643554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd4c55e34-3892-4a20-b84b-b66ce83c281b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020CF6B85AF0>]}
[0m15:58:57.705030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd4c55e34-3892-4a20-b84b-b66ce83c281b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020CF6A1FB00>]}
[0m15:58:57.709565 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:58:57.976143 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:58:58.098568 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m15:58:58.099597 [debug] [MainThread]: Partial parsing: added file: archi://models\duckdb\cleanpr.sql
[0m15:58:58.336019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd4c55e34-3892-4a20-b84b-b66ce83c281b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020CF8E33F80>]}
[0m15:58:58.384276 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:58:58.386561 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:58:58.421213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd4c55e34-3892-4a20-b84b-b66ce83c281b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020CF8FE15E0>]}
[0m15:58:58.422124 [info ] [MainThread]: Found 3 models, 424 macros
[0m15:58:58.424101 [info ] [MainThread]: 
[0m15:58:58.425461 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:58:58.425517 [info ] [MainThread]: 
[0m15:58:58.426491 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:58:58.430502 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:58:58.512286 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:58:58.513842 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:58:58.513842 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:58:58.532831 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:58:58.533848 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:58:58.536880 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:58:58.537874 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:58:58.544015 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:58:58.544015 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:58:58.545009 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:58:58.561950 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m15:58:58.562950 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:58:58.563910 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:58:58.563910 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:58:58.563910 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:58:58.564907 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:58:58.564907 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:58:58.566091 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:58:58.566207 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:58:58.566207 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:58:58.567090 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:58:58.567090 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:58:58.571330 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:58:58.577310 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:58:58.577310 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:58:58.577310 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:58:58.594125 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m15:58:58.594125 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:58:58.595101 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:58:58.637088 [debug] [ThreadPool]: SQL status: OK in 0.042 seconds
[0m15:58:58.638022 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:58:58.639015 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:58:58.640015 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:58:58.645716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd4c55e34-3892-4a20-b84b-b66ce83c281b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020CF41AB350>]}
[0m15:58:58.646343 [debug] [MainThread]: Using duckdb connection "master"
[0m15:58:58.646388 [debug] [MainThread]: On master: BEGIN
[0m15:58:58.646388 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:58:58.663659 [debug] [MainThread]: SQL status: OK in 0.017 seconds
[0m15:58:58.663659 [debug] [MainThread]: On master: COMMIT
[0m15:58:58.663659 [debug] [MainThread]: Using duckdb connection "master"
[0m15:58:58.664568 [debug] [MainThread]: On master: COMMIT
[0m15:58:58.665161 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:58:58.665161 [debug] [MainThread]: On master: Close
[0m15:58:58.669699 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m15:58:58.669699 [info ] [Thread-1 (]: 1 of 3 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m15:58:58.670694 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m15:58:58.670694 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m15:58:58.677194 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m15:58:58.678179 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m15:58:58.707705 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m15:58:58.708643 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:58:58.709638 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m15:58:58.709638 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:58:58.726374 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:58:58.726374 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:58:58.727381 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m15:58:58.728291 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:58:58.733891 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:58:58.733891 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m15:58:58.734768 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:58:58.736867 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:58:58.736867 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m15:58:58.737862 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:58:58.748940 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m15:58:58.749876 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:58:58.749876 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m15:58:58.753307 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:58:58.757763 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:58:58.758271 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m15:58:58.759266 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:58:58.761844 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m15:58:58.798809 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd4c55e34-3892-4a20-b84b-b66ce83c281b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020CF8B75AC0>]}
[0m15:58:58.798809 [info ] [Thread-1 (]: 1 of 3 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.13s]
[0m15:58:58.799789 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m15:58:58.799789 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m15:58:58.800818 [info ] [Thread-1 (]: 2 of 3 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m15:58:58.801784 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m15:58:58.801784 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m15:58:58.803362 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m15:58:58.804385 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m15:58:58.808256 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m15:58:58.809222 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:58:58.809222 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m15:58:58.810220 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:58:58.832138 [debug] [Thread-1 (]: SQL status: OK in 0.022 seconds
[0m15:58:58.832646 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:58:58.833153 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m15:58:58.833662 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:58:58.836192 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:58:58.836192 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m15:58:58.837187 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:58:58.839691 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:58:58.839691 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m15:58:58.840264 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:58:58.841766 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m15:58:58.841766 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:58:58.842609 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m15:58:58.844644 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m15:58:58.846709 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:58:58.846709 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m15:58:58.848535 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:58:58.849042 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m15:58:58.883575 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd4c55e34-3892-4a20-b84b-b66ce83c281b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020CF96B5EE0>]}
[0m15:58:58.884572 [info ] [Thread-1 (]: 2 of 3 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.08s]
[0m15:58:58.885897 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m15:58:58.885897 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m15:58:58.885897 [info ] [Thread-1 (]: 3 of 3 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m15:58:58.886844 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanpr)
[0m15:58:58.886844 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m15:58:58.888839 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m15:58:58.889836 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m15:58:58.893675 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m15:58:58.894227 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:58:58.894227 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m15:58:58.895178 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:58:58.916931 [debug] [Thread-1 (]: SQL status: OK in 0.022 seconds
[0m15:58:58.916931 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:58:58.916931 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m15:58:58.917928 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:58:58.921371 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:58:58.921914 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m15:58:58.921914 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:58:58.922937 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m15:58:58.923879 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:58:58.923879 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m15:58:58.925910 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:58:58.927936 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:58:58.927936 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m15:58:58.928941 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:58:58.929931 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m15:58:58.970934 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd4c55e34-3892-4a20-b84b-b66ce83c281b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020CF962F1A0>]}
[0m15:58:58.971441 [info ] [Thread-1 (]: 3 of 3 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.08s]
[0m15:58:58.972436 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m15:58:58.973371 [debug] [MainThread]: Using duckdb connection "master"
[0m15:58:58.973878 [debug] [MainThread]: On master: BEGIN
[0m15:58:58.973878 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:58:58.996522 [debug] [MainThread]: SQL status: OK in 0.023 seconds
[0m15:58:58.996522 [debug] [MainThread]: On master: COMMIT
[0m15:58:58.997445 [debug] [MainThread]: Using duckdb connection "master"
[0m15:58:58.997445 [debug] [MainThread]: On master: COMMIT
[0m15:58:58.998007 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:58:58.998007 [debug] [MainThread]: On master: Close
[0m15:58:59.000942 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:58:59.001940 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:58:59.001940 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:58:59.001940 [debug] [MainThread]: Connection 'model.archi.cleanpr' was properly closed.
[0m15:58:59.002942 [info ] [MainThread]: 
[0m15:58:59.003508 [info ] [MainThread]: Finished running 3 view models in 0 hours 0 minutes and 0.58 seconds (0.58s).
[0m15:58:59.004445 [debug] [MainThread]: Command end result
[0m15:58:59.021359 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:58:59.023496 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:58:59.029449 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:58:59.029449 [info ] [MainThread]: 
[0m15:58:59.030445 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:58:59.030445 [info ] [MainThread]: 
[0m15:58:59.031443 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m15:58:59.032443 [debug] [MainThread]: Command `dbt build` succeeded at 15:58:59.032443 after 1.76 seconds
[0m15:58:59.033038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020CF774AF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020CF77496D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020CF7DEACF0>]}
[0m15:58:59.033546 [debug] [MainThread]: Flushing usage events
[0m15:59:00.070553 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:00:34.109448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A0AEF800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A4667350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A4665010>]}


============================== 16:00:34.114391 | 73c2e50f-cab2-42dc-be2b-ee56592f3aff ==============================
[0m16:00:34.114391 [info ] [MainThread]: Running with dbt=1.9.1
[0m16:00:34.114391 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt build', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:00:34.323089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '73c2e50f-cab2-42dc-be2b-ee56592f3aff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A4BA88C0>]}
[0m16:00:34.382144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '73c2e50f-cab2-42dc-be2b-ee56592f3aff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A09E85C0>]}
[0m16:00:34.386132 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m16:00:34.643848 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m16:00:34.765367 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m16:00:34.765367 [debug] [MainThread]: Partial parsing: added file: archi://models\duckdb\cleanissue.sql
[0m16:00:34.997611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '73c2e50f-cab2-42dc-be2b-ee56592f3aff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A571B3E0>]}
[0m16:00:35.044471 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:00:35.046470 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:00:35.082705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '73c2e50f-cab2-42dc-be2b-ee56592f3aff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A5CE5610>]}
[0m16:00:35.083210 [info ] [MainThread]: Found 4 models, 424 macros
[0m16:00:35.085243 [info ] [MainThread]: 
[0m16:00:35.085772 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:00:35.086281 [info ] [MainThread]: 
[0m16:00:35.086790 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m16:00:35.090955 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m16:00:35.173823 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:00:35.174393 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:00:35.174393 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:00:35.192548 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m16:00:35.194051 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:00:35.197476 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m16:00:35.198826 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m16:00:35.203928 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:00:35.203928 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:00:35.204957 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:00:35.220638 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:00:35.222181 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:00:35.222724 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m16:00:35.222724 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:00:35.222724 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:00:35.223717 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m16:00:35.223717 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:00:35.224781 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:00:35.224781 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:00:35.225899 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:00:35.225899 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:00:35.226875 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m16:00:35.231437 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m16:00:35.236441 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:00:35.236441 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m16:00:35.237382 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:00:35.252382 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:00:35.253384 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:00:35.253896 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:00:35.294770 [debug] [ThreadPool]: SQL status: OK in 0.041 seconds
[0m16:00:35.296963 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m16:00:35.298506 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m16:00:35.298592 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m16:00:35.303813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '73c2e50f-cab2-42dc-be2b-ee56592f3aff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A5FD01A0>]}
[0m16:00:35.303813 [debug] [MainThread]: Using duckdb connection "master"
[0m16:00:35.304753 [debug] [MainThread]: On master: BEGIN
[0m16:00:35.304753 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:00:35.320076 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m16:00:35.321082 [debug] [MainThread]: On master: COMMIT
[0m16:00:35.321082 [debug] [MainThread]: Using duckdb connection "master"
[0m16:00:35.321623 [debug] [MainThread]: On master: COMMIT
[0m16:00:35.321623 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:00:35.321623 [debug] [MainThread]: On master: Close
[0m16:00:35.327343 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m16:00:35.327343 [info ] [Thread-1 (]: 1 of 4 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m16:00:35.328990 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m16:00:35.329498 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m16:00:35.335532 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m16:00:35.336217 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m16:00:35.366493 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m16:00:35.366493 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:00:35.367479 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m16:00:35.367479 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:00:35.383635 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m16:00:35.383635 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:00:35.383635 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m16:00:35.384621 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:35.390176 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:00:35.390721 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m16:00:35.390721 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:35.393778 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:00:35.394759 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m16:00:35.396256 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:00:35.406758 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:00:35.407299 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:00:35.407299 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:00:35.409998 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m16:00:35.415192 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:00:35.415192 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m16:00:35.416159 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:00:35.418313 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m16:00:35.454743 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73c2e50f-cab2-42dc-be2b-ee56592f3aff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A0F09AF0>]}
[0m16:00:35.455310 [info ] [Thread-1 (]: 1 of 4 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.12s]
[0m16:00:35.456245 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m16:00:35.456245 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m16:00:35.456245 [info ] [Thread-1 (]: 2 of 4 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m16:00:35.457242 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m16:00:35.457856 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m16:00:35.459910 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m16:00:35.459910 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m16:00:35.465091 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m16:00:35.466109 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:00:35.466109 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m16:00:35.466109 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:00:35.488763 [debug] [Thread-1 (]: SQL status: OK in 0.022 seconds
[0m16:00:35.488763 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:00:35.489674 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m16:00:35.489674 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:35.492666 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:00:35.492666 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m16:00:35.493663 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:35.497190 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:00:35.497190 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m16:00:35.498159 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:35.498159 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:00:35.499769 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:00:35.499769 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:00:35.501832 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:00:35.503917 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:00:35.503917 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m16:00:35.504809 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:00:35.505834 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m16:00:35.541036 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73c2e50f-cab2-42dc-be2b-ee56592f3aff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A63CF8F0>]}
[0m16:00:35.541036 [info ] [Thread-1 (]: 2 of 4 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.08s]
[0m16:00:35.542546 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m16:00:35.543057 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m16:00:35.543057 [info ] [Thread-1 (]: 3 of 4 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m16:00:35.543564 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m16:00:35.544070 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m16:00:35.546121 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m16:00:35.547106 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m16:00:35.549946 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m16:00:35.550941 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:00:35.551485 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m16:00:35.551492 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:00:35.572093 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m16:00:35.573090 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:00:35.573090 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user_id",
    created_at
from raw
  );

[0m16:00:35.574441 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user_id",
    created_at
from raw
  );

[0m16:00:35.574441 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m16:00:35.575436 [debug] [Thread-1 (]: On model.archi.cleanissue: ROLLBACK
[0m16:00:35.580846 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanissue'
[0m16:00:35.580846 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m16:00:35.586967 [debug] [Thread-1 (]: Runtime Error in model cleanissue (models\duckdb\cleanissue.sql)
  Binder Error: Referenced column "user_id" not found in FROM clause!
  Candidate bindings: "raw.user.id"
  LINE 19:     "user_id",
               ^
[0m16:00:35.587474 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73c2e50f-cab2-42dc-be2b-ee56592f3aff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A63EE420>]}
[0m16:00:35.587981 [error] [Thread-1 (]: 3 of 4 ERROR creating sql view model main_cleansed.cleanissue .................. [[31mERROR[0m in 0.04s]
[0m16:00:35.588489 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m16:00:35.588995 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m16:00:35.589501 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanissue' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanissue (models\duckdb\cleanissue.sql)
  Binder Error: Referenced column "user_id" not found in FROM clause!
  Candidate bindings: "raw.user.id"
  LINE 19:     "user_id",
               ^.
[0m16:00:35.589501 [info ] [Thread-1 (]: 4 of 4 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m16:00:35.590498 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m16:00:35.590498 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m16:00:35.592598 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m16:00:35.593939 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m16:00:35.597200 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m16:00:35.598177 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:00:35.598177 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m16:00:35.599174 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:00:35.615576 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m16:00:35.615576 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:00:35.616582 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m16:00:35.617125 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:00:35.620235 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:00:35.620235 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m16:00:35.620235 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:35.622811 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:00:35.623837 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m16:00:35.623837 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:35.625383 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:00:35.625925 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:00:35.625925 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:00:35.626918 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:00:35.630346 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:00:35.630346 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m16:00:35.631855 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:00:35.632887 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m16:00:35.665784 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73c2e50f-cab2-42dc-be2b-ee56592f3aff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A6E56660>]}
[0m16:00:35.666709 [info ] [Thread-1 (]: 4 of 4 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.08s]
[0m16:00:35.667310 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m16:00:35.668212 [debug] [MainThread]: Using duckdb connection "master"
[0m16:00:35.668212 [debug] [MainThread]: On master: BEGIN
[0m16:00:35.668212 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:00:35.689821 [debug] [MainThread]: SQL status: OK in 0.021 seconds
[0m16:00:35.689821 [debug] [MainThread]: On master: COMMIT
[0m16:00:35.690818 [debug] [MainThread]: Using duckdb connection "master"
[0m16:00:35.690818 [debug] [MainThread]: On master: COMMIT
[0m16:00:35.690818 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:00:35.691821 [debug] [MainThread]: On master: Close
[0m16:00:35.695907 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:00:35.696414 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m16:00:35.696414 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m16:00:35.696920 [debug] [MainThread]: Connection 'model.archi.cleanpr' was properly closed.
[0m16:00:35.696920 [info ] [MainThread]: 
[0m16:00:35.696920 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 0.61 seconds (0.61s).
[0m16:00:35.698945 [debug] [MainThread]: Command end result
[0m16:00:35.716091 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:00:35.718514 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:00:35.724128 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m16:00:35.724128 [info ] [MainThread]: 
[0m16:00:35.724128 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m16:00:35.725160 [info ] [MainThread]: 
[0m16:00:35.725749 [error] [MainThread]:   Runtime Error in model cleanissue (models\duckdb\cleanissue.sql)
  Binder Error: Referenced column "user_id" not found in FROM clause!
  Candidate bindings: "raw.user.id"
  LINE 19:     "user_id",
               ^
[0m16:00:35.726300 [info ] [MainThread]: 
[0m16:00:35.727283 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m16:00:35.728293 [debug] [MainThread]: Command `dbt build` failed at 16:00:35.728293 after 1.77 seconds
[0m16:00:35.728293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A4AEB1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A49A3890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207A49A2960>]}
[0m16:00:35.729309 [debug] [MainThread]: Flushing usage events
[0m16:00:36.856972 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:00:47.967649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021499919B20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149AAC0530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149C3A3EC0>]}


============================== 16:00:47.972142 | 206df551-64ef-4e3b-9149-724c752269c2 ==============================
[0m16:00:47.972142 [info ] [MainThread]: Running with dbt=1.9.1
[0m16:00:47.972142 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:00:48.183886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '206df551-64ef-4e3b-9149-724c752269c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149E0DB920>]}
[0m16:00:48.242642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '206df551-64ef-4e3b-9149-724c752269c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149C3F5C10>]}
[0m16:00:48.247432 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m16:00:48.497956 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m16:00:48.616110 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:00:48.617108 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleanissue.sql
[0m16:00:48.851376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '206df551-64ef-4e3b-9149-724c752269c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149E94C650>]}
[0m16:00:48.900462 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:00:48.902040 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:00:48.937042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '206df551-64ef-4e3b-9149-724c752269c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149EAE1DF0>]}
[0m16:00:48.938067 [info ] [MainThread]: Found 4 models, 424 macros
[0m16:00:48.940114 [info ] [MainThread]: 
[0m16:00:48.940114 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:00:48.941112 [info ] [MainThread]: 
[0m16:00:48.941112 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m16:00:48.946486 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m16:00:49.028273 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:00:49.028273 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:00:49.029231 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:00:49.046869 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m16:00:49.047863 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:00:49.051331 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m16:00:49.052341 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m16:00:49.058306 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:00:49.058306 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:00:49.059304 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:00:49.075521 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:00:49.076519 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:00:49.077547 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m16:00:49.077547 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:00:49.077547 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:00:49.078546 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m16:00:49.078546 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:00:49.079667 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:00:49.079667 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:00:49.079667 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:00:49.080573 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:00:49.080573 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m16:00:49.085076 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m16:00:49.090536 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:00:49.090536 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m16:00:49.091469 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:00:49.106284 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:00:49.107250 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:00:49.107757 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:00:49.149761 [debug] [ThreadPool]: SQL status: OK in 0.042 seconds
[0m16:00:49.150754 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m16:00:49.152262 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m16:00:49.152770 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m16:00:49.158260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '206df551-64ef-4e3b-9149-724c752269c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149E9A22D0>]}
[0m16:00:49.158260 [debug] [MainThread]: Using duckdb connection "master"
[0m16:00:49.159258 [debug] [MainThread]: On master: BEGIN
[0m16:00:49.159258 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:00:49.175239 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m16:00:49.175745 [debug] [MainThread]: On master: COMMIT
[0m16:00:49.175745 [debug] [MainThread]: Using duckdb connection "master"
[0m16:00:49.175745 [debug] [MainThread]: On master: COMMIT
[0m16:00:49.176773 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:00:49.176773 [debug] [MainThread]: On master: Close
[0m16:00:49.181413 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m16:00:49.181413 [info ] [Thread-1 (]: 1 of 4 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m16:00:49.182439 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m16:00:49.182439 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m16:00:49.190489 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m16:00:49.191486 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m16:00:49.221085 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m16:00:49.221625 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:00:49.221625 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m16:00:49.222648 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:00:49.238269 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m16:00:49.239264 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:00:49.239264 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m16:00:49.240228 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:49.246435 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:00:49.246435 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m16:00:49.247490 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:49.249003 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:00:49.250027 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m16:00:49.250027 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:49.262322 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:00:49.262863 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:00:49.262863 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:00:49.266636 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m16:00:49.270802 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:00:49.271340 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m16:00:49.272396 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:00:49.274422 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m16:00:49.310354 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '206df551-64ef-4e3b-9149-724c752269c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149F06C770>]}
[0m16:00:49.310354 [info ] [Thread-1 (]: 1 of 4 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.13s]
[0m16:00:49.311830 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m16:00:49.311830 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m16:00:49.311830 [info ] [Thread-1 (]: 2 of 4 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m16:00:49.312823 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m16:00:49.313425 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m16:00:49.315406 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m16:00:49.315406 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m16:00:49.319534 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m16:00:49.320475 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:00:49.320475 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m16:00:49.321472 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:00:49.342828 [debug] [Thread-1 (]: SQL status: OK in 0.022 seconds
[0m16:00:49.344002 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:00:49.344100 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m16:00:49.345030 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:49.347533 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:00:49.347633 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m16:00:49.347633 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:49.350129 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:00:49.351093 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m16:00:49.351093 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:49.352910 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:00:49.352910 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:00:49.353937 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:00:49.354901 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:00:49.357900 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:00:49.357900 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m16:00:49.358889 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:00:49.360916 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m16:00:49.395366 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '206df551-64ef-4e3b-9149-724c752269c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149F1E0CE0>]}
[0m16:00:49.396361 [info ] [Thread-1 (]: 2 of 4 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.08s]
[0m16:00:49.397358 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m16:00:49.397358 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m16:00:49.397358 [info ] [Thread-1 (]: 3 of 4 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m16:00:49.398358 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m16:00:49.399114 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m16:00:49.400709 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m16:00:49.401673 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m16:00:49.404250 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m16:00:49.405212 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:00:49.405212 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m16:00:49.405212 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:00:49.426552 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m16:00:49.426552 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:00:49.427935 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user_id",
    created_at
from raw
  );

[0m16:00:49.427935 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user_id",
    created_at
from raw
  );

[0m16:00:49.429444 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m16:00:49.429444 [debug] [Thread-1 (]: On model.archi.cleanissue: ROLLBACK
[0m16:00:49.434510 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanissue'
[0m16:00:49.434599 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m16:00:49.439585 [debug] [Thread-1 (]: Runtime Error in model cleanissue (models\duckdb\cleanissue.sql)
  Binder Error: Referenced column "user_id" not found in FROM clause!
  Candidate bindings: "raw.user.id"
  LINE 19:     "user_id",
               ^
[0m16:00:49.440508 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '206df551-64ef-4e3b-9149-724c752269c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149F1E5850>]}
[0m16:00:49.441081 [error] [Thread-1 (]: 3 of 4 ERROR creating sql view model main_cleansed.cleanissue .................. [[31mERROR[0m in 0.04s]
[0m16:00:49.442011 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m16:00:49.442011 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m16:00:49.443008 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanissue' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanissue (models\duckdb\cleanissue.sql)
  Binder Error: Referenced column "user_id" not found in FROM clause!
  Candidate bindings: "raw.user.id"
  LINE 19:     "user_id",
               ^.
[0m16:00:49.443008 [info ] [Thread-1 (]: 4 of 4 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m16:00:49.444280 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m16:00:49.444280 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m16:00:49.446249 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m16:00:49.447241 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m16:00:49.450980 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m16:00:49.451518 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:00:49.452078 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m16:00:49.452613 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:00:49.468204 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m16:00:49.468723 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:00:49.469231 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m16:00:49.470226 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:00:49.472734 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:00:49.472734 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m16:00:49.473730 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:49.476215 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:00:49.477158 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m16:00:49.477158 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:49.478159 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:00:49.479584 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:00:49.479584 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:00:49.481630 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:00:49.483735 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:00:49.483735 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m16:00:49.484702 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:00:49.485699 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m16:00:49.520431 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '206df551-64ef-4e3b-9149-724c752269c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149F1DFDA0>]}
[0m16:00:49.521427 [info ] [Thread-1 (]: 4 of 4 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.08s]
[0m16:00:49.522736 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m16:00:49.523717 [debug] [MainThread]: Using duckdb connection "master"
[0m16:00:49.523717 [debug] [MainThread]: On master: BEGIN
[0m16:00:49.524770 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:00:49.546279 [debug] [MainThread]: SQL status: OK in 0.022 seconds
[0m16:00:49.546279 [debug] [MainThread]: On master: COMMIT
[0m16:00:49.547277 [debug] [MainThread]: Using duckdb connection "master"
[0m16:00:49.547277 [debug] [MainThread]: On master: COMMIT
[0m16:00:49.547277 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:00:49.548274 [debug] [MainThread]: On master: Close
[0m16:00:49.550738 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:00:49.551735 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m16:00:49.551735 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m16:00:49.552732 [debug] [MainThread]: Connection 'model.archi.cleanpr' was properly closed.
[0m16:00:49.552732 [info ] [MainThread]: 
[0m16:00:49.553730 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 0.61 seconds (0.61s).
[0m16:00:49.554885 [debug] [MainThread]: Command end result
[0m16:00:49.570960 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:00:49.572959 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:00:49.579226 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m16:00:49.579226 [info ] [MainThread]: 
[0m16:00:49.580226 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m16:00:49.580226 [info ] [MainThread]: 
[0m16:00:49.581188 [error] [MainThread]:   Runtime Error in model cleanissue (models\duckdb\cleanissue.sql)
  Binder Error: Referenced column "user_id" not found in FROM clause!
  Candidate bindings: "raw.user.id"
  LINE 19:     "user_id",
               ^
[0m16:00:49.582186 [info ] [MainThread]: 
[0m16:00:49.582186 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m16:00:49.583182 [debug] [MainThread]: Command `dbt build` failed at 16:00:49.583182 after 1.73 seconds
[0m16:00:49.584180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000214991E0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149E8C9AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002149CE3D220>]}
[0m16:00:49.584180 [debug] [MainThread]: Flushing usage events
[0m16:00:50.340547 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:01:02.259956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B00DDBE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B2DA1520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B2DA2C90>]}


============================== 16:01:02.263958 | 0a6b3c2d-9929-4521-b905-5b30fca496e6 ==============================
[0m16:01:02.263958 [info ] [MainThread]: Running with dbt=1.9.1
[0m16:01:02.264955 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:01:02.477384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0a6b3c2d-9929-4521-b905-5b30fca496e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B3229520>]}
[0m16:01:02.542325 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0a6b3c2d-9929-4521-b905-5b30fca496e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B4A2B020>]}
[0m16:01:02.545950 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m16:01:02.797711 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m16:01:02.925343 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:01:02.926336 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\cleanissue.sql
[0m16:01:03.160272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0a6b3c2d-9929-4521-b905-5b30fca496e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B514C2F0>]}
[0m16:01:03.207987 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:01:03.210073 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:01:03.246230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0a6b3c2d-9929-4521-b905-5b30fca496e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B54E5070>]}
[0m16:01:03.246230 [info ] [MainThread]: Found 4 models, 424 macros
[0m16:01:03.249028 [info ] [MainThread]: 
[0m16:01:03.249701 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:01:03.250208 [info ] [MainThread]: 
[0m16:01:03.250208 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m16:01:03.254195 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m16:01:03.336745 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:01:03.337307 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:01:03.337848 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:01:03.356546 [debug] [ThreadPool]: SQL status: OK in 0.019 seconds
[0m16:01:03.358542 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:01:03.362040 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m16:01:03.363071 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m16:01:03.368408 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:01:03.369354 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:01:03.369354 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:01:03.386946 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m16:01:03.387943 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:01:03.387943 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m16:01:03.389197 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:01:03.389197 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:01:03.389197 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m16:01:03.390201 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:01:03.390752 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:01:03.390752 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:01:03.390752 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:01:03.391737 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:01:03.391737 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m16:01:03.397217 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m16:01:03.402236 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:01:03.402236 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m16:01:03.402236 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:01:03.417917 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:01:03.418914 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:01:03.419498 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:01:03.460933 [debug] [ThreadPool]: SQL status: OK in 0.042 seconds
[0m16:01:03.462470 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m16:01:03.463630 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m16:01:03.463630 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m16:01:03.468642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0a6b3c2d-9929-4521-b905-5b30fca496e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B43F3590>]}
[0m16:01:03.468642 [debug] [MainThread]: Using duckdb connection "master"
[0m16:01:03.469885 [debug] [MainThread]: On master: BEGIN
[0m16:01:03.469885 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:01:03.485813 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m16:01:03.486811 [debug] [MainThread]: On master: COMMIT
[0m16:01:03.486811 [debug] [MainThread]: Using duckdb connection "master"
[0m16:01:03.486811 [debug] [MainThread]: On master: COMMIT
[0m16:01:03.487808 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:01:03.487808 [debug] [MainThread]: On master: Close
[0m16:01:03.492965 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m16:01:03.493982 [info ] [Thread-1 (]: 1 of 4 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m16:01:03.493982 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m16:01:03.495015 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m16:01:03.501625 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m16:01:03.502588 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m16:01:03.533431 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m16:01:03.534455 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:01:03.534455 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m16:01:03.535459 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:01:03.551316 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m16:01:03.551925 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:01:03.552435 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m16:01:03.553486 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:03.559149 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:01:03.559149 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m16:01:03.560146 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:03.562966 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:01:03.562966 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m16:01:03.563991 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:03.574971 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:01:03.575479 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:01:03.575479 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:01:03.579482 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m16:01:03.583762 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:01:03.583762 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m16:01:03.585489 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:01:03.588057 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m16:01:03.623000 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a6b3c2d-9929-4521-b905-5b30fca496e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B5134AA0>]}
[0m16:01:03.623929 [info ] [Thread-1 (]: 1 of 4 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.13s]
[0m16:01:03.623929 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m16:01:03.624910 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m16:01:03.624910 [info ] [Thread-1 (]: 2 of 4 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m16:01:03.625875 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m16:01:03.626441 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m16:01:03.628408 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m16:01:03.629408 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m16:01:03.632744 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m16:01:03.633772 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:01:03.634784 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m16:01:03.634784 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:01:03.656146 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m16:01:03.656146 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:01:03.657145 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m16:01:03.657145 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:03.660399 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:01:03.661397 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m16:01:03.661922 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:03.665462 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:01:03.665462 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m16:01:03.666397 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:03.666961 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:01:03.667899 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:01:03.667899 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:01:03.670004 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m16:01:03.672199 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:01:03.672199 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m16:01:03.673751 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:01:03.674774 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m16:01:03.710575 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a6b3c2d-9929-4521-b905-5b30fca496e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B43774D0>]}
[0m16:01:03.711084 [info ] [Thread-1 (]: 2 of 4 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.08s]
[0m16:01:03.712280 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m16:01:03.712280 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m16:01:03.712823 [info ] [Thread-1 (]: 3 of 4 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m16:01:03.713353 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m16:01:03.713353 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m16:01:03.716032 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m16:01:03.717001 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m16:01:03.720088 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m16:01:03.721028 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:01:03.721028 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m16:01:03.721539 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:01:03.743883 [debug] [Thread-1 (]: SQL status: OK in 0.022 seconds
[0m16:01:03.743883 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:01:03.744874 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m16:01:03.744874 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:03.748311 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:01:03.748311 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m16:01:03.749268 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:03.750775 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:01:03.750775 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:01:03.750775 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:01:03.753406 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:01:03.755427 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:01:03.755427 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m16:01:03.756429 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:03.757422 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m16:01:03.791736 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a6b3c2d-9929-4521-b905-5b30fca496e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B5BDE480>]}
[0m16:01:03.791736 [info ] [Thread-1 (]: 3 of 4 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.08s]
[0m16:01:03.792727 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m16:01:03.792727 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m16:01:03.794273 [info ] [Thread-1 (]: 4 of 4 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m16:01:03.794912 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m16:01:03.795423 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m16:01:03.797413 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m16:01:03.797413 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m16:01:03.801056 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m16:01:03.801056 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:01:03.802007 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m16:01:03.802007 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:01:03.822498 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m16:01:03.823603 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:01:03.823603 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m16:01:03.824641 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:01:03.827985 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:01:03.828071 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m16:01:03.828978 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:03.832005 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:01:03.832005 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m16:01:03.833292 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:03.834315 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:01:03.834315 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:01:03.834315 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:01:03.836314 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:01:03.838435 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:01:03.838435 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m16:01:03.839451 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:01:03.840003 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m16:01:03.874274 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a6b3c2d-9929-4521-b905-5b30fca496e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B5BF9250>]}
[0m16:01:03.875270 [info ] [Thread-1 (]: 4 of 4 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.08s]
[0m16:01:03.876266 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m16:01:03.877280 [debug] [MainThread]: Using duckdb connection "master"
[0m16:01:03.877280 [debug] [MainThread]: On master: BEGIN
[0m16:01:03.878260 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:01:03.899209 [debug] [MainThread]: SQL status: OK in 0.022 seconds
[0m16:01:03.900140 [debug] [MainThread]: On master: COMMIT
[0m16:01:03.900140 [debug] [MainThread]: Using duckdb connection "master"
[0m16:01:03.900140 [debug] [MainThread]: On master: COMMIT
[0m16:01:03.901137 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:01:03.901137 [debug] [MainThread]: On master: Close
[0m16:01:03.903956 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:01:03.904953 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m16:01:03.904953 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m16:01:03.905504 [debug] [MainThread]: Connection 'model.archi.cleanpr' was properly closed.
[0m16:01:03.905504 [info ] [MainThread]: 
[0m16:01:03.905504 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 0.66 seconds (0.66s).
[0m16:01:03.907452 [debug] [MainThread]: Command end result
[0m16:01:03.922941 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:01:03.925441 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:01:03.931446 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m16:01:03.931446 [info ] [MainThread]: 
[0m16:01:03.932443 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:01:03.932954 [info ] [MainThread]: 
[0m16:01:03.932954 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m16:01:03.933948 [debug] [MainThread]: Command `dbt build` succeeded at 16:01:03.933948 after 1.79 seconds
[0m16:01:03.934975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B00DDBE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B42EB110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B1B42EADB0>]}
[0m16:01:03.934975 [debug] [MainThread]: Flushing usage events
[0m16:01:04.631817 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:01:09.265885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024089DFF740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408C9A0920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408C9A0860>]}


============================== 16:01:09.269834 | 367069e4-8c17-4765-a19a-84a559484d40 ==============================
[0m16:01:09.269834 [info ] [MainThread]: Running with dbt=1.9.1
[0m16:01:09.269834 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:01:09.480964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '367069e4-8c17-4765-a19a-84a559484d40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408DEE7800>]}
[0m16:01:09.539855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '367069e4-8c17-4765-a19a-84a559484d40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408CE856D0>]}
[0m16:01:09.542868 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m16:01:09.800384 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m16:01:09.927417 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:01:09.928726 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:01:09.952415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '367069e4-8c17-4765-a19a-84a559484d40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408E6B71A0>]}
[0m16:01:10.002993 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:01:10.004559 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:01:10.025531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '367069e4-8c17-4765-a19a-84a559484d40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408EC36270>]}
[0m16:01:10.025531 [info ] [MainThread]: Found 4 models, 424 macros
[0m16:01:10.026528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '367069e4-8c17-4765-a19a-84a559484d40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408E7767B0>]}
[0m16:01:10.028150 [info ] [MainThread]: 
[0m16:01:10.029148 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:01:10.029804 [info ] [MainThread]: 
[0m16:01:10.030382 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m16:01:10.034644 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m16:01:10.116504 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:01:10.117497 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:01:10.117497 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:01:10.136458 [debug] [ThreadPool]: SQL status: OK in 0.019 seconds
[0m16:01:10.137960 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:01:10.141017 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m16:01:10.141017 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m16:01:10.148285 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:01:10.148792 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:01:10.148850 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:01:10.165049 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m16:01:10.166945 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:01:10.167455 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m16:01:10.167972 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:01:10.167972 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:01:10.168475 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m16:01:10.168983 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:01:10.169490 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:01:10.169490 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:01:10.169490 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:01:10.170485 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:01:10.170485 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m16:01:10.174908 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m16:01:10.180055 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:01:10.180055 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m16:01:10.181050 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:01:10.199064 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m16:01:10.200053 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:01:10.200053 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:01:10.242121 [debug] [ThreadPool]: SQL status: OK in 0.042 seconds
[0m16:01:10.244086 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m16:01:10.245620 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m16:01:10.245620 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m16:01:10.251679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '367069e4-8c17-4765-a19a-84a559484d40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408E749E80>]}
[0m16:01:10.251679 [debug] [MainThread]: Using duckdb connection "master"
[0m16:01:10.252675 [debug] [MainThread]: On master: BEGIN
[0m16:01:10.252675 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:01:10.268687 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m16:01:10.268687 [debug] [MainThread]: On master: COMMIT
[0m16:01:10.269685 [debug] [MainThread]: Using duckdb connection "master"
[0m16:01:10.269685 [debug] [MainThread]: On master: COMMIT
[0m16:01:10.269685 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:01:10.270687 [debug] [MainThread]: On master: Close
[0m16:01:10.274715 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m16:01:10.275686 [info ] [Thread-1 (]: 1 of 4 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m16:01:10.275686 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m16:01:10.276672 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m16:01:10.283643 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m16:01:10.283714 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m16:01:10.313331 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m16:01:10.314198 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:01:10.315240 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m16:01:10.315240 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:01:10.332502 [debug] [Thread-1 (]: SQL status: OK in 0.017 seconds
[0m16:01:10.332502 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:01:10.333501 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m16:01:10.334467 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:10.339028 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:01:10.340032 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m16:01:10.340572 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:10.343144 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:01:10.343144 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m16:01:10.343144 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:10.354797 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:01:10.355804 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:01:10.355804 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:01:10.358549 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m16:01:10.363543 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:01:10.364050 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m16:01:10.365062 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:01:10.368084 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m16:01:10.404758 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '367069e4-8c17-4765-a19a-84a559484d40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408C9CBFB0>]}
[0m16:01:10.405674 [info ] [Thread-1 (]: 1 of 4 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.13s]
[0m16:01:10.405674 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m16:01:10.406672 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m16:01:10.406672 [info ] [Thread-1 (]: 2 of 4 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m16:01:10.407669 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m16:01:10.407669 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m16:01:10.409669 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m16:01:10.410261 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m16:01:10.413774 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m16:01:10.414769 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:01:10.415317 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m16:01:10.415317 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:01:10.437037 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m16:01:10.437037 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:01:10.437037 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m16:01:10.438551 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:10.440623 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:01:10.441618 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m16:01:10.441618 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:10.444613 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:01:10.444613 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m16:01:10.445611 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:10.447264 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:01:10.447264 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:01:10.448214 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:01:10.449182 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:01:10.451278 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:01:10.452305 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m16:01:10.453496 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:01:10.454008 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m16:01:10.488061 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '367069e4-8c17-4765-a19a-84a559484d40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408DFF33E0>]}
[0m16:01:10.489055 [info ] [Thread-1 (]: 2 of 4 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.08s]
[0m16:01:10.490305 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m16:01:10.490330 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m16:01:10.490330 [info ] [Thread-1 (]: 3 of 4 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m16:01:10.491305 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m16:01:10.491305 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m16:01:10.493812 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m16:01:10.493812 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m16:01:10.497683 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m16:01:10.498681 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:01:10.498681 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m16:01:10.499188 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:01:10.520014 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m16:01:10.521011 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:01:10.521011 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m16:01:10.522010 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:10.524020 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:01:10.525018 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m16:01:10.525018 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:10.527488 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:01:10.528442 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m16:01:10.529422 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:10.530419 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:01:10.530419 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:01:10.531416 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:01:10.532414 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:01:10.534917 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:01:10.534917 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m16:01:10.534917 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:01:10.537247 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m16:01:10.571400 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '367069e4-8c17-4765-a19a-84a559484d40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408F1211C0>]}
[0m16:01:10.572416 [info ] [Thread-1 (]: 3 of 4 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.08s]
[0m16:01:10.572924 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m16:01:10.573489 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m16:01:10.573489 [info ] [Thread-1 (]: 4 of 4 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m16:01:10.573489 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m16:01:10.574426 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m16:01:10.576421 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m16:01:10.576938 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m16:01:10.580915 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m16:01:10.581913 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:01:10.582443 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m16:01:10.582953 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:01:10.603741 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m16:01:10.604736 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:01:10.604736 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m16:01:10.606284 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:01:10.608233 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:01:10.609231 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m16:01:10.609231 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:10.612223 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:01:10.612977 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m16:01:10.613529 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:01:10.614483 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:01:10.615480 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:01:10.615480 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:01:10.617097 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:01:10.619112 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:01:10.620010 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m16:01:10.621007 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:01:10.622006 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m16:01:10.656389 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '367069e4-8c17-4765-a19a-84a559484d40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408F2B7890>]}
[0m16:01:10.657898 [info ] [Thread-1 (]: 4 of 4 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.08s]
[0m16:01:10.657898 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m16:01:10.659785 [debug] [MainThread]: Using duckdb connection "master"
[0m16:01:10.660294 [debug] [MainThread]: On master: BEGIN
[0m16:01:10.660294 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:01:10.681976 [debug] [MainThread]: SQL status: OK in 0.022 seconds
[0m16:01:10.682973 [debug] [MainThread]: On master: COMMIT
[0m16:01:10.682973 [debug] [MainThread]: Using duckdb connection "master"
[0m16:01:10.683971 [debug] [MainThread]: On master: COMMIT
[0m16:01:10.683971 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:01:10.684829 [debug] [MainThread]: On master: Close
[0m16:01:10.687733 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:01:10.688294 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m16:01:10.688294 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m16:01:10.688294 [debug] [MainThread]: Connection 'model.archi.cleanpr' was properly closed.
[0m16:01:10.689236 [info ] [MainThread]: 
[0m16:01:10.689236 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 0.66 seconds (0.66s).
[0m16:01:10.690291 [debug] [MainThread]: Command end result
[0m16:01:10.706454 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:01:10.708009 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:01:10.714044 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m16:01:10.714044 [info ] [MainThread]: 
[0m16:01:10.714616 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:01:10.715129 [info ] [MainThread]: 
[0m16:01:10.715129 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m16:01:10.716736 [debug] [MainThread]: Command `dbt run` succeeded at 16:01:10.716736 after 1.57 seconds
[0m16:01:10.717244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408DEE7A70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408DDFDF40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002408D923BF0>]}
[0m16:01:10.717244 [debug] [MainThread]: Flushing usage events
[0m16:01:11.353254 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:31:07.288774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017426A19C40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174279C4B60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001742A0460C0>]}


============================== 16:31:07.299253 | 3bee76a7-e3c9-4bdd-be36-d9720fb3cb93 ==============================
[0m16:31:07.299253 [info ] [MainThread]: Running with dbt=1.9.1
[0m16:31:07.299253 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m16:31:07.588019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3bee76a7-e3c9-4bdd-be36-d9720fb3cb93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017429385C10>]}
[0m16:31:07.641567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3bee76a7-e3c9-4bdd-be36-d9720fb3cb93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001742A009430>]}
[0m16:31:07.658613 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m16:31:07.963849 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m16:31:08.025339 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m16:31:08.026285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3bee76a7-e3c9-4bdd-be36-d9720fb3cb93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017429F664B0>]}
[0m16:31:09.488852 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.archi.application
- models.archi.duckdb
[0m16:31:09.492860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3bee76a7-e3c9-4bdd-be36-d9720fb3cb93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001742B60EA20>]}
[0m16:31:09.538034 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:31:09.547834 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:31:09.779270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3bee76a7-e3c9-4bdd-be36-d9720fb3cb93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001742B67DE80>]}
[0m16:31:09.779270 [info ] [MainThread]: Found 4 models, 424 macros
[0m16:31:09.781164 [info ] [MainThread]: 
[0m16:31:09.781164 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:31:09.782193 [info ] [MainThread]: 
[0m16:31:09.782820 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m16:31:09.786755 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m16:31:11.269830 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:31:11.269830 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:31:11.270847 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:31:11.295479 [debug] [ThreadPool]: SQL status: OK in 0.025 seconds
[0m16:31:11.296481 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:31:11.299978 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m16:31:11.301096 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m16:31:11.305680 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:31:11.306677 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:31:11.306677 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:31:11.322206 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:31:11.323230 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:31:11.323230 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m16:31:11.324239 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:31:11.324781 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:31:11.324781 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m16:31:11.324781 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:31:11.325814 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:31:11.325814 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:31:11.326810 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:31:11.326810 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:31:11.327319 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m16:31:11.331505 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m16:31:11.336000 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:31:11.336997 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m16:31:11.336997 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:31:11.351868 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:31:11.351868 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:31:11.352863 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:31:11.389692 [debug] [ThreadPool]: SQL status: OK in 0.037 seconds
[0m16:31:11.390689 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m16:31:11.400465 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m16:31:11.401462 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m16:31:11.406416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3bee76a7-e3c9-4bdd-be36-d9720fb3cb93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001742B64CBF0>]}
[0m16:31:11.406416 [debug] [MainThread]: Using duckdb connection "master"
[0m16:31:11.407132 [debug] [MainThread]: On master: BEGIN
[0m16:31:11.407634 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:31:11.422226 [debug] [MainThread]: SQL status: OK in 0.015 seconds
[0m16:31:11.422744 [debug] [MainThread]: On master: COMMIT
[0m16:31:11.423249 [debug] [MainThread]: Using duckdb connection "master"
[0m16:31:11.423249 [debug] [MainThread]: On master: COMMIT
[0m16:31:11.423249 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:31:11.423249 [debug] [MainThread]: On master: Close
[0m16:31:11.427816 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m16:31:11.428772 [info ] [Thread-1 (]: 1 of 4 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m16:31:11.428772 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m16:31:11.429770 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m16:31:11.435902 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m16:31:11.436902 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m16:31:11.466576 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m16:31:11.468194 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:31:11.468704 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m16:31:11.469244 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:31:11.483503 [debug] [Thread-1 (]: SQL status: OK in 0.015 seconds
[0m16:31:11.484531 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:31:11.484531 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m16:31:11.485534 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:31:11.490855 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:31:11.490855 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m16:31:11.491849 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:31:11.493545 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:31:11.493545 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m16:31:11.494569 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:31:11.504831 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:31:11.504831 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:31:11.505462 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:31:11.508397 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m16:31:11.513170 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:31:11.513187 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m16:31:11.514928 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:31:11.516746 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m16:31:11.555745 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bee76a7-e3c9-4bdd-be36-d9720fb3cb93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017426B09BB0>]}
[0m16:31:11.555745 [info ] [Thread-1 (]: 1 of 4 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.12s]
[0m16:31:11.556774 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m16:31:11.556774 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m16:31:11.557771 [info ] [Thread-1 (]: 2 of 4 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m16:31:11.557771 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m16:31:11.558770 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m16:31:11.560801 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m16:31:11.561762 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m16:31:11.563788 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m16:31:11.565395 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:31:11.565395 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m16:31:11.565395 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:31:11.585480 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:31:11.586020 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:31:11.586560 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m16:31:11.587102 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:31:11.589167 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:31:11.590181 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m16:31:11.591202 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:31:11.593240 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:31:11.593240 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m16:31:11.594242 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:31:11.595744 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:31:11.595744 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:31:11.595744 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:31:11.597275 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:31:11.599779 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:31:11.600285 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m16:31:11.601299 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:31:11.602293 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m16:31:11.634448 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bee76a7-e3c9-4bdd-be36-d9720fb3cb93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001742BD564E0>]}
[0m16:31:11.635446 [info ] [Thread-1 (]: 2 of 4 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.08s]
[0m16:31:11.635446 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m16:31:11.636475 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m16:31:11.636475 [info ] [Thread-1 (]: 3 of 4 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m16:31:11.636475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m16:31:11.637799 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m16:31:11.638822 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m16:31:11.639820 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m16:31:11.644332 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m16:31:11.644967 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:31:11.644967 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m16:31:11.645899 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:31:11.665013 [debug] [Thread-1 (]: SQL status: OK in 0.019 seconds
[0m16:31:11.665554 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:31:11.665554 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m16:31:11.666580 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:31:11.669124 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:31:11.670122 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m16:31:11.670122 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:31:11.672626 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:31:11.673239 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m16:31:11.673239 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:31:11.674160 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:31:11.675156 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:31:11.675156 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:31:11.676155 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:31:11.678808 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:31:11.678808 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m16:31:11.679727 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:31:11.680755 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m16:31:11.712680 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bee76a7-e3c9-4bdd-be36-d9720fb3cb93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001742BDFB290>]}
[0m16:31:11.713737 [info ] [Thread-1 (]: 3 of 4 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.08s]
[0m16:31:11.713737 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m16:31:11.714677 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m16:31:11.714677 [info ] [Thread-1 (]: 4 of 4 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m16:31:11.714677 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m16:31:11.715674 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m16:31:11.717254 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m16:31:11.718175 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m16:31:11.721701 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m16:31:11.721701 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:31:11.722670 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m16:31:11.722670 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:31:11.741773 [debug] [Thread-1 (]: SQL status: OK in 0.019 seconds
[0m16:31:11.742767 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:31:11.742767 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m16:31:11.743765 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:31:11.746264 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:31:11.747261 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m16:31:11.747261 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:31:11.749832 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:31:11.749832 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m16:31:11.750373 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:31:11.751401 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:31:11.751401 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:31:11.752403 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:31:11.753935 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:31:11.755630 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:31:11.756171 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m16:31:11.756706 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:31:11.757702 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m16:31:11.790926 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3bee76a7-e3c9-4bdd-be36-d9720fb3cb93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174292CB980>]}
[0m16:31:11.790926 [info ] [Thread-1 (]: 4 of 4 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.08s]
[0m16:31:11.791924 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m16:31:11.793263 [debug] [MainThread]: Using duckdb connection "master"
[0m16:31:11.793263 [debug] [MainThread]: On master: BEGIN
[0m16:31:11.793263 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:31:11.812400 [debug] [MainThread]: SQL status: OK in 0.019 seconds
[0m16:31:11.813432 [debug] [MainThread]: On master: COMMIT
[0m16:31:11.813432 [debug] [MainThread]: Using duckdb connection "master"
[0m16:31:11.813432 [debug] [MainThread]: On master: COMMIT
[0m16:31:11.814434 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:31:11.814434 [debug] [MainThread]: On master: Close
[0m16:31:11.817417 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:31:11.817417 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m16:31:11.817417 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m16:31:11.818416 [debug] [MainThread]: Connection 'model.archi.cleanpr' was properly closed.
[0m16:31:11.818416 [info ] [MainThread]: 
[0m16:31:11.819043 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 2.04 seconds (2.04s).
[0m16:31:11.819981 [debug] [MainThread]: Command end result
[0m16:31:11.835415 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:31:11.837383 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:31:11.842719 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m16:31:11.843227 [info ] [MainThread]: 
[0m16:31:11.843227 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:31:11.843227 [info ] [MainThread]: 
[0m16:31:11.844253 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m16:31:11.845251 [debug] [MainThread]: Command `dbt build` succeeded at 16:31:11.845251 after 4.70 seconds
[0m16:31:11.845251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001742A0D7560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001742A4FDE20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001742A4FDA60>]}
[0m16:31:11.846245 [debug] [MainThread]: Flushing usage events
[0m16:31:12.270430 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:32:22.922908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF03C493A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF03C48530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF034DD880>]}


============================== 16:32:22.926743 | 74d7b160-1fe3-4f9d-b23b-5e9947ea1002 ==============================
[0m16:32:22.926743 [info ] [MainThread]: Running with dbt=1.9.1
[0m16:32:22.927251 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:32:23.116843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '74d7b160-1fe3-4f9d-b23b-5e9947ea1002', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF03281C70>]}
[0m16:32:23.170177 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '74d7b160-1fe3-4f9d-b23b-5e9947ea1002', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF04A7B4A0>]}
[0m16:32:23.173421 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m16:32:23.402246 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m16:32:23.517224 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m16:32:23.517734 [debug] [MainThread]: Partial parsing: added file: archi://models\duckdb\view.sql
[0m16:32:23.726400 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.application
[0m16:32:23.730454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '74d7b160-1fe3-4f9d-b23b-5e9947ea1002', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF0513BE60>]}
[0m16:32:23.773483 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:32:23.775402 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:32:23.806113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '74d7b160-1fe3-4f9d-b23b-5e9947ea1002', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF054E1FA0>]}
[0m16:32:23.807079 [info ] [MainThread]: Found 5 models, 424 macros
[0m16:32:23.809113 [info ] [MainThread]: 
[0m16:32:23.809113 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:32:23.809979 [info ] [MainThread]: 
[0m16:32:23.810487 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m16:32:23.814084 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m16:32:23.888148 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:32:23.888654 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:32:23.888654 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:32:23.904656 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m16:32:23.906258 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:32:23.911303 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:32:23.911845 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:32:23.911845 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:32:23.926482 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:32:23.928057 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:32:23.931730 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m16:32:23.931730 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m16:32:23.937413 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:32:23.937413 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:32:23.937413 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:32:23.953689 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:32:23.954958 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:32:23.954964 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m16:32:23.955504 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:32:23.955504 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:32:23.955504 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m16:32:23.956521 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:32:23.956521 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:32:23.957526 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:32:23.957526 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:32:23.958165 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:32:23.958165 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m16:32:23.961094 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main)
[0m16:32:23.962052 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m16:32:23.963280 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:32:23.964314 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:32:23.964314 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:32:23.979785 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:32:23.980814 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:32:23.980814 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m16:32:23.980814 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:32:23.981812 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:32:23.981812 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m16:32:23.982476 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:32:23.983390 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m16:32:23.983390 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:32:23.983390 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m16:32:23.984395 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:32:23.984395 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m16:32:23.988597 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m16:32:23.993587 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:32:23.993587 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m16:32:23.993587 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:32:24.008874 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:32:24.008874 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:32:24.009414 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:32:24.047095 [debug] [ThreadPool]: SQL status: OK in 0.037 seconds
[0m16:32:24.048076 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m16:32:24.049074 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m16:32:24.049074 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m16:32:24.053571 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main)
[0m16:32:24.055144 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m16:32:24.055144 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m16:32:24.056110 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:32:24.071000 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:32:24.071541 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m16:32:24.071541 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:32:24.108682 [debug] [ThreadPool]: SQL status: OK in 0.037 seconds
[0m16:32:24.109683 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m16:32:24.110683 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m16:32:24.110683 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m16:32:24.116283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '74d7b160-1fe3-4f9d-b23b-5e9947ea1002', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF05AF11F0>]}
[0m16:32:24.116283 [debug] [MainThread]: Using duckdb connection "master"
[0m16:32:24.116283 [debug] [MainThread]: On master: BEGIN
[0m16:32:24.117280 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:32:24.132861 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m16:32:24.132861 [debug] [MainThread]: On master: COMMIT
[0m16:32:24.132861 [debug] [MainThread]: Using duckdb connection "master"
[0m16:32:24.133775 [debug] [MainThread]: On master: COMMIT
[0m16:32:24.133775 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:32:24.133775 [debug] [MainThread]: On master: Close
[0m16:32:24.138762 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m16:32:24.138762 [info ] [Thread-1 (]: 1 of 5 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m16:32:24.139761 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m16:32:24.139761 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m16:32:24.147061 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m16:32:24.147581 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m16:32:24.175541 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m16:32:24.176081 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:32:24.176081 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m16:32:24.176081 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:32:24.191907 [debug] [Thread-1 (]: SQL status: OK in 0.015 seconds
[0m16:32:24.191907 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:32:24.192911 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m16:32:24.193456 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:24.198772 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:32:24.198772 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m16:32:24.199798 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:24.202367 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:32:24.203507 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m16:32:24.203507 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:24.213771 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:32:24.214673 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:32:24.214673 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:32:24.218852 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m16:32:24.223437 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:32:24.223437 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m16:32:24.224951 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:24.227521 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m16:32:24.262276 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74d7b160-1fe3-4f9d-b23b-5e9947ea1002', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF02DCBF80>]}
[0m16:32:24.263274 [info ] [Thread-1 (]: 1 of 5 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.12s]
[0m16:32:24.263274 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m16:32:24.264307 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m16:32:24.264307 [info ] [Thread-1 (]: 2 of 5 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m16:32:24.265269 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m16:32:24.265269 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m16:32:24.266845 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m16:32:24.267870 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m16:32:24.270874 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m16:32:24.270874 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:32:24.270874 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m16:32:24.272156 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:32:24.291315 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:32:24.292339 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:32:24.292339 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m16:32:24.293343 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:24.294908 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:32:24.295911 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m16:32:24.296461 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:24.298027 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:32:24.299031 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m16:32:24.299573 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:24.300598 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:32:24.300598 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:32:24.301601 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:32:24.303135 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:24.304867 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:32:24.304867 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m16:32:24.306756 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:24.307979 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m16:32:24.341719 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74d7b160-1fe3-4f9d-b23b-5e9947ea1002', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF05BCB980>]}
[0m16:32:24.341719 [info ] [Thread-1 (]: 2 of 5 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.08s]
[0m16:32:24.342714 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m16:32:24.343275 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m16:32:24.343275 [info ] [Thread-1 (]: 3 of 5 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m16:32:24.344270 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m16:32:24.344805 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m16:32:24.345800 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m16:32:24.347310 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m16:32:24.349892 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m16:32:24.350822 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:32:24.350822 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m16:32:24.350822 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:32:24.370358 [debug] [Thread-1 (]: SQL status: OK in 0.019 seconds
[0m16:32:24.371386 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:32:24.371386 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m16:32:24.372384 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:24.375051 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:32:24.375051 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m16:32:24.375941 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:24.377938 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:32:24.378934 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m16:32:24.379595 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:24.380223 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:32:24.381158 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:32:24.381158 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:32:24.382127 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:24.385783 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:32:24.385783 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m16:32:24.386681 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:24.387709 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m16:32:24.419533 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74d7b160-1fe3-4f9d-b23b-5e9947ea1002', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF0661E660>]}
[0m16:32:24.419533 [info ] [Thread-1 (]: 3 of 5 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.07s]
[0m16:32:24.420875 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m16:32:24.420875 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m16:32:24.420875 [info ] [Thread-1 (]: 4 of 5 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m16:32:24.421951 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m16:32:24.421951 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m16:32:24.423865 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m16:32:24.424862 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m16:32:24.427869 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m16:32:24.428449 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:32:24.428449 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m16:32:24.428449 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:32:24.448524 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:32:24.448524 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:32:24.449508 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m16:32:24.450485 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:24.452510 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:32:24.453509 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m16:32:24.454052 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:24.456188 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:32:24.456188 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m16:32:24.457109 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:24.458104 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:32:24.458104 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:32:24.459101 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:32:24.459686 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:24.461630 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:32:24.462637 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m16:32:24.463146 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:24.464171 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m16:32:24.496704 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74d7b160-1fe3-4f9d-b23b-5e9947ea1002', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF0661E720>]}
[0m16:32:24.497775 [info ] [Thread-1 (]: 4 of 5 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.07s]
[0m16:32:24.497775 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m16:32:24.498695 [debug] [Thread-1 (]: Began running node model.archi.view
[0m16:32:24.498695 [info ] [Thread-1 (]: 5 of 5 START sql view model main.view .......................................... [RUN]
[0m16:32:24.499692 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m16:32:24.499692 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m16:32:24.501250 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m16:32:24.502192 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m16:32:24.504729 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m16:32:24.505752 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:32:24.506574 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m16:32:24.506574 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:32:24.528456 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m16:32:24.528456 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:32:24.529068 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commit
  );

[0m16:32:24.560992 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commit
  );

[0m16:32:24.561532 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m16:32:24.561532 [debug] [Thread-1 (]: On model.archi.view: ROLLBACK
[0m16:32:24.631105 [debug] [Thread-1 (]: Failed to rollback 'model.archi.view'
[0m16:32:24.631990 [debug] [Thread-1 (]: On model.archi.view: Close
[0m16:32:24.637561 [debug] [Thread-1 (]: Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commit does not exist!
  Did you mean "raw_commits"?
  LINE 5:     SELECT * FROM raw_commit
                            ^
[0m16:32:24.638558 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '74d7b160-1fe3-4f9d-b23b-5e9947ea1002', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF051CCE30>]}
[0m16:32:24.638558 [error] [Thread-1 (]: 5 of 5 ERROR creating sql view model main.view ................................. [[31mERROR[0m in 0.14s]
[0m16:32:24.639555 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m16:32:24.640522 [debug] [Thread-4 (]: Marking all children of 'model.archi.view' to be skipped because of status 'error'.  Reason: Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commit does not exist!
  Did you mean "raw_commits"?
  LINE 5:     SELECT * FROM raw_commit
                            ^.
[0m16:32:24.641786 [debug] [MainThread]: Using duckdb connection "master"
[0m16:32:24.641887 [debug] [MainThread]: On master: BEGIN
[0m16:32:24.641887 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:32:24.656807 [debug] [MainThread]: SQL status: OK in 0.015 seconds
[0m16:32:24.657314 [debug] [MainThread]: On master: COMMIT
[0m16:32:24.657820 [debug] [MainThread]: Using duckdb connection "master"
[0m16:32:24.657820 [debug] [MainThread]: On master: COMMIT
[0m16:32:24.657820 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:32:24.658815 [debug] [MainThread]: On master: Close
[0m16:32:24.661130 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:32:24.661130 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m16:32:24.662132 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m16:32:24.662638 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m16:32:24.662638 [info ] [MainThread]: 
[0m16:32:24.662638 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.85 seconds (0.85s).
[0m16:32:24.664687 [debug] [MainThread]: Command end result
[0m16:32:24.679645 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:32:24.681639 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:32:24.686626 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m16:32:24.687624 [info ] [MainThread]: 
[0m16:32:24.687624 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m16:32:24.688622 [info ] [MainThread]: 
[0m16:32:24.689131 [error] [MainThread]:   Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commit does not exist!
  Did you mean "raw_commits"?
  LINE 5:     SELECT * FROM raw_commit
                            ^
[0m16:32:24.689131 [info ] [MainThread]: 
[0m16:32:24.690125 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m16:32:24.691094 [debug] [MainThread]: Command `dbt build` failed at 16:32:24.691094 after 1.87 seconds
[0m16:32:24.691636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF03281670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF041FA3C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DF02DF4260>]}
[0m16:32:24.691636 [debug] [MainThread]: Flushing usage events
[0m16:32:25.112763 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:32:51.851229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC60491C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC6049850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC6048560>]}


============================== 16:32:51.854701 | d52f9547-b140-408b-954a-b6313755ae84 ==============================
[0m16:32:51.854701 [info ] [MainThread]: Running with dbt=1.9.1
[0m16:32:51.855648 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:32:52.045445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd52f9547-b140-408b-954a-b6313755ae84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC6EDCB00>]}
[0m16:32:52.098597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd52f9547-b140-408b-954a-b6313755ae84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC6777410>]}
[0m16:32:52.101623 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m16:32:52.333401 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m16:32:52.445819 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:32:52.445819 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\view.sql
[0m16:32:52.660418 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.application
[0m16:32:52.665820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd52f9547-b140-408b-954a-b6313755ae84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC754C9E0>]}
[0m16:32:52.711758 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:32:52.713234 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:32:52.745911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd52f9547-b140-408b-954a-b6313755ae84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC78E5C70>]}
[0m16:32:52.745911 [info ] [MainThread]: Found 5 models, 424 macros
[0m16:32:52.748319 [info ] [MainThread]: 
[0m16:32:52.749302 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:32:52.749302 [info ] [MainThread]: 
[0m16:32:52.750299 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m16:32:52.754467 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m16:32:52.828362 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:32:52.828362 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:32:52.828905 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:32:52.844606 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:32:52.846555 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:32:52.851125 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:32:52.851125 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:32:52.852114 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:32:52.867629 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:32:52.868653 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:32:52.872250 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m16:32:52.872250 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m16:32:52.877850 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:32:52.878849 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:32:52.878849 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:32:52.894185 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:32:52.895184 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:32:52.895834 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m16:32:52.895834 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:32:52.895834 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:32:52.896750 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m16:32:52.896750 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:32:52.897747 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:32:52.897747 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:32:52.897747 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:32:52.898742 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:32:52.899283 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m16:32:52.901307 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main)
[0m16:32:52.902925 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m16:32:52.903819 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:32:52.904814 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:32:52.904814 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:32:52.920609 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:32:52.921636 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:32:52.921636 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m16:32:52.921636 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:32:52.922641 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:32:52.922641 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m16:32:52.923183 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:32:52.923724 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m16:32:52.924262 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:32:52.924262 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m16:32:52.924262 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:32:52.925292 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m16:32:52.929298 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m16:32:52.933766 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:32:52.934770 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m16:32:52.934770 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:32:52.950017 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:32:52.951014 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:32:52.951521 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:32:52.990480 [debug] [ThreadPool]: SQL status: OK in 0.039 seconds
[0m16:32:52.990480 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m16:32:52.991880 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m16:32:52.992906 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m16:32:52.997046 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main)
[0m16:32:52.998590 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m16:32:52.998590 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m16:32:52.998590 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:32:53.013956 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:32:53.015071 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m16:32:53.015071 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:32:53.053378 [debug] [ThreadPool]: SQL status: OK in 0.038 seconds
[0m16:32:53.054991 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m16:32:53.054991 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m16:32:53.055950 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m16:32:53.060740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd52f9547-b140-408b-954a-b6313755ae84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC7453DA0>]}
[0m16:32:53.061280 [debug] [MainThread]: Using duckdb connection "master"
[0m16:32:53.061280 [debug] [MainThread]: On master: BEGIN
[0m16:32:53.061280 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:32:53.075969 [debug] [MainThread]: SQL status: OK in 0.015 seconds
[0m16:32:53.076962 [debug] [MainThread]: On master: COMMIT
[0m16:32:53.076962 [debug] [MainThread]: Using duckdb connection "master"
[0m16:32:53.076962 [debug] [MainThread]: On master: COMMIT
[0m16:32:53.078038 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:32:53.078038 [debug] [MainThread]: On master: Close
[0m16:32:53.082456 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m16:32:53.083508 [info ] [Thread-1 (]: 1 of 5 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m16:32:53.083508 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m16:32:53.084455 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m16:32:53.090502 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m16:32:53.091457 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m16:32:53.118546 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m16:32:53.119460 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:32:53.119460 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m16:32:53.120457 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:32:53.134566 [debug] [Thread-1 (]: SQL status: OK in 0.014 seconds
[0m16:32:53.135454 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:32:53.135454 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m16:32:53.136452 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:53.141514 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:32:53.141514 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m16:32:53.142455 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:53.145016 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:32:53.145955 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m16:32:53.145955 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:53.156536 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:32:53.156536 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:32:53.157491 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:32:53.160484 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m16:32:53.164994 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:32:53.164994 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m16:32:53.166624 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:53.168077 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m16:32:53.202834 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd52f9547-b140-408b-954a-b6313755ae84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC2A09A30>]}
[0m16:32:53.203374 [info ] [Thread-1 (]: 1 of 5 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.12s]
[0m16:32:53.204286 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m16:32:53.204409 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m16:32:53.204921 [info ] [Thread-1 (]: 2 of 5 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m16:32:53.205429 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m16:32:53.205429 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m16:32:53.207429 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m16:32:53.207937 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m16:32:53.210452 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m16:32:53.211444 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:32:53.211444 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m16:32:53.212450 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:32:53.232561 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:32:53.232561 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:32:53.233072 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m16:32:53.233584 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:53.236576 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:32:53.236576 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m16:32:53.236576 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:53.239121 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:32:53.239121 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m16:32:53.240076 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:53.241073 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:32:53.242071 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:32:53.242584 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:32:53.243576 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:53.245572 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:32:53.246133 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m16:32:53.246133 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:53.248074 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m16:32:53.278869 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd52f9547-b140-408b-954a-b6313755ae84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC7EDDEE0>]}
[0m16:32:53.279781 [info ] [Thread-1 (]: 2 of 5 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.07s]
[0m16:32:53.279781 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m16:32:53.280778 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m16:32:53.280778 [info ] [Thread-1 (]: 3 of 5 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m16:32:53.280778 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m16:32:53.282020 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m16:32:53.283614 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m16:32:53.284517 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m16:32:53.287076 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m16:32:53.287582 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:32:53.288089 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m16:32:53.288605 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:32:53.307634 [debug] [Thread-1 (]: SQL status: OK in 0.019 seconds
[0m16:32:53.307634 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:32:53.307634 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m16:32:53.308632 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:53.311624 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:32:53.311624 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m16:32:53.312621 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:53.314616 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:32:53.314616 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m16:32:53.315613 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:53.316610 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:32:53.316610 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:32:53.316610 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:32:53.318915 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m16:32:53.321837 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:32:53.322400 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m16:32:53.323339 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:53.324336 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m16:32:53.355874 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd52f9547-b140-408b-954a-b6313755ae84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC8A0AFC0>]}
[0m16:32:53.356829 [info ] [Thread-1 (]: 3 of 5 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.08s]
[0m16:32:53.356829 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m16:32:53.357826 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m16:32:53.357826 [info ] [Thread-1 (]: 4 of 5 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m16:32:53.357826 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m16:32:53.359007 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m16:32:53.360605 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m16:32:53.361504 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m16:32:53.364062 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m16:32:53.365001 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:32:53.365001 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m16:32:53.365001 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:32:53.386129 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:32:53.386129 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:32:53.386129 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m16:32:53.387125 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:53.390347 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:32:53.390347 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m16:32:53.390347 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:53.392437 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:32:53.393463 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m16:32:53.393463 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:32:53.395455 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:32:53.395455 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:32:53.395455 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:32:53.397056 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:53.399002 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:32:53.400001 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m16:32:53.400509 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:32:53.401536 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m16:32:53.433662 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd52f9547-b140-408b-954a-b6313755ae84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC8A22540>]}
[0m16:32:53.433662 [info ] [Thread-1 (]: 4 of 5 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.08s]
[0m16:32:53.434648 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m16:32:53.434648 [debug] [Thread-1 (]: Began running node model.archi.view
[0m16:32:53.435646 [info ] [Thread-1 (]: 5 of 5 START sql view model main.view .......................................... [RUN]
[0m16:32:53.435646 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m16:32:53.436747 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m16:32:53.438249 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m16:32:53.439274 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m16:32:53.441803 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m16:32:53.442792 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:32:53.443302 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m16:32:53.443489 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:32:53.461977 [debug] [Thread-1 (]: SQL status: OK in 0.019 seconds
[0m16:32:53.463496 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:32:53.463496 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commit
  );

[0m16:32:53.496143 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commit
  );

[0m16:32:53.496685 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m16:32:53.497225 [debug] [Thread-1 (]: On model.archi.view: ROLLBACK
[0m16:32:53.501243 [debug] [Thread-1 (]: Failed to rollback 'model.archi.view'
[0m16:32:53.501243 [debug] [Thread-1 (]: On model.archi.view: Close
[0m16:32:53.507338 [debug] [Thread-1 (]: Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commit does not exist!
  Did you mean "raw_commits"?
  LINE 5:     SELECT * FROM raw_commit
                            ^
[0m16:32:53.507338 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd52f9547-b140-408b-954a-b6313755ae84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC7F0F1A0>]}
[0m16:32:53.508333 [error] [Thread-1 (]: 5 of 5 ERROR creating sql view model main.view ................................. [[31mERROR[0m in 0.07s]
[0m16:32:53.508963 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m16:32:53.508963 [debug] [Thread-4 (]: Marking all children of 'model.archi.view' to be skipped because of status 'error'.  Reason: Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commit does not exist!
  Did you mean "raw_commits"?
  LINE 5:     SELECT * FROM raw_commit
                            ^.
[0m16:32:53.510871 [debug] [MainThread]: Using duckdb connection "master"
[0m16:32:53.510871 [debug] [MainThread]: On master: BEGIN
[0m16:32:53.510871 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:32:53.526472 [debug] [MainThread]: SQL status: OK in 0.015 seconds
[0m16:32:53.526472 [debug] [MainThread]: On master: COMMIT
[0m16:32:53.527012 [debug] [MainThread]: Using duckdb connection "master"
[0m16:32:53.527012 [debug] [MainThread]: On master: COMMIT
[0m16:32:53.527012 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:32:53.528037 [debug] [MainThread]: On master: Close
[0m16:32:53.530555 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:32:53.530555 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m16:32:53.530555 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m16:32:53.531557 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m16:32:53.532091 [info ] [MainThread]: 
[0m16:32:53.532097 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.78 seconds (0.78s).
[0m16:32:53.533122 [debug] [MainThread]: Command end result
[0m16:32:53.549916 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:32:53.551439 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:32:53.557178 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m16:32:53.557178 [info ] [MainThread]: 
[0m16:32:53.557688 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m16:32:53.557688 [info ] [MainThread]: 
[0m16:32:53.558715 [error] [MainThread]:   Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commit does not exist!
  Did you mean "raw_commits"?
  LINE 5:     SELECT * FROM raw_commit
                            ^
[0m16:32:53.559320 [info ] [MainThread]: 
[0m16:32:53.559862 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m16:32:53.560374 [debug] [MainThread]: Command `dbt build` failed at 16:32:53.560374 after 1.81 seconds
[0m16:32:53.561370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC6015AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC6702360>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FEC51F4980>]}
[0m16:32:53.561370 [debug] [MainThread]: Flushing usage events
[0m16:32:53.934097 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:33:08.165435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897C767050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897C767020>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897C766BD0>]}


============================== 16:33:08.168936 | 28fa22fc-d7d5-4084-a7d4-867d0ff7f8e8 ==============================
[0m16:33:08.168936 [info ] [MainThread]: Running with dbt=1.9.1
[0m16:33:08.169934 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:33:08.364351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '28fa22fc-d7d5-4084-a7d4-867d0ff7f8e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897D0ACEF0>]}
[0m16:33:08.420315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '28fa22fc-d7d5-4084-a7d4-867d0ff7f8e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897BA53830>]}
[0m16:33:08.423768 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m16:33:08.655893 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m16:33:08.774915 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:33:08.775423 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\view.sql
[0m16:33:08.984367 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.application
[0m16:33:08.988853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '28fa22fc-d7d5-4084-a7d4-867d0ff7f8e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897DE4CA70>]}
[0m16:33:09.032671 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:33:09.034757 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:33:09.066634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '28fa22fc-d7d5-4084-a7d4-867d0ff7f8e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897DFE6000>]}
[0m16:33:09.066634 [info ] [MainThread]: Found 5 models, 424 macros
[0m16:33:09.068603 [info ] [MainThread]: 
[0m16:33:09.069734 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:33:09.069734 [info ] [MainThread]: 
[0m16:33:09.070632 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m16:33:09.075253 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m16:33:09.148029 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:33:09.149027 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:33:09.149562 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:33:09.165839 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m16:33:09.167460 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:33:09.171990 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:33:09.172993 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:33:09.172993 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:33:09.189007 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:33:09.190031 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:33:09.193558 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m16:33:09.193558 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m16:33:09.198990 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:33:09.200019 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:33:09.200019 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:33:09.214883 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:33:09.215833 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:33:09.216827 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m16:33:09.217404 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:33:09.217410 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:33:09.217410 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m16:33:09.218032 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:33:09.218981 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m16:33:09.218981 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:33:09.218981 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m16:33:09.219974 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:33:09.219974 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m16:33:09.223247 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_cleansed)
[0m16:33:09.223247 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m16:33:09.225497 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:33:09.225497 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:33:09.226002 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:33:09.241049 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:33:09.242133 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:33:09.242673 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m16:33:09.243191 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:33:09.243191 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:33:09.243734 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m16:33:09.243734 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:33:09.244759 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:33:09.244759 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:33:09.244759 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:33:09.245762 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:33:09.245762 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m16:33:09.250552 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m16:33:09.254539 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m16:33:09.254539 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m16:33:09.255537 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:33:09.269499 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:33:09.270497 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m16:33:09.270497 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:33:09.308395 [debug] [ThreadPool]: SQL status: OK in 0.038 seconds
[0m16:33:09.309393 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m16:33:09.310390 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m16:33:09.311387 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m16:33:09.314786 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_cleansed)
[0m16:33:09.316795 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:33:09.316795 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m16:33:09.317790 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:33:09.332890 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:33:09.332890 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:33:09.332890 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:33:09.370787 [debug] [ThreadPool]: SQL status: OK in 0.037 seconds
[0m16:33:09.371785 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m16:33:09.372782 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m16:33:09.373780 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m16:33:09.377906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '28fa22fc-d7d5-4084-a7d4-867d0ff7f8e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897E5FD820>]}
[0m16:33:09.378903 [debug] [MainThread]: Using duckdb connection "master"
[0m16:33:09.378903 [debug] [MainThread]: On master: BEGIN
[0m16:33:09.378903 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:33:09.394403 [debug] [MainThread]: SQL status: OK in 0.015 seconds
[0m16:33:09.395401 [debug] [MainThread]: On master: COMMIT
[0m16:33:09.395401 [debug] [MainThread]: Using duckdb connection "master"
[0m16:33:09.395401 [debug] [MainThread]: On master: COMMIT
[0m16:33:09.395401 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:33:09.396398 [debug] [MainThread]: On master: Close
[0m16:33:09.400580 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m16:33:09.400580 [info ] [Thread-1 (]: 1 of 5 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m16:33:09.401608 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m16:33:09.402585 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m16:33:09.408800 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m16:33:09.409734 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m16:33:09.436034 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m16:33:09.437639 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:33:09.437639 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m16:33:09.437639 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:33:09.452999 [debug] [Thread-1 (]: SQL status: OK in 0.015 seconds
[0m16:33:09.452999 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:33:09.453999 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m16:33:09.454965 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:33:09.460175 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:33:09.460175 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m16:33:09.460175 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:33:09.464263 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:33:09.464263 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m16:33:09.464263 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:33:09.474902 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:33:09.474902 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:33:09.475905 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:33:09.479984 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m16:33:09.484349 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:33:09.484349 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m16:33:09.486256 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:33:09.488250 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m16:33:09.522782 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28fa22fc-d7d5-4084-a7d4-867d0ff7f8e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897DB70AD0>]}
[0m16:33:09.523322 [info ] [Thread-1 (]: 1 of 5 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.12s]
[0m16:33:09.524316 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m16:33:09.524316 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m16:33:09.524971 [info ] [Thread-1 (]: 2 of 5 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m16:33:09.525512 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m16:33:09.526018 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m16:33:09.528050 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m16:33:09.528590 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m16:33:09.531168 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m16:33:09.532161 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:33:09.532161 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m16:33:09.532870 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:33:09.552544 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:33:09.553089 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:33:09.553630 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m16:33:09.553630 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:33:09.556918 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:33:09.556918 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m16:33:09.556918 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:33:09.559879 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:33:09.560509 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m16:33:09.560509 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:33:09.562075 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:33:09.562075 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:33:09.562075 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:33:09.564069 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:33:09.566065 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:33:09.566599 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m16:33:09.566700 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:33:09.567630 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m16:33:09.599015 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28fa22fc-d7d5-4084-a7d4-867d0ff7f8e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897E6A78C0>]}
[0m16:33:09.600529 [info ] [Thread-1 (]: 2 of 5 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.07s]
[0m16:33:09.600529 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m16:33:09.601524 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m16:33:09.602072 [info ] [Thread-1 (]: 3 of 5 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m16:33:09.602579 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m16:33:09.602579 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m16:33:09.604575 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m16:33:09.605082 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m16:33:09.607659 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m16:33:09.608593 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:33:09.608593 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m16:33:09.608593 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:33:09.628555 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:33:09.629548 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:33:09.629548 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m16:33:09.630569 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:33:09.633145 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:33:09.633145 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m16:33:09.633688 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:33:09.636257 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:33:09.636257 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m16:33:09.636257 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:33:09.638279 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:33:09.638279 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:33:09.638925 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:33:09.639809 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:33:09.642493 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:33:09.643410 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m16:33:09.644400 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:33:09.645408 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m16:33:09.676292 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28fa22fc-d7d5-4084-a7d4-867d0ff7f8e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897F21F110>]}
[0m16:33:09.677278 [info ] [Thread-1 (]: 3 of 5 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.07s]
[0m16:33:09.678434 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m16:33:09.678434 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m16:33:09.678434 [info ] [Thread-1 (]: 4 of 5 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m16:33:09.679434 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m16:33:09.679952 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m16:33:09.681933 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m16:33:09.681933 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m16:33:09.685461 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m16:33:09.685461 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:33:09.686466 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m16:33:09.686466 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:33:09.705898 [debug] [Thread-1 (]: SQL status: OK in 0.019 seconds
[0m16:33:09.705898 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:33:09.706940 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m16:33:09.706940 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:33:09.710100 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:33:09.710640 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m16:33:09.710640 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:33:09.712954 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:33:09.713879 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m16:33:09.713879 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:33:09.715876 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:33:09.715876 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:33:09.716417 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:33:09.717445 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:33:09.719103 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:33:09.719103 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m16:33:09.720090 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:33:09.721632 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m16:33:09.753502 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28fa22fc-d7d5-4084-a7d4-867d0ff7f8e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897F21EED0>]}
[0m16:33:09.753502 [info ] [Thread-1 (]: 4 of 5 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.07s]
[0m16:33:09.754489 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m16:33:09.754489 [debug] [Thread-1 (]: Began running node model.archi.view
[0m16:33:09.755487 [info ] [Thread-1 (]: 5 of 5 START sql view model main.view .......................................... [RUN]
[0m16:33:09.755487 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m16:33:09.755487 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m16:33:09.757514 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m16:33:09.758510 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m16:33:09.761070 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m16:33:09.762079 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:33:09.762628 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m16:33:09.762628 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:33:09.782220 [debug] [Thread-1 (]: SQL status: OK in 0.019 seconds
[0m16:33:09.782872 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:33:09.783412 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m16:33:09.784642 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:33:09.787145 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:33:09.787145 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m16:33:09.787145 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:33:09.789143 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m16:33:09.789143 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:33:09.789683 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m16:33:09.790708 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:33:09.792416 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:33:09.792416 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m16:33:09.793444 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:33:09.794797 [debug] [Thread-1 (]: On model.archi.view: Close
[0m16:33:09.825908 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28fa22fc-d7d5-4084-a7d4-867d0ff7f8e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897F213FE0>]}
[0m16:33:09.825908 [info ] [Thread-1 (]: 5 of 5 OK created sql view model main.view ..................................... [[32mOK[0m in 0.07s]
[0m16:33:09.826903 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m16:33:09.828056 [debug] [MainThread]: Using duckdb connection "master"
[0m16:33:09.828056 [debug] [MainThread]: On master: BEGIN
[0m16:33:09.829052 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:33:09.849852 [debug] [MainThread]: SQL status: OK in 0.022 seconds
[0m16:33:09.850849 [debug] [MainThread]: On master: COMMIT
[0m16:33:09.850849 [debug] [MainThread]: Using duckdb connection "master"
[0m16:33:09.850849 [debug] [MainThread]: On master: COMMIT
[0m16:33:09.852354 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:33:09.852354 [debug] [MainThread]: On master: Close
[0m16:33:09.855532 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:33:09.855532 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m16:33:09.855532 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m16:33:09.856530 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m16:33:09.857097 [info ] [MainThread]: 
[0m16:33:09.857097 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.79 seconds (0.79s).
[0m16:33:09.858031 [debug] [MainThread]: Command end result
[0m16:33:09.874545 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:33:09.876538 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:33:09.882260 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m16:33:09.882260 [info ] [MainThread]: 
[0m16:33:09.883140 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:33:09.883140 [info ] [MainThread]: 
[0m16:33:09.884137 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m16:33:09.885164 [debug] [MainThread]: Command `dbt build` succeeded at 16:33:09.884137 after 1.82 seconds
[0m16:33:09.885164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897DE37680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897D0A0440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002897CDEB9B0>]}
[0m16:33:09.885164 [debug] [MainThread]: Flushing usage events
[0m16:33:10.283354 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:34:16.285625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CAFA2E70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CD3A3E30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CD3A2780>]}


============================== 16:34:16.289219 | 27c2c611-b8fd-4db2-8a54-5619a8cdbd5f ==============================
[0m16:34:16.289219 [info ] [MainThread]: Running with dbt=1.9.1
[0m16:34:16.290185 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:34:16.483201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '27c2c611-b8fd-4db2-8a54-5619a8cdbd5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CC429190>]}
[0m16:34:16.538074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '27c2c611-b8fd-4db2-8a54-5619a8cdbd5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CAEDFF20>]}
[0m16:34:16.541062 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m16:34:16.775846 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m16:34:16.893540 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:34:16.893540 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:34:16.898894 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.application
[0m16:34:16.916586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '27c2c611-b8fd-4db2-8a54-5619a8cdbd5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CD52F2C0>]}
[0m16:34:16.963210 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:34:16.964207 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:34:16.996122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '27c2c611-b8fd-4db2-8a54-5619a8cdbd5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CE341FD0>]}
[0m16:34:16.997119 [info ] [MainThread]: Found 5 models, 424 macros
[0m16:34:16.999584 [info ] [MainThread]: 
[0m16:34:16.999584 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:34:17.000598 [info ] [MainThread]: 
[0m16:34:17.001104 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m16:34:17.005102 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m16:34:17.080702 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:34:17.080702 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:34:17.080702 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:34:17.098289 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m16:34:17.098829 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:34:17.104602 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:34:17.104602 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:34:17.104602 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:34:17.121027 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:34:17.122590 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:34:17.125520 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m16:34:17.125520 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m16:34:17.131704 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:34:17.131817 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:34:17.131817 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:34:17.147700 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:34:17.148334 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:34:17.149275 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m16:34:17.149275 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:34:17.149816 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:34:17.149816 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m16:34:17.149816 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:34:17.150843 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:34:17.150843 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:34:17.151832 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:34:17.152405 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:34:17.152405 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m16:34:17.155495 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main)
[0m16:34:17.155495 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m16:34:17.157524 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:34:17.157524 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:34:17.158069 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:34:17.173893 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:34:17.174921 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:34:17.174921 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m16:34:17.175745 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:34:17.175745 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:34:17.176392 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m16:34:17.176392 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:34:17.177311 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m16:34:17.177311 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:34:17.177311 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m16:34:17.178309 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:34:17.178309 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m16:34:17.182200 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m16:34:17.187397 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:34:17.187397 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m16:34:17.187397 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:34:17.202635 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:34:17.203568 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:34:17.203568 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:34:17.241706 [debug] [ThreadPool]: SQL status: OK in 0.038 seconds
[0m16:34:17.242701 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m16:34:17.243701 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m16:34:17.244706 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m16:34:17.248453 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main)
[0m16:34:17.250276 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m16:34:17.250276 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m16:34:17.250276 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:34:17.266602 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:34:17.266602 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m16:34:17.266602 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:34:17.305255 [debug] [ThreadPool]: SQL status: OK in 0.038 seconds
[0m16:34:17.306676 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m16:34:17.306676 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m16:34:17.307701 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m16:34:17.312199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '27c2c611-b8fd-4db2-8a54-5619a8cdbd5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CDCB1220>]}
[0m16:34:17.313310 [debug] [MainThread]: Using duckdb connection "master"
[0m16:34:17.313310 [debug] [MainThread]: On master: BEGIN
[0m16:34:17.313816 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:34:17.328795 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m16:34:17.329792 [debug] [MainThread]: On master: COMMIT
[0m16:34:17.329792 [debug] [MainThread]: Using duckdb connection "master"
[0m16:34:17.330308 [debug] [MainThread]: On master: COMMIT
[0m16:34:17.330308 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:34:17.330308 [debug] [MainThread]: On master: Close
[0m16:34:17.334856 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m16:34:17.335886 [info ] [Thread-1 (]: 1 of 5 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m16:34:17.335886 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m16:34:17.336885 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m16:34:17.343969 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m16:34:17.344966 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m16:34:17.372101 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m16:34:17.373023 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:34:17.373023 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m16:34:17.374021 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:34:17.388907 [debug] [Thread-1 (]: SQL status: OK in 0.015 seconds
[0m16:34:17.389898 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:34:17.389898 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m16:34:17.390895 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:17.395462 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:34:17.396460 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m16:34:17.397124 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:17.399033 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:34:17.399033 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m16:34:17.400033 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:17.409864 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:34:17.410861 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:34:17.410861 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:34:17.414584 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m16:34:17.418590 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:34:17.419586 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m16:34:17.420129 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:17.422806 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m16:34:17.458999 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27c2c611-b8fd-4db2-8a54-5619a8cdbd5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CEA24170>]}
[0m16:34:17.459997 [info ] [Thread-1 (]: 1 of 5 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.12s]
[0m16:34:17.460577 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m16:34:17.460577 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m16:34:17.461499 [info ] [Thread-1 (]: 2 of 5 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m16:34:17.461499 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m16:34:17.462496 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m16:34:17.464004 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m16:34:17.464999 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m16:34:17.467824 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m16:34:17.468353 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:34:17.468353 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m16:34:17.469346 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:34:17.489444 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:34:17.489444 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:34:17.489444 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m16:34:17.490455 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:17.493437 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:34:17.493437 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m16:34:17.494090 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:17.496569 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:34:17.496569 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m16:34:17.496569 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:17.498562 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:34:17.498562 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:34:17.499410 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:34:17.501319 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m16:34:17.504541 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:34:17.504541 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m16:34:17.505417 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:17.507444 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m16:34:17.538933 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27c2c611-b8fd-4db2-8a54-5619a8cdbd5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CEA8CBF0>]}
[0m16:34:17.539930 [info ] [Thread-1 (]: 2 of 5 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.08s]
[0m16:34:17.539930 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m16:34:17.540927 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m16:34:17.540927 [info ] [Thread-1 (]: 3 of 5 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m16:34:17.541925 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m16:34:17.541925 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m16:34:17.543577 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m16:34:17.544524 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m16:34:17.547716 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m16:34:17.548694 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:34:17.549236 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m16:34:17.549340 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:34:17.569579 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:34:17.569579 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:34:17.569579 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m16:34:17.570615 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:17.573243 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:34:17.573243 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m16:34:17.574237 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:17.576450 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:34:17.576450 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m16:34:17.577448 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:17.578448 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:34:17.579411 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:34:17.579411 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:34:17.580409 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:17.582403 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:34:17.582403 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m16:34:17.583942 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:17.584935 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m16:34:17.616358 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27c2c611-b8fd-4db2-8a54-5619a8cdbd5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CEA3D520>]}
[0m16:34:17.617357 [info ] [Thread-1 (]: 3 of 5 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.07s]
[0m16:34:17.617944 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m16:34:17.618859 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m16:34:17.618859 [info ] [Thread-1 (]: 4 of 5 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m16:34:17.618859 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m16:34:17.619856 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m16:34:17.621444 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m16:34:17.622356 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m16:34:17.625010 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m16:34:17.625886 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:34:17.625886 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m16:34:17.625886 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:34:17.646164 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:34:17.647149 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:34:17.647149 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m16:34:17.648136 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:17.650690 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:34:17.650690 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m16:34:17.651714 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:17.654291 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:34:17.654291 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m16:34:17.654884 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:17.655422 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:34:17.656451 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:34:17.656451 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:34:17.657928 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:17.659596 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:34:17.659596 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m16:34:17.661134 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:17.662163 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m16:34:17.693053 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27c2c611-b8fd-4db2-8a54-5619a8cdbd5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CE97F8C0>]}
[0m16:34:17.694561 [info ] [Thread-1 (]: 4 of 5 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.07s]
[0m16:34:17.694561 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m16:34:17.695557 [debug] [Thread-1 (]: Began running node model.archi.view
[0m16:34:17.695557 [info ] [Thread-1 (]: 5 of 5 START sql view model main.view .......................................... [RUN]
[0m16:34:17.695557 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m16:34:17.696762 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m16:34:17.697691 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m16:34:17.698689 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m16:34:17.702261 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m16:34:17.703187 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:34:17.703187 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m16:34:17.704184 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:34:17.723869 [debug] [Thread-1 (]: SQL status: OK in 0.019 seconds
[0m16:34:17.723869 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:34:17.723869 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m16:34:17.724896 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:17.727471 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:34:17.728472 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m16:34:17.728472 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:17.730466 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:34:17.731460 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m16:34:17.731460 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:17.733635 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m16:34:17.733635 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:34:17.733635 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m16:34:17.735625 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:17.736819 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:34:17.737755 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m16:34:17.738753 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:17.739750 [debug] [Thread-1 (]: On model.archi.view: Close
[0m16:34:17.772835 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27c2c611-b8fd-4db2-8a54-5619a8cdbd5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CE90B500>]}
[0m16:34:17.773830 [info ] [Thread-1 (]: 5 of 5 OK created sql view model main.view ..................................... [[32mOK[0m in 0.08s]
[0m16:34:17.774663 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m16:34:17.775275 [debug] [MainThread]: Using duckdb connection "master"
[0m16:34:17.775789 [debug] [MainThread]: On master: BEGIN
[0m16:34:17.776297 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:34:17.795465 [debug] [MainThread]: SQL status: OK in 0.020 seconds
[0m16:34:17.796460 [debug] [MainThread]: On master: COMMIT
[0m16:34:17.796460 [debug] [MainThread]: Using duckdb connection "master"
[0m16:34:17.796460 [debug] [MainThread]: On master: COMMIT
[0m16:34:17.797463 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:34:17.797463 [debug] [MainThread]: On master: Close
[0m16:34:17.800161 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:34:17.800161 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m16:34:17.801154 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m16:34:17.801154 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m16:34:17.801154 [info ] [MainThread]: 
[0m16:34:17.801154 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.80 seconds (0.80s).
[0m16:34:17.803582 [debug] [MainThread]: Command end result
[0m16:34:17.818131 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:34:17.820067 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:34:17.825130 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m16:34:17.825130 [info ] [MainThread]: 
[0m16:34:17.826063 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:34:17.826063 [info ] [MainThread]: 
[0m16:34:17.827060 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m16:34:17.828057 [debug] [MainThread]: Command `dbt build` succeeded at 16:34:17.828057 after 1.65 seconds
[0m16:34:17.828057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CAFA2E70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CD2A1160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000277CD2D2060>]}
[0m16:34:17.829055 [debug] [MainThread]: Flushing usage events
[0m16:34:18.251991 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:34:29.130350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026476BDDF10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002647A49DE80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002647A49D8E0>]}


============================== 16:34:29.134341 | c84be562-4369-4aef-8c8a-9cbedc91dcff ==============================
[0m16:34:29.134341 [info ] [MainThread]: Running with dbt=1.9.1
[0m16:34:29.134341 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:34:29.344309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c84be562-4369-4aef-8c8a-9cbedc91dcff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026479A85C70>]}
[0m16:34:29.403632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c84be562-4369-4aef-8c8a-9cbedc91dcff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026476F974D0>]}
[0m16:34:29.406745 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m16:34:29.651698 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m16:34:29.769997 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:34:29.769997 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:34:29.776005 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.application
[0m16:34:29.793366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c84be562-4369-4aef-8c8a-9cbedc91dcff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002647B34FEF0>]}
[0m16:34:29.841546 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:34:29.843608 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:34:29.863285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c84be562-4369-4aef-8c8a-9cbedc91dcff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002647B832D80>]}
[0m16:34:29.863791 [info ] [MainThread]: Found 5 models, 424 macros
[0m16:34:29.864298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c84be562-4369-4aef-8c8a-9cbedc91dcff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002647B34E270>]}
[0m16:34:29.865800 [info ] [MainThread]: 
[0m16:34:29.865800 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:34:29.866852 [info ] [MainThread]: 
[0m16:34:29.867357 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m16:34:29.870857 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m16:34:29.946688 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:34:29.946688 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:34:29.946688 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:34:29.963951 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m16:34:29.964976 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:34:29.969938 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:34:29.969938 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:34:29.969938 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:34:29.985739 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:34:29.986768 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:34:29.990249 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m16:34:29.990755 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m16:34:29.996271 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:34:29.996271 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:34:29.996271 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:34:30.013368 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:34:30.014366 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:34:30.014872 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m16:34:30.015391 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:34:30.015391 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:34:30.015391 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m16:34:30.016442 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:34:30.016949 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m16:34:30.017520 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:34:30.017520 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m16:34:30.017520 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:34:30.018451 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m16:34:30.021785 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_cleansed)
[0m16:34:30.021785 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m16:34:30.023780 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:34:30.024283 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:34:30.024357 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:34:30.039448 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:34:30.041015 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:34:30.041015 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m16:34:30.041015 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:34:30.041015 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:34:30.042275 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m16:34:30.042275 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:34:30.043204 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:34:30.043204 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:34:30.043204 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:34:30.044201 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:34:30.044201 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m16:34:30.048093 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m16:34:30.053096 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m16:34:30.053096 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m16:34:30.053096 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:34:30.067745 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:34:30.068742 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m16:34:30.068742 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:34:30.105864 [debug] [ThreadPool]: SQL status: OK in 0.037 seconds
[0m16:34:30.107411 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m16:34:30.108543 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m16:34:30.109086 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m16:34:30.112770 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_cleansed)
[0m16:34:30.114281 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:34:30.115276 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m16:34:30.115276 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:34:30.130252 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:34:30.131147 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:34:30.131147 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:34:30.168857 [debug] [ThreadPool]: SQL status: OK in 0.037 seconds
[0m16:34:30.169855 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m16:34:30.170857 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m16:34:30.170857 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m16:34:30.175873 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c84be562-4369-4aef-8c8a-9cbedc91dcff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026476F97890>]}
[0m16:34:30.175873 [debug] [MainThread]: Using duckdb connection "master"
[0m16:34:30.176771 [debug] [MainThread]: On master: BEGIN
[0m16:34:30.176771 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:34:30.191911 [debug] [MainThread]: SQL status: OK in 0.015 seconds
[0m16:34:30.191911 [debug] [MainThread]: On master: COMMIT
[0m16:34:30.191911 [debug] [MainThread]: Using duckdb connection "master"
[0m16:34:30.192908 [debug] [MainThread]: On master: COMMIT
[0m16:34:30.192908 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:34:30.192908 [debug] [MainThread]: On master: Close
[0m16:34:30.197406 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m16:34:30.198404 [info ] [Thread-1 (]: 1 of 5 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m16:34:30.198404 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m16:34:30.199401 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m16:34:30.204975 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m16:34:30.205999 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m16:34:30.233718 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m16:34:30.234716 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:34:30.234716 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m16:34:30.234716 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:34:30.249863 [debug] [Thread-1 (]: SQL status: OK in 0.015 seconds
[0m16:34:30.250861 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:34:30.251373 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m16:34:30.252006 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:30.258097 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:34:30.258097 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m16:34:30.259010 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:30.261005 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:34:30.261573 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m16:34:30.262102 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:30.272187 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:34:30.272699 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:34:30.272699 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:34:30.277192 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m16:34:30.283870 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:34:30.284877 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m16:34:30.285900 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:30.287973 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m16:34:30.323224 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c84be562-4369-4aef-8c8a-9cbedc91dcff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002647B373740>]}
[0m16:34:30.323766 [info ] [Thread-1 (]: 1 of 5 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.12s]
[0m16:34:30.324360 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m16:34:30.324360 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m16:34:30.325271 [info ] [Thread-1 (]: 2 of 5 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m16:34:30.325271 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m16:34:30.326268 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m16:34:30.327779 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m16:34:30.328771 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m16:34:30.330770 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m16:34:30.331767 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:34:30.331767 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m16:34:30.332765 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:34:30.352450 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:34:30.353448 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:34:30.354013 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m16:34:30.354522 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:30.356539 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:34:30.357540 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m16:34:30.358053 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:30.360047 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:34:30.360554 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m16:34:30.360554 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:30.362557 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:34:30.362557 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:34:30.363069 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:34:30.364604 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:30.365597 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:34:30.366603 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m16:34:30.368110 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:30.369119 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m16:34:30.400280 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c84be562-4369-4aef-8c8a-9cbedc91dcff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002647BEACCB0>]}
[0m16:34:30.401232 [info ] [Thread-1 (]: 2 of 5 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.08s]
[0m16:34:30.401232 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m16:34:30.402229 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m16:34:30.402229 [info ] [Thread-1 (]: 3 of 5 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m16:34:30.402229 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m16:34:30.403607 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m16:34:30.405510 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m16:34:30.405510 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m16:34:30.409022 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m16:34:30.409534 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:34:30.409534 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m16:34:30.409534 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:34:30.429387 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:34:30.430390 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:34:30.430902 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m16:34:30.430902 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:30.433412 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:34:30.434405 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m16:34:30.434405 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:30.436913 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:34:30.438427 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m16:34:30.438427 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:30.439420 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:34:30.440426 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:34:30.440426 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:34:30.441930 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:30.444008 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:34:30.444008 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m16:34:30.444008 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:30.446437 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m16:34:30.477983 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c84be562-4369-4aef-8c8a-9cbedc91dcff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002647B22A450>]}
[0m16:34:30.478494 [info ] [Thread-1 (]: 3 of 5 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.08s]
[0m16:34:30.479488 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m16:34:30.479488 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m16:34:30.479488 [info ] [Thread-1 (]: 4 of 5 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m16:34:30.480489 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m16:34:30.481001 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m16:34:30.482999 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m16:34:30.483507 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m16:34:30.486021 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m16:34:30.486532 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:34:30.487041 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m16:34:30.487554 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:34:30.506840 [debug] [Thread-1 (]: SQL status: OK in 0.019 seconds
[0m16:34:30.507353 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:34:30.507353 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m16:34:30.508866 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:30.511381 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:34:30.511889 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m16:34:30.511889 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:30.514403 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:34:30.514403 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m16:34:30.515397 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:30.516398 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:34:30.516910 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:34:30.516910 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:34:30.517903 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:30.520815 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:34:30.520815 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m16:34:30.521808 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:30.522814 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m16:34:30.553297 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c84be562-4369-4aef-8c8a-9cbedc91dcff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002647BD27C20>]}
[0m16:34:30.554291 [info ] [Thread-1 (]: 4 of 5 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.07s]
[0m16:34:30.554291 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m16:34:30.555312 [debug] [Thread-1 (]: Began running node model.archi.view
[0m16:34:30.555819 [info ] [Thread-1 (]: 5 of 5 START sql view model main.view .......................................... [RUN]
[0m16:34:30.555819 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m16:34:30.555819 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m16:34:30.558330 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m16:34:30.558330 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m16:34:30.561862 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m16:34:30.562371 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:34:30.562371 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m16:34:30.562371 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:34:30.582220 [debug] [Thread-1 (]: SQL status: OK in 0.019 seconds
[0m16:34:30.582220 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:34:30.583226 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m16:34:30.583737 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:30.586246 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:34:30.586246 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m16:34:30.587239 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:30.589748 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:34:30.589748 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m16:34:30.590753 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:34:30.591264 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m16:34:30.592258 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:34:30.592258 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m16:34:30.593775 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:30.594768 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:34:30.595773 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m16:34:30.596284 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:34:30.597278 [debug] [Thread-1 (]: On model.archi.view: Close
[0m16:34:30.628819 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c84be562-4369-4aef-8c8a-9cbedc91dcff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002647BE42A50>]}
[0m16:34:30.629813 [info ] [Thread-1 (]: 5 of 5 OK created sql view model main.view ..................................... [[32mOK[0m in 0.07s]
[0m16:34:30.629813 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m16:34:30.632147 [debug] [MainThread]: Using duckdb connection "master"
[0m16:34:30.632147 [debug] [MainThread]: On master: BEGIN
[0m16:34:30.632654 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:34:30.652154 [debug] [MainThread]: SQL status: OK in 0.020 seconds
[0m16:34:30.652662 [debug] [MainThread]: On master: COMMIT
[0m16:34:30.652662 [debug] [MainThread]: Using duckdb connection "master"
[0m16:34:30.652662 [debug] [MainThread]: On master: COMMIT
[0m16:34:30.653657 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:34:30.653657 [debug] [MainThread]: On master: Close
[0m16:34:30.657025 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:34:30.657025 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m16:34:30.658023 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m16:34:30.658534 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m16:34:30.659099 [info ] [MainThread]: 
[0m16:34:30.659641 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.79 seconds (0.79s).
[0m16:34:30.661646 [debug] [MainThread]: Command end result
[0m16:34:30.686094 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:34:30.688614 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:34:30.695632 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m16:34:30.696169 [info ] [MainThread]: 
[0m16:34:30.696169 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:34:30.697167 [info ] [MainThread]: 
[0m16:34:30.698170 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m16:34:30.698678 [debug] [MainThread]: Command `dbt run` succeeded at 16:34:30.698678 after 1.67 seconds
[0m16:34:30.699673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026476B4C1A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026476AFF230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026479E07C80>]}
[0m16:34:30.699673 [debug] [MainThread]: Flushing usage events
[0m16:34:31.182638 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:41:17.731645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298DFF042F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E5108A70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E4F66CF0>]}


============================== 16:41:17.736140 | e1000273-e052-4268-bdbf-b894abab3d23 ==============================
[0m16:41:17.736140 [info ] [MainThread]: Running with dbt=1.9.1
[0m16:41:17.736140 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m16:41:17.939171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e1000273-e052-4268-bdbf-b894abab3d23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E4385AF0>]}
[0m16:41:17.992736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e1000273-e052-4268-bdbf-b894abab3d23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E13F1CD0>]}
[0m16:41:17.996346 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m16:41:18.226378 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m16:41:18.339110 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:41:18.339110 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:41:18.344749 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.application
[0m16:41:18.361585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e1000273-e052-4268-bdbf-b894abab3d23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E56F2B70>]}
[0m16:41:18.406603 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:41:18.408546 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:41:18.440238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e1000273-e052-4268-bdbf-b894abab3d23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E6441F10>]}
[0m16:41:18.440238 [info ] [MainThread]: Found 5 models, 424 macros
[0m16:41:18.442808 [info ] [MainThread]: 
[0m16:41:18.443802 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:41:18.443802 [info ] [MainThread]: 
[0m16:41:18.444672 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m16:41:18.448853 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m16:41:18.522393 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:41:18.523401 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:41:18.524025 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:41:18.540712 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m16:41:18.541708 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:41:18.546708 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m16:41:18.546708 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m16:41:18.547635 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:41:18.562894 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:41:18.564547 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m16:41:18.568101 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m16:41:18.569062 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m16:41:18.573617 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:41:18.574624 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:41:18.574624 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:41:18.590987 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:41:18.591531 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:41:18.591531 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m16:41:18.592556 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:41:18.592556 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:41:18.593296 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m16:41:18.593806 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:41:18.593806 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:41:18.593806 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m16:41:18.594831 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m16:41:18.594831 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:41:18.594831 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m16:41:18.599010 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main)
[0m16:41:18.599540 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m16:41:18.600565 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:41:18.600565 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m16:41:18.601568 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:41:18.615797 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:41:18.617790 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:41:18.617790 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m16:41:18.617790 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:41:18.617790 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:41:18.619059 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m16:41:18.619169 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:41:18.620083 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m16:41:18.620083 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m16:41:18.620083 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m16:41:18.621082 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:41:18.621082 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m16:41:18.624901 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m16:41:18.629987 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:41:18.631001 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m16:41:18.631001 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:41:18.646610 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:41:18.646610 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:41:18.647152 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:41:18.684993 [debug] [ThreadPool]: SQL status: OK in 0.038 seconds
[0m16:41:18.685916 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m16:41:18.686908 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m16:41:18.687909 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m16:41:18.692032 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main)
[0m16:41:18.693059 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m16:41:18.694060 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m16:41:18.694060 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:41:18.708942 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:41:18.709949 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m16:41:18.709949 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:41:18.747467 [debug] [ThreadPool]: SQL status: OK in 0.037 seconds
[0m16:41:18.748484 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m16:41:18.749024 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m16:41:18.749024 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m16:41:18.754639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e1000273-e052-4268-bdbf-b894abab3d23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E1A9B5F0>]}
[0m16:41:18.754639 [debug] [MainThread]: Using duckdb connection "master"
[0m16:41:18.755634 [debug] [MainThread]: On master: BEGIN
[0m16:41:18.755634 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:41:18.770265 [debug] [MainThread]: SQL status: OK in 0.015 seconds
[0m16:41:18.771225 [debug] [MainThread]: On master: COMMIT
[0m16:41:18.771225 [debug] [MainThread]: Using duckdb connection "master"
[0m16:41:18.771225 [debug] [MainThread]: On master: COMMIT
[0m16:41:18.772189 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:41:18.772189 [debug] [MainThread]: On master: Close
[0m16:41:18.776306 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m16:41:18.777304 [info ] [Thread-1 (]: 1 of 5 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m16:41:18.777304 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m16:41:18.778301 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m16:41:18.785810 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m16:41:18.785810 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m16:41:18.813346 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m16:41:18.815036 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:41:18.815548 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m16:41:18.815548 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:41:18.831146 [debug] [Thread-1 (]: SQL status: OK in 0.015 seconds
[0m16:41:18.831146 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:41:18.831146 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m16:41:18.832071 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:41:18.837640 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:41:18.837640 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m16:41:18.838586 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:41:18.840589 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:41:18.841139 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m16:41:18.841139 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:41:18.851646 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:41:18.851646 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:41:18.852602 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m16:41:18.855593 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m16:41:18.860093 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m16:41:18.861091 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m16:41:18.862910 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:41:18.865103 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m16:41:18.899396 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1000273-e052-4268-bdbf-b894abab3d23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E6A5A0C0>]}
[0m16:41:18.900393 [info ] [Thread-1 (]: 1 of 5 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.12s]
[0m16:41:18.901670 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m16:41:18.901728 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m16:41:18.901728 [info ] [Thread-1 (]: 2 of 5 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m16:41:18.902662 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m16:41:18.902662 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m16:41:18.904700 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m16:41:18.905337 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m16:41:18.908266 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m16:41:18.908918 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:41:18.908918 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m16:41:18.909832 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:41:18.928989 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:41:18.928989 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:41:18.930147 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m16:41:18.930147 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:41:18.933045 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:41:18.933590 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m16:41:18.933667 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:41:18.935612 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:41:18.935612 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m16:41:18.936579 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:41:18.938113 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:41:18.938113 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:41:18.938113 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m16:41:18.940170 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m16:41:18.943668 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m16:41:18.943668 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m16:41:18.945684 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:41:18.946726 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m16:41:18.980421 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1000273-e052-4268-bdbf-b894abab3d23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E6B88860>]}
[0m16:41:18.980934 [info ] [Thread-1 (]: 2 of 5 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.08s]
[0m16:41:18.981926 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m16:41:18.981926 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m16:41:18.981926 [info ] [Thread-1 (]: 3 of 5 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m16:41:18.981926 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m16:41:18.983451 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m16:41:18.985360 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m16:41:18.985360 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m16:41:18.988923 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m16:41:18.988923 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:41:18.989861 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m16:41:18.989861 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:41:19.009502 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:41:19.010014 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:41:19.010014 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m16:41:19.011007 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:41:19.013028 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:41:19.014021 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m16:41:19.014021 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:41:19.016525 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:41:19.016525 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m16:41:19.017522 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:41:19.019096 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:41:19.019096 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:41:19.019096 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m16:41:19.021022 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:41:19.023017 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m16:41:19.023017 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m16:41:19.024589 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:41:19.025576 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m16:41:19.057927 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1000273-e052-4268-bdbf-b894abab3d23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E6B6FF50>]}
[0m16:41:19.058557 [info ] [Thread-1 (]: 3 of 5 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.08s]
[0m16:41:19.059459 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m16:41:19.059459 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m16:41:19.060456 [info ] [Thread-1 (]: 4 of 5 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m16:41:19.060456 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m16:41:19.060456 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m16:41:19.062451 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m16:41:19.064008 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m16:41:19.066536 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m16:41:19.067540 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:41:19.067540 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m16:41:19.068053 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:41:19.087758 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:41:19.087758 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:41:19.088690 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m16:41:19.089688 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:41:19.092191 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:41:19.092191 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m16:41:19.093188 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:41:19.094762 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:41:19.095691 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m16:41:19.095691 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:41:19.097691 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:41:19.097691 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:41:19.098284 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m16:41:19.099196 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:41:19.101761 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m16:41:19.101761 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m16:41:19.102696 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:41:19.104722 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m16:41:19.139208 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1000273-e052-4268-bdbf-b894abab3d23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E6A09040>]}
[0m16:41:19.140238 [info ] [Thread-1 (]: 4 of 5 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.08s]
[0m16:41:19.140238 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m16:41:19.141231 [debug] [Thread-1 (]: Began running node model.archi.view
[0m16:41:19.141231 [info ] [Thread-1 (]: 5 of 5 START sql view model main.view .......................................... [RUN]
[0m16:41:19.142201 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m16:41:19.142201 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m16:41:19.144226 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m16:41:19.145256 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m16:41:19.148790 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m16:41:19.149892 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:41:19.149892 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m16:41:19.150399 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:41:19.170350 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m16:41:19.170858 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:41:19.170858 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m16:41:19.171853 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:41:19.174273 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:41:19.175239 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m16:41:19.175239 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:41:19.177836 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:41:19.177836 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m16:41:19.177836 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:41:19.179829 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m16:41:19.180448 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:41:19.180448 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m16:41:19.183437 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m16:41:19.185466 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m16:41:19.185466 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m16:41:19.187847 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:41:19.188954 [debug] [Thread-1 (]: On model.archi.view: Close
[0m16:41:19.220382 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1000273-e052-4268-bdbf-b894abab3d23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E6B39040>]}
[0m16:41:19.220382 [info ] [Thread-1 (]: 5 of 5 OK created sql view model main.view ..................................... [[32mOK[0m in 0.08s]
[0m16:41:19.221936 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m16:41:19.222855 [debug] [MainThread]: Using duckdb connection "master"
[0m16:41:19.222855 [debug] [MainThread]: On master: BEGIN
[0m16:41:19.222855 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:41:19.242960 [debug] [MainThread]: SQL status: OK in 0.020 seconds
[0m16:41:19.243940 [debug] [MainThread]: On master: COMMIT
[0m16:41:19.243940 [debug] [MainThread]: Using duckdb connection "master"
[0m16:41:19.243940 [debug] [MainThread]: On master: COMMIT
[0m16:41:19.244933 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:41:19.244933 [debug] [MainThread]: On master: Close
[0m16:41:19.248286 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:41:19.249284 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m16:41:19.249284 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m16:41:19.249791 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m16:41:19.249852 [info ] [MainThread]: 
[0m16:41:19.249852 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.81 seconds (0.81s).
[0m16:41:19.251783 [debug] [MainThread]: Command end result
[0m16:41:19.266193 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:41:19.267741 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:41:19.272343 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m16:41:19.272343 [info ] [MainThread]: 
[0m16:41:19.273634 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:41:19.274174 [info ] [MainThread]: 
[0m16:41:19.274174 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m16:41:19.275202 [debug] [MainThread]: Command `dbt build` succeeded at 16:41:19.275202 after 1.69 seconds
[0m16:41:19.276196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E4385760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E4385640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298E42F49B0>]}
[0m16:41:19.276196 [debug] [MainThread]: Flushing usage events
[0m16:41:19.715256 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:48:40.508335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022EA647ABD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022EA2B1FD10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022EA5BB5220>]}


============================== 16:48:40.511852 | fcee5d4c-aace-484c-8d65-39ccb0db0e1c ==============================
[0m16:48:40.511852 [info ] [MainThread]: Running with dbt=1.9.1
[0m16:48:40.512847 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt docs serve', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:48:40.701970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fcee5d4c-aace-484c-8d65-39ccb0db0e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022EA6AE7170>]}
[0m16:48:40.754988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fcee5d4c-aace-484c-8d65-39ccb0db0e1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022EA5C8CB30>]}
[0m16:50:11.353605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1EC4F7650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1EC4F7860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1ED24B5C0>]}


============================== 16:50:11.358103 | f31af328-4844-419b-ab24-22f534219338 ==============================
[0m16:50:11.358103 [info ] [MainThread]: Running with dbt=1.9.1
[0m16:50:11.358610 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m16:50:11.547173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f31af328-4844-419b-ab24-22f534219338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1EC585CD0>]}
[0m16:50:11.602080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f31af328-4844-419b-ab24-22f534219338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1ED2483E0>]}
[0m16:50:11.605477 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m16:50:11.835574 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m16:50:11.945355 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:50:11.945898 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:50:11.950040 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.application
[0m16:50:11.967532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f31af328-4844-419b-ab24-22f534219338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1ED8E77A0>]}
[0m16:50:11.992347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f31af328-4844-419b-ab24-22f534219338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1EE65A7B0>]}
[0m16:50:11.992347 [info ] [MainThread]: Found 5 models, 424 macros
[0m16:50:11.993378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f31af328-4844-419b-ab24-22f534219338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1EE178140>]}
[0m16:50:11.994373 [info ] [MainThread]: 
[0m16:50:11.995370 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:50:11.995370 [info ] [MainThread]: 
[0m16:50:11.996369 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m16:50:12.000356 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m16:50:12.076079 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m16:50:12.077090 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m16:50:12.077090 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:12.092599 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:50:12.093587 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m16:50:12.093587 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:50:12.132125 [debug] [ThreadPool]: SQL status: OK in 0.038 seconds
[0m16:50:12.133673 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m16:50:12.134212 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m16:50:12.134212 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m16:50:12.139178 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_cleansed)
[0m16:50:12.140173 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:50:12.141182 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m16:50:12.141182 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:50:12.155329 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:50:12.156337 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m16:50:12.156337 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m16:50:12.194112 [debug] [ThreadPool]: SQL status: OK in 0.037 seconds
[0m16:50:12.194654 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m16:50:12.195679 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m16:50:12.195679 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m16:50:12.201510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f31af328-4844-419b-ab24-22f534219338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1EE150F80>]}
[0m16:50:12.204015 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m16:50:12.204539 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m16:50:12.204539 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m16:50:12.211519 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m16:50:12.211519 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m16:50:12.212516 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m16:50:12.212516 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m16:50:12.213514 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m16:50:12.213514 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m16:50:12.215508 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m16:50:12.215508 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m16:50:12.216680 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m16:50:12.218628 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m16:50:12.219591 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m16:50:12.219591 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m16:50:12.222089 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m16:50:12.222089 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m16:50:12.223884 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m16:50:12.223884 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m16:50:12.224400 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m16:50:12.224400 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m16:50:12.226384 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m16:50:12.227381 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m16:50:12.227923 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m16:50:12.227923 [debug] [Thread-1 (]: Began running node model.archi.view
[0m16:50:12.228883 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m16:50:12.228883 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m16:50:12.230878 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m16:50:12.231875 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m16:50:12.231875 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m16:50:12.233318 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:50:12.233431 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m16:50:12.233431 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m16:50:12.234342 [debug] [MainThread]: Command end result
[0m16:50:12.278935 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:50:12.281513 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:50:12.286862 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m16:50:12.289203 [debug] [MainThread]: Acquiring new duckdb connection 'generate_catalog'
[0m16:50:12.289203 [info ] [MainThread]: Building catalog
[0m16:50:12.298438 [debug] [ThreadPool]: Acquiring new duckdb connection 'pytorch_data.information_schema'
[0m16:50:12.304234 [debug] [ThreadPool]: Using duckdb connection "pytorch_data.information_schema"
[0m16:50:12.304342 [debug] [ThreadPool]: On pytorch_data.information_schema: BEGIN
[0m16:50:12.304342 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:12.319680 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m16:50:12.319680 [debug] [ThreadPool]: Using duckdb connection "pytorch_data.information_schema"
[0m16:50:12.319680 [debug] [ThreadPool]: On pytorch_data.information_schema: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "pytorch_data.information_schema"} */
with relations AS (
      select
        t.table_name
        , t.database_name
        , t.schema_name
        , 'BASE TABLE' as table_type
        , t.comment as table_comment
      from duckdb_tables() t
      WHERE t.database_name = 'pytorch_data'
      UNION ALL
      SELECT v.view_name as table_name
      , v.database_name
      , v.schema_name
      , 'VIEW' as table_type
      , v.comment as table_comment
      from duckdb_views() v
      WHERE v.database_name = 'pytorch_data'
    )
    select
        'pytorch_data' as table_database,
        r.schema_name as table_schema,
        r.table_name,
        r.table_type,
        r.table_comment,
        c.column_name,
        c.column_index as column_index,
        c.data_type as column_type,
        c.comment as column_comment,
        '' as table_owner
    FROM relations r JOIN duckdb_columns() c ON r.schema_name = c.schema_name AND r.table_name = c.table_name
    WHERE (upper(r.schema_name) = upper('main') or upper(r.schema_name) = upper('main_cleansed'))
    ORDER BY
        r.schema_name,
        r.table_name,
        c.column_index
[0m16:50:12.362645 [debug] [ThreadPool]: SQL status: OK in 0.042 seconds
[0m16:50:12.399633 [debug] [ThreadPool]: On pytorch_data.information_schema: ROLLBACK
[0m16:50:12.400173 [debug] [ThreadPool]: Failed to rollback 'pytorch_data.information_schema'
[0m16:50:12.400714 [debug] [ThreadPool]: On pytorch_data.information_schema: Close
[0m16:50:12.441514 [debug] [MainThread]: Wrote artifact CatalogArtifact to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\catalog.json
[0m16:50:12.455964 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m16:50:12.457550 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m16:50:12.457550 [info ] [MainThread]: Catalog written to C:\Users\Julien\repo\ArchiDecisionnelle\archi\target\catalog.json
[0m16:50:12.459076 [debug] [MainThread]: Command `dbt docs generate` succeeded at 16:50:12.459076 after 1.20 seconds
[0m16:50:12.459715 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m16:50:12.459829 [debug] [MainThread]: Connection 'pytorch_data.information_schema' was properly closed.
[0m16:50:12.459829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1EA7ACB60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1EC4F4B60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E1EE4C1250>]}
[0m16:50:12.460373 [debug] [MainThread]: Flushing usage events
[0m16:50:12.867642 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:50:34.077157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8ECCA09E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8ECCF5340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8ECCF78C0>]}


============================== 16:50:34.080654 | 93890999-03c0-4857-bf97-fab77462ef5a ==============================
[0m16:50:34.080654 [info ] [MainThread]: Running with dbt=1.9.1
[0m16:50:34.080654 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\Julien\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt docs serve', 'send_anonymous_usage_stats': 'True'}
[0m16:50:34.271915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '93890999-03c0-4857-bf97-fab77462ef5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8EE2AA1B0>]}
[0m16:50:34.325998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '93890999-03c0-4857-bf97-fab77462ef5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8EA39B380>]}
[0m12:01:03.868664 [error] [MainThread]: Encountered an error:

[0m12:01:03.881438 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\Julien\repo\ArchiDecisionnelle\venv\Lib\site-packages\dbt\cli\requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Julien\repo\ArchiDecisionnelle\venv\Lib\site-packages\dbt\cli\requires.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Julien\repo\ArchiDecisionnelle\venv\Lib\site-packages\dbt\cli\requires.py", line 235, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Julien\repo\ArchiDecisionnelle\venv\Lib\site-packages\dbt\cli\requires.py", line 264, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Julien\repo\ArchiDecisionnelle\venv\Lib\site-packages\dbt\cli\requires.py", line 311, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Julien\repo\ArchiDecisionnelle\venv\Lib\site-packages\dbt\cli\main.py", line 301, in docs_serve
    results = task.run()
              ^^^^^^^^^^
  File "C:\Users\Julien\repo\ArchiDecisionnelle\venv\Lib\site-packages\dbt\task\docs\serve.py", line 29, in run
    httpd.serve_forever()
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.12_3.12.2288.0_x64__qbz5n2kfra8p0\Lib\socketserver.py", line 235, in serve_forever
    ready = selector.select(poll_interval)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.12_3.12.2288.0_x64__qbz5n2kfra8p0\Lib\selectors.py", line 323, in select
    r, w, _ = self._select(self._readers, self._writers, [], timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.12_3.12.2288.0_x64__qbz5n2kfra8p0\Lib\selectors.py", line 314, in _select
    r, w, x = select.select(r, w, w, timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m12:01:03.883404 [debug] [MainThread]: Command `dbt docs serve` failed at 12:01:03.883404 after 69033.89 seconds
[0m12:01:03.884481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8ECCCA510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8EE2C9AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8EE200110>]}
[0m12:01:03.885025 [debug] [MainThread]: Flushing usage events
[0m12:01:04.313509 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:14:49.318920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028A43D8E7B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028A43D8FD70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028A43D8FBC0>]}


============================== 12:14:49.321549 | 7a73012b-cacb-46b7-bd68-30d8d6b0e4a4 ==============================
[0m12:14:49.321549 [info ] [MainThread]: Running with dbt=1.9.1
[0m12:14:49.321549 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt init', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:14:49.332689 [warn ] [MainThread]: [ConfigFolderDirectory]: Unable to parse logging event dictionary. Failed to parse dir field: expected string or bytes-like object, got 'WindowsPath'.. Dictionary: {'dir': WindowsPath('C:/Users/julie/.dbt')}
[0m12:14:49.333888 [info ] [MainThread]: Creating dbt configuration folder at 
[0m12:14:49.334968 [info ] [MainThread]: Setting up your profile.
[0m12:14:53.673135 [info ] [MainThread]: Profile archi written to C:\Users\julie\.dbt\profiles.yml using target's sample configuration. Once updated, you'll be able to start developing with dbt.
[0m12:14:53.674221 [debug] [MainThread]: Command `dbt init` succeeded at 12:14:53.674221 after 4.44 seconds
[0m12:14:53.674221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028A44A7F7A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028A44A7CB00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028A426CF0E0>]}
[0m12:14:53.675234 [debug] [MainThread]: Flushing usage events
[0m12:14:54.184521 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:15:07.253271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E4E97920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E48CA8D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E48CA870>]}


============================== 12:15:07.255343 | c102b1d0-dd8d-4c47-a597-5d2b13896249 ==============================
[0m12:15:07.255343 [info ] [MainThread]: Running with dbt=1.9.1
[0m12:15:07.256347 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\julie\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:15:07.369226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c102b1d0-dd8d-4c47-a597-5d2b13896249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E5831430>]}
[0m12:15:07.398612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c102b1d0-dd8d-4c47-a597-5d2b13896249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E58710D0>]}
[0m12:15:07.401125 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m12:15:07.520426 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m12:15:07.563090 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m12:15:07.563090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c102b1d0-dd8d-4c47-a597-5d2b13896249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E52803B0>]}
[0m12:15:08.088364 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.application
[0m12:15:08.093785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c102b1d0-dd8d-4c47-a597-5d2b13896249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E6E1B410>]}
[0m12:15:08.128276 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m12:15:08.130822 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m12:15:08.207621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c102b1d0-dd8d-4c47-a597-5d2b13896249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E6C09E50>]}
[0m12:15:08.207621 [info ] [MainThread]: Found 5 models, 4 sources, 424 macros
[0m12:15:08.208649 [info ] [MainThread]: 
[0m12:15:08.208649 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:15:08.210160 [info ] [MainThread]: 
[0m12:15:08.210160 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m12:15:08.212215 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev'
[0m12:15:09.221272 [debug] [ThreadPool]: Using duckdb connection "list_dev"
[0m12:15:09.221272 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dev"'
    
  
  
[0m12:15:09.221272 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:15:09.236026 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m12:15:09.237093 [debug] [ThreadPool]: On list_dev: Close
[0m12:15:09.240416 [debug] [ThreadPool]: Using duckdb connection "list_dev"
[0m12:15:09.240925 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dev"'
    
  
  
[0m12:15:09.240925 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:15:09.250361 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m12:15:09.250873 [debug] [ThreadPool]: On list_dev: Close
[0m12:15:09.252522 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now create_dev_main)
[0m12:15:09.252522 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "main"
"
[0m12:15:09.256641 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:15:09.256641 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dev'
        and type='sqlite'
    
  
[0m12:15:09.256641 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:15:09.261215 [debug] [ThreadPool]: SQL status: OK in 0.004 seconds
[0m12:15:09.262245 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:15:09.262245 [debug] [ThreadPool]: On create_dev_main: BEGIN
[0m12:15:09.262245 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:15:09.263271 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:15:09.263271 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
    
        create schema if not exists "dev"."main"
    
[0m12:15:09.264293 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m12:15:09.264293 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m12:15:09.264293 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:15:09.265334 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m12:15:09.265334 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:15:09.265334 [debug] [ThreadPool]: On create_dev_main: Close
[0m12:15:09.267471 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_dev_main, now create_dev_main_cleansed)
[0m12:15:09.267471 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "main_cleansed"
"
[0m12:15:09.268475 [debug] [ThreadPool]: Using duckdb connection "create_dev_main_cleansed"
[0m12:15:09.268475 [debug] [ThreadPool]: On create_dev_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dev'
        and type='sqlite'
    
  
[0m12:15:09.268475 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:15:09.273175 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m12:15:09.274685 [debug] [ThreadPool]: Using duckdb connection "create_dev_main_cleansed"
[0m12:15:09.274685 [debug] [ThreadPool]: On create_dev_main_cleansed: BEGIN
[0m12:15:09.274685 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:15:09.274685 [debug] [ThreadPool]: Using duckdb connection "create_dev_main_cleansed"
[0m12:15:09.275717 [debug] [ThreadPool]: On create_dev_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main_cleansed"} */

    
    
        create schema if not exists "dev"."main_cleansed"
    
[0m12:15:09.275717 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:15:09.275717 [debug] [ThreadPool]: On create_dev_main_cleansed: COMMIT
[0m12:15:09.276742 [debug] [ThreadPool]: Using duckdb connection "create_dev_main_cleansed"
[0m12:15:09.276742 [debug] [ThreadPool]: On create_dev_main_cleansed: COMMIT
[0m12:15:09.278250 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m12:15:09.278250 [debug] [ThreadPool]: On create_dev_main_cleansed: Close
[0m12:15:09.284018 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev_main'
[0m12:15:09.286532 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m12:15:09.288043 [debug] [ThreadPool]: On list_dev_main: BEGIN
[0m12:15:09.288043 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:15:09.297244 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m12:15:09.297244 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m12:15:09.297244 [debug] [ThreadPool]: On list_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev_main"} */
select
      'dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'dev'
  
[0m12:15:09.317208 [debug] [ThreadPool]: SQL status: OK in 0.019 seconds
[0m12:15:09.318223 [debug] [ThreadPool]: On list_dev_main: ROLLBACK
[0m12:15:09.318223 [debug] [ThreadPool]: Failed to rollback 'list_dev_main'
[0m12:15:09.319229 [debug] [ThreadPool]: On list_dev_main: Close
[0m12:15:09.320760 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev_main, now list_dev_main_cleansed)
[0m12:15:09.321781 [debug] [ThreadPool]: Using duckdb connection "list_dev_main_cleansed"
[0m12:15:09.321781 [debug] [ThreadPool]: On list_dev_main_cleansed: BEGIN
[0m12:15:09.321781 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:15:09.326384 [debug] [ThreadPool]: SQL status: OK in 0.004 seconds
[0m12:15:09.326384 [debug] [ThreadPool]: Using duckdb connection "list_dev_main_cleansed"
[0m12:15:09.326384 [debug] [ThreadPool]: On list_dev_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev_main_cleansed"} */
select
      'dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'dev'
  
[0m12:15:09.341973 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m12:15:09.343482 [debug] [ThreadPool]: On list_dev_main_cleansed: ROLLBACK
[0m12:15:09.343482 [debug] [ThreadPool]: Failed to rollback 'list_dev_main_cleansed'
[0m12:15:09.343482 [debug] [ThreadPool]: On list_dev_main_cleansed: Close
[0m12:15:09.345572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c102b1d0-dd8d-4c47-a597-5d2b13896249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E6DFC4A0>]}
[0m12:15:09.345572 [debug] [MainThread]: Using duckdb connection "master"
[0m12:15:09.346576 [debug] [MainThread]: On master: BEGIN
[0m12:15:09.346576 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:15:09.350145 [debug] [MainThread]: SQL status: OK in 0.004 seconds
[0m12:15:09.350145 [debug] [MainThread]: On master: COMMIT
[0m12:15:09.351176 [debug] [MainThread]: Using duckdb connection "master"
[0m12:15:09.351176 [debug] [MainThread]: On master: COMMIT
[0m12:15:09.351176 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m12:15:09.351176 [debug] [MainThread]: On master: Close
[0m12:15:09.353711 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m12:15:09.353711 [info ] [Thread-1 (]: 1 of 5 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m12:15:09.353711 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m12:15:09.354753 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m12:15:09.357827 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m12:15:09.358844 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m12:15:09.376975 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m12:15:09.376975 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:15:09.378009 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m12:15:09.378009 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:15:09.382585 [debug] [Thread-1 (]: SQL status: OK in 0.005 seconds
[0m12:15:09.382585 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:15:09.383618 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "dev"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m12:15:09.401476 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "dev"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m12:15:09.402500 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:15:09.402500 [debug] [Thread-1 (]: On model.archi.cleancommit: ROLLBACK
[0m12:15:09.412733 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommit'
[0m12:15:09.412733 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m12:15:09.416308 [debug] [Thread-1 (]: Runtime Error in model cleancommit (models\cleansed\cleancommit.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 12:     from raw_commits
                    ^
[0m12:15:09.417871 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c102b1d0-dd8d-4c47-a597-5d2b13896249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E4BB4DD0>]}
[0m12:15:09.418396 [error] [Thread-1 (]: 1 of 5 ERROR creating sql view model main_cleansed.cleancommit ................. [[31mERROR[0m in 0.06s]
[0m12:15:09.418396 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m12:15:09.418396 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m12:15:09.418396 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommit' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommit (models\cleansed\cleancommit.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 12:     from raw_commits
                    ^.
[0m12:15:09.419906 [info ] [Thread-1 (]: 2 of 5 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m12:15:09.419906 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m12:15:09.420935 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m12:15:09.421959 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m12:15:09.423061 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m12:15:09.424066 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m12:15:09.424066 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:15:09.424066 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m12:15:09.425581 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:15:09.430185 [debug] [Thread-1 (]: SQL status: OK in 0.005 seconds
[0m12:15:09.430185 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:15:09.430185 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "dev"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m12:15:09.444536 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "dev"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m12:15:09.446047 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:15:09.446047 [debug] [Thread-1 (]: On model.archi.cleancontributor: ROLLBACK
[0m12:15:09.448106 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancontributor'
[0m12:15:09.448106 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m12:15:09.450673 [debug] [Thread-1 (]: Runtime Error in model cleancontributor (models\cleansed\cleancontributor.sql)
  Catalog Error: Table with name raw_contributors does not exist!
  Did you mean "pg_constraint"?
  LINE 10:     from raw_contributors
                    ^
[0m12:15:09.451697 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c102b1d0-dd8d-4c47-a597-5d2b13896249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E73BFB90>]}
[0m12:15:09.451697 [error] [Thread-1 (]: 2 of 5 ERROR creating sql view model main_cleansed.cleancontributor ............ [[31mERROR[0m in 0.03s]
[0m12:15:09.451697 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m12:15:09.452725 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m12:15:09.452725 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancontributor' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancontributor (models\cleansed\cleancontributor.sql)
  Catalog Error: Table with name raw_contributors does not exist!
  Did you mean "pg_constraint"?
  LINE 10:     from raw_contributors
                    ^.
[0m12:15:09.452725 [info ] [Thread-1 (]: 3 of 5 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m12:15:09.453809 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m12:15:09.453809 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m12:15:09.454814 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m12:15:09.456323 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m12:15:09.457354 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m12:15:09.458396 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:15:09.458396 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m12:15:09.458928 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:15:09.463534 [debug] [Thread-1 (]: SQL status: OK in 0.005 seconds
[0m12:15:09.463534 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:15:09.463534 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "dev"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m12:15:09.478306 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "dev"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m12:15:09.479322 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:15:09.479831 [debug] [Thread-1 (]: On model.archi.cleanissue: ROLLBACK
[0m12:15:09.481365 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanissue'
[0m12:15:09.481365 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m12:15:09.484504 [debug] [Thread-1 (]: Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Catalog Error: Table with name raw_issues does not exist!
  Did you mean "pragma_database_list"?
  LINE 12:     from raw_issues
                    ^
[0m12:15:09.484504 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c102b1d0-dd8d-4c47-a597-5d2b13896249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E752FA70>]}
[0m12:15:09.485521 [error] [Thread-1 (]: 3 of 5 ERROR creating sql view model main_cleansed.cleanissue .................. [[31mERROR[0m in 0.03s]
[0m12:15:09.485521 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m12:15:09.485521 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m12:15:09.485521 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanissue' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Catalog Error: Table with name raw_issues does not exist!
  Did you mean "pragma_database_list"?
  LINE 12:     from raw_issues
                    ^.
[0m12:15:09.487032 [info ] [Thread-1 (]: 4 of 5 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m12:15:09.487032 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m12:15:09.487032 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m12:15:09.488541 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m12:15:09.488541 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m12:15:09.491081 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m12:15:09.491081 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:15:09.491081 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m12:15:09.492105 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:15:09.496195 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m12:15:09.496195 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:15:09.497200 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "dev"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m12:15:09.510975 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "dev"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m12:15:09.510975 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:15:09.511998 [debug] [Thread-1 (]: On model.archi.cleanpr: ROLLBACK
[0m12:15:09.513022 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanpr'
[0m12:15:09.514045 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m12:15:09.516469 [debug] [Thread-1 (]: Runtime Error in model cleanpr (models\cleansed\cleanpr.sql)
  Catalog Error: Table with name raw_pull_requests does not exist!
  Did you mean "pg_tables"?
  LINE 12:     from raw_pull_requests
                    ^
[0m12:15:09.517474 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c102b1d0-dd8d-4c47-a597-5d2b13896249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E7576450>]}
[0m12:15:09.517978 [error] [Thread-1 (]: 4 of 5 ERROR creating sql view model main_cleansed.cleanpr ..................... [[31mERROR[0m in 0.03s]
[0m12:15:09.517978 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m12:15:09.517978 [debug] [Thread-1 (]: Began running node model.archi.view
[0m12:15:09.519006 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanpr' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanpr (models\cleansed\cleanpr.sql)
  Catalog Error: Table with name raw_pull_requests does not exist!
  Did you mean "pg_tables"?
  LINE 12:     from raw_pull_requests
                    ^.
[0m12:15:09.519006 [info ] [Thread-1 (]: 5 of 5 START sql view model main.view .......................................... [RUN]
[0m12:15:09.519006 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m12:15:09.520011 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m12:15:09.520515 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m12:15:09.521542 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m12:15:09.522585 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m12:15:09.523606 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:15:09.523606 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m12:15:09.524630 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:15:09.529217 [debug] [Thread-1 (]: SQL status: OK in 0.005 seconds
[0m12:15:09.529217 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:15:09.529217 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "dev"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m12:15:09.543520 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "dev"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m12:15:09.543520 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:15:09.543520 [debug] [Thread-1 (]: On model.archi.view: ROLLBACK
[0m12:15:09.545626 [debug] [Thread-1 (]: Failed to rollback 'model.archi.view'
[0m12:15:09.545626 [debug] [Thread-1 (]: On model.archi.view: Close
[0m12:15:09.549891 [debug] [Thread-1 (]: Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 5:     SELECT * FROM raw_commits
                            ^
[0m12:15:09.549891 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c102b1d0-dd8d-4c47-a597-5d2b13896249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E75A5370>]}
[0m12:15:09.550396 [error] [Thread-1 (]: 5 of 5 ERROR creating sql view model main.view ................................. [[31mERROR[0m in 0.03s]
[0m12:15:09.550396 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m12:15:09.551424 [debug] [Thread-4 (]: Marking all children of 'model.archi.view' to be skipped because of status 'error'.  Reason: Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 5:     SELECT * FROM raw_commits
                            ^.
[0m12:15:09.551424 [debug] [MainThread]: Using duckdb connection "master"
[0m12:15:09.552470 [debug] [MainThread]: On master: BEGIN
[0m12:15:09.552470 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:15:09.557617 [debug] [MainThread]: SQL status: OK in 0.005 seconds
[0m12:15:09.557617 [debug] [MainThread]: On master: COMMIT
[0m12:15:09.557617 [debug] [MainThread]: Using duckdb connection "master"
[0m12:15:09.557617 [debug] [MainThread]: On master: COMMIT
[0m12:15:09.558639 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m12:15:09.558639 [debug] [MainThread]: On master: Close
[0m12:15:09.560149 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:15:09.560149 [debug] [MainThread]: Connection 'create_dev_main_cleansed' was properly closed.
[0m12:15:09.560149 [debug] [MainThread]: Connection 'list_dev_main_cleansed' was properly closed.
[0m12:15:09.560149 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m12:15:09.560149 [info ] [MainThread]: 
[0m12:15:09.561181 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 1.35 seconds (1.35s).
[0m12:15:09.562272 [debug] [MainThread]: Command end result
[0m12:15:09.572464 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m12:15:09.573467 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m12:15:09.577031 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m12:15:09.578079 [info ] [MainThread]: 
[0m12:15:09.578079 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m12:15:09.578079 [info ] [MainThread]: 
[0m12:15:09.579112 [error] [MainThread]:   Runtime Error in model cleancommit (models\cleansed\cleancommit.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 12:     from raw_commits
                    ^
[0m12:15:09.579112 [info ] [MainThread]: 
[0m12:15:09.579112 [error] [MainThread]:   Runtime Error in model cleancontributor (models\cleansed\cleancontributor.sql)
  Catalog Error: Table with name raw_contributors does not exist!
  Did you mean "pg_constraint"?
  LINE 10:     from raw_contributors
                    ^
[0m12:15:09.580116 [info ] [MainThread]: 
[0m12:15:09.580116 [error] [MainThread]:   Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Catalog Error: Table with name raw_issues does not exist!
  Did you mean "pragma_database_list"?
  LINE 12:     from raw_issues
                    ^
[0m12:15:09.580621 [info ] [MainThread]: 
[0m12:15:09.580621 [error] [MainThread]:   Runtime Error in model cleanpr (models\cleansed\cleanpr.sql)
  Catalog Error: Table with name raw_pull_requests does not exist!
  Did you mean "pg_tables"?
  LINE 12:     from raw_pull_requests
                    ^
[0m12:15:09.580621 [info ] [MainThread]: 
[0m12:15:09.580621 [error] [MainThread]:   Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 5:     SELECT * FROM raw_commits
                            ^
[0m12:15:09.580621 [info ] [MainThread]: 
[0m12:15:09.582131 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=0 TOTAL=5
[0m12:15:09.582131 [debug] [MainThread]: Command `dbt build` failed at 12:15:09.582131 after 2.41 seconds
[0m12:15:09.583164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E4F80470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E521F9E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000207E521EBA0>]}
[0m12:15:09.583164 [debug] [MainThread]: Flushing usage events
[0m12:15:10.076307 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:15:33.080888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BCFC57EED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BCFC57F020>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BCFC57EF60>]}


============================== 12:15:33.083274 | 8ad183bd-4b7b-4bca-88e9-48ff65b7de39 ==============================
[0m12:15:33.083274 [info ] [MainThread]: Running with dbt=1.9.1
[0m12:15:33.083274 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\julie\\.dbt', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt build', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:15:33.199842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8ad183bd-4b7b-4bca-88e9-48ff65b7de39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BCFCAF6FC0>]}
[0m12:15:33.231370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8ad183bd-4b7b-4bca-88e9-48ff65b7de39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BCFC543A40>]}
[0m12:15:33.234500 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m12:15:33.357454 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m12:15:33.401858 [error] [MainThread]: Encountered an error:
'str' object has no attribute 'get'
[0m12:15:33.403132 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\cli\requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\cli\requires.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\cli\requires.py", line 235, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\cli\requires.py", line 264, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\cli\requires.py", line 311, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\cli\requires.py", line 327, in wrapper
    setup_manifest(ctx, write=write, write_perf_info=write_perf_info)
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\cli\requires.py", line 351, in setup_manifest
    ctx.obj["manifest"] = parse_manifest(
                          ^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\manifest.py", line 2061, in parse_manifest
    manifest = ManifestLoader.get_full_manifest(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\manifest.py", line 312, in get_full_manifest
    manifest = loader.load()
               ^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\manifest.py", line 359, in load
    file_reader.read_files()
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\read_files.py", line 212, in read_files
    self.read_files_for_project(project, file_types)
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\read_files.py", line 219, in read_files_for_project
    project_files[file_type_info["parser"]] = read_files_for_parser(
                                              ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\read_files.py", line 167, in read_files_for_parser
    source_files = get_source_files(
                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\read_files.py", line 156, in get_source_files
    file = load_source_file(fp, parse_file_type, project.project_name, saved_files)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\read_files.py", line 89, in load_source_file
    dfy = yaml_from_file(source_file)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\schemas.py", line 124, in yaml_from_file
    for table in source.get("tables", []):
                 ^^^^^^^^^^
AttributeError: 'str' object has no attribute 'get'

[0m12:15:33.404136 [debug] [MainThread]: Command `dbt build` failed at 12:15:33.404136 after 0.41 seconds
[0m12:15:33.404136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BCFCB2E840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BCFCC53C20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BCFCC1CA70>]}
[0m12:15:33.404136 [debug] [MainThread]: Flushing usage events
[0m12:15:33.761058 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:17:18.130182 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020250062DB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002024D9C9460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202500619D0>]}


============================== 12:17:18.132713 | d9789ff6-b80f-4bdb-9fd8-da1a0d7d02df ==============================
[0m12:17:18.132713 [info ] [MainThread]: Running with dbt=1.9.1
[0m12:17:18.133736 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:17:18.243195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd9789ff6-b80f-4bdb-9fd8-da1a0d7d02df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020250516F00>]}
[0m12:17:18.273894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd9789ff6-b80f-4bdb-9fd8-da1a0d7d02df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020250516D50>]}
[0m12:17:18.275958 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m12:17:18.392029 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m12:17:18.435892 [error] [MainThread]: Encountered an error:
'str' object has no attribute 'get'
[0m12:17:18.437935 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\cli\requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\cli\requires.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\cli\requires.py", line 235, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\cli\requires.py", line 264, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\cli\requires.py", line 311, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\cli\requires.py", line 327, in wrapper
    setup_manifest(ctx, write=write, write_perf_info=write_perf_info)
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\cli\requires.py", line 351, in setup_manifest
    ctx.obj["manifest"] = parse_manifest(
                          ^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\manifest.py", line 2061, in parse_manifest
    manifest = ManifestLoader.get_full_manifest(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\manifest.py", line 312, in get_full_manifest
    manifest = loader.load()
               ^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\manifest.py", line 359, in load
    file_reader.read_files()
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\read_files.py", line 212, in read_files
    self.read_files_for_project(project, file_types)
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\read_files.py", line 219, in read_files_for_project
    project_files[file_type_info["parser"]] = read_files_for_parser(
                                              ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\read_files.py", line 167, in read_files_for_parser
    source_files = get_source_files(
                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\read_files.py", line 156, in get_source_files
    file = load_source_file(fp, parse_file_type, project.project_name, saved_files)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\read_files.py", line 89, in load_source_file
    dfy = yaml_from_file(source_file)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julie\repo\ArchiDecisionnelle\.venv\Lib\site-packages\dbt\parser\schemas.py", line 124, in yaml_from_file
    for table in source.get("tables", []):
                 ^^^^^^^^^^
AttributeError: 'str' object has no attribute 'get'

[0m12:17:18.438961 [debug] [MainThread]: Command `dbt build` failed at 12:17:18.438961 after 0.39 seconds
[0m12:17:18.438961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202503DDA30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020250516C60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202504CE840>]}
[0m12:17:18.438961 [debug] [MainThread]: Flushing usage events
[0m12:17:18.837753 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:19:04.119993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECED09A630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECED8A06B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECEDBCA6F0>]}


============================== 12:19:04.122667 | 2c06a68b-f63c-4812-b086-f85f1c8b90e8 ==============================
[0m12:19:04.122667 [info ] [MainThread]: Running with dbt=1.9.1
[0m12:19:04.122667 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:19:04.234684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2c06a68b-f63c-4812-b086-f85f1c8b90e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECEE0820F0>]}
[0m12:19:04.264869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2c06a68b-f63c-4812-b086-f85f1c8b90e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECED70B1A0>]}
[0m12:19:04.266907 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m12:19:04.382117 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m12:19:04.450480 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:19:04.450480 [debug] [MainThread]: Partial parsing: updated file: archi://models\duckdb\sources.yaml
[0m12:19:04.519796 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.application
[0m12:19:04.522886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c06a68b-f63c-4812-b086-f85f1c8b90e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECEF516210>]}
[0m12:19:04.547963 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m12:19:04.549476 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m12:19:04.573097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c06a68b-f63c-4812-b086-f85f1c8b90e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECEF716DB0>]}
[0m12:19:04.573097 [info ] [MainThread]: Found 5 models, 424 macros
[0m12:19:04.574607 [info ] [MainThread]: 
[0m12:19:04.574607 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:19:04.575634 [info ] [MainThread]: 
[0m12:19:04.575634 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m12:19:04.577699 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev'
[0m12:19:04.621020 [debug] [ThreadPool]: Using duckdb connection "list_dev"
[0m12:19:04.621020 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dev"'
    
  
  
[0m12:19:04.621522 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:19:04.659429 [debug] [ThreadPool]: SQL status: OK in 0.038 seconds
[0m12:19:04.660459 [debug] [ThreadPool]: On list_dev: Close
[0m12:19:04.662997 [debug] [ThreadPool]: Using duckdb connection "list_dev"
[0m12:19:04.662997 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dev"'
    
  
  
[0m12:19:04.662997 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:19:04.672454 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m12:19:04.672454 [debug] [ThreadPool]: On list_dev: Close
[0m12:19:04.675063 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now create_dev_main_cleansed)
[0m12:19:04.675063 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "main_cleansed"
"
[0m12:19:04.680182 [debug] [ThreadPool]: Using duckdb connection "create_dev_main_cleansed"
[0m12:19:04.680182 [debug] [ThreadPool]: On create_dev_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dev'
        and type='sqlite'
    
  
[0m12:19:04.680182 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:19:04.684786 [debug] [ThreadPool]: SQL status: OK in 0.004 seconds
[0m12:19:04.685323 [debug] [ThreadPool]: Using duckdb connection "create_dev_main_cleansed"
[0m12:19:04.685323 [debug] [ThreadPool]: On create_dev_main_cleansed: BEGIN
[0m12:19:04.686353 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:19:04.686353 [debug] [ThreadPool]: Using duckdb connection "create_dev_main_cleansed"
[0m12:19:04.686353 [debug] [ThreadPool]: On create_dev_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main_cleansed"} */

    
    
        create schema if not exists "dev"."main_cleansed"
    
[0m12:19:04.686353 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:19:04.687373 [debug] [ThreadPool]: On create_dev_main_cleansed: COMMIT
[0m12:19:04.687373 [debug] [ThreadPool]: Using duckdb connection "create_dev_main_cleansed"
[0m12:19:04.687373 [debug] [ThreadPool]: On create_dev_main_cleansed: COMMIT
[0m12:19:04.689440 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m12:19:04.689440 [debug] [ThreadPool]: On create_dev_main_cleansed: Close
[0m12:19:04.694011 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_dev_main_cleansed, now create_dev_main)
[0m12:19:04.694519 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "main"
"
[0m12:19:04.695584 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:19:04.695584 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dev'
        and type='sqlite'
    
  
[0m12:19:04.695584 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:19:04.705865 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m12:19:04.705865 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:19:04.706894 [debug] [ThreadPool]: On create_dev_main: BEGIN
[0m12:19:04.706894 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:19:04.706894 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:19:04.706894 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
    
        create schema if not exists "dev"."main"
    
[0m12:19:04.707923 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:19:04.707923 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m12:19:04.707923 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:19:04.708960 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m12:19:04.708960 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:19:04.708960 [debug] [ThreadPool]: On create_dev_main: Close
[0m12:19:04.711015 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev_main_cleansed'
[0m12:19:04.714122 [debug] [ThreadPool]: Using duckdb connection "list_dev_main_cleansed"
[0m12:19:04.715151 [debug] [ThreadPool]: On list_dev_main_cleansed: BEGIN
[0m12:19:04.715151 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:19:04.719208 [debug] [ThreadPool]: SQL status: OK in 0.004 seconds
[0m12:19:04.719208 [debug] [ThreadPool]: Using duckdb connection "list_dev_main_cleansed"
[0m12:19:04.720232 [debug] [ThreadPool]: On list_dev_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev_main_cleansed"} */
select
      'dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'dev'
  
[0m12:19:04.736078 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m12:19:04.736078 [debug] [ThreadPool]: On list_dev_main_cleansed: ROLLBACK
[0m12:19:04.737842 [debug] [ThreadPool]: Failed to rollback 'list_dev_main_cleansed'
[0m12:19:04.737842 [debug] [ThreadPool]: On list_dev_main_cleansed: Close
[0m12:19:04.739902 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev_main_cleansed, now list_dev_main)
[0m12:19:04.740930 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m12:19:04.740930 [debug] [ThreadPool]: On list_dev_main: BEGIN
[0m12:19:04.740930 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:19:04.744493 [debug] [ThreadPool]: SQL status: OK in 0.004 seconds
[0m12:19:04.744493 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m12:19:04.746003 [debug] [ThreadPool]: On list_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev_main"} */
select
      'dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'dev'
  
[0m12:19:04.761833 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m12:19:04.761833 [debug] [ThreadPool]: On list_dev_main: ROLLBACK
[0m12:19:04.763342 [debug] [ThreadPool]: Failed to rollback 'list_dev_main'
[0m12:19:04.763342 [debug] [ThreadPool]: On list_dev_main: Close
[0m12:19:04.764849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c06a68b-f63c-4812-b086-f85f1c8b90e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECEF17CB00>]}
[0m12:19:04.764849 [debug] [MainThread]: Using duckdb connection "master"
[0m12:19:04.765873 [debug] [MainThread]: On master: BEGIN
[0m12:19:04.765873 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:19:04.769427 [debug] [MainThread]: SQL status: OK in 0.004 seconds
[0m12:19:04.769427 [debug] [MainThread]: On master: COMMIT
[0m12:19:04.770451 [debug] [MainThread]: Using duckdb connection "master"
[0m12:19:04.770451 [debug] [MainThread]: On master: COMMIT
[0m12:19:04.770451 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m12:19:04.770451 [debug] [MainThread]: On master: Close
[0m12:19:04.772504 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m12:19:04.773508 [info ] [Thread-1 (]: 1 of 5 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m12:19:04.774013 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m12:19:04.774013 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m12:19:04.777603 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m12:19:04.778606 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m12:19:04.794450 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m12:19:04.795468 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:19:04.795468 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m12:19:04.795468 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:19:04.799574 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m12:19:04.800593 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:19:04.800593 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "dev"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m12:19:04.815443 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "dev"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m12:19:04.815443 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:19:04.815443 [debug] [Thread-1 (]: On model.archi.cleancommit: ROLLBACK
[0m12:19:04.819015 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommit'
[0m12:19:04.819015 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m12:19:04.822570 [debug] [Thread-1 (]: Runtime Error in model cleancommit (models\cleansed\cleancommit.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 12:     from raw_commits
                    ^
[0m12:19:04.824082 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c06a68b-f63c-4812-b086-f85f1c8b90e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECEF21C350>]}
[0m12:19:04.824590 [error] [Thread-1 (]: 1 of 5 ERROR creating sql view model main_cleansed.cleancommit ................. [[31mERROR[0m in 0.05s]
[0m12:19:04.825102 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m12:19:04.825102 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m12:19:04.825102 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommit' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommit (models\cleansed\cleancommit.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 12:     from raw_commits
                    ^.
[0m12:19:04.826132 [info ] [Thread-1 (]: 2 of 5 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m12:19:04.826132 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m12:19:04.827162 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m12:19:04.828671 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m12:19:04.828671 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m12:19:04.830702 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m12:19:04.830702 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:19:04.830702 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m12:19:04.831722 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:19:04.835768 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m12:19:04.835768 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:19:04.835768 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "dev"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m12:19:04.851048 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "dev"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m12:19:04.851048 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:19:04.851048 [debug] [Thread-1 (]: On model.archi.cleancontributor: ROLLBACK
[0m12:19:04.853089 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancontributor'
[0m12:19:04.853089 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m12:19:04.856641 [debug] [Thread-1 (]: Runtime Error in model cleancontributor (models\cleansed\cleancontributor.sql)
  Catalog Error: Table with name raw_contributors does not exist!
  Did you mean "pg_constraint"?
  LINE 10:     from raw_contributors
                    ^
[0m12:19:04.856641 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c06a68b-f63c-4812-b086-f85f1c8b90e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECEFE710A0>]}
[0m12:19:04.856641 [error] [Thread-1 (]: 2 of 5 ERROR creating sql view model main_cleansed.cleancontributor ............ [[31mERROR[0m in 0.03s]
[0m12:19:04.857646 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m12:19:04.858150 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m12:19:04.858150 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancontributor' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancontributor (models\cleansed\cleancontributor.sql)
  Catalog Error: Table with name raw_contributors does not exist!
  Did you mean "pg_constraint"?
  LINE 10:     from raw_contributors
                    ^.
[0m12:19:04.858677 [info ] [Thread-1 (]: 3 of 5 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m12:19:04.859208 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m12:19:04.859208 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m12:19:04.860235 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m12:19:04.861258 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m12:19:04.863307 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m12:19:04.863307 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:19:04.864312 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m12:19:04.864815 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:19:04.868885 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m12:19:04.868885 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:19:04.868885 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "dev"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m12:19:04.884174 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "dev"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m12:19:04.884174 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:19:04.884678 [debug] [Thread-1 (]: On model.archi.cleanissue: ROLLBACK
[0m12:19:04.885704 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanissue'
[0m12:19:04.886732 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m12:19:04.889826 [debug] [Thread-1 (]: Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Catalog Error: Table with name raw_issues does not exist!
  Did you mean "pragma_database_list"?
  LINE 12:     from raw_issues
                    ^
[0m12:19:04.889826 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c06a68b-f63c-4812-b086-f85f1c8b90e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECEFE850A0>]}
[0m12:19:04.889826 [error] [Thread-1 (]: 3 of 5 ERROR creating sql view model main_cleansed.cleanissue .................. [[31mERROR[0m in 0.03s]
[0m12:19:04.890842 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m12:19:04.890842 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m12:19:04.890842 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanissue' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Catalog Error: Table with name raw_issues does not exist!
  Did you mean "pragma_database_list"?
  LINE 12:     from raw_issues
                    ^.
[0m12:19:04.891860 [info ] [Thread-1 (]: 4 of 5 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m12:19:04.891860 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m12:19:04.891860 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m12:19:04.893375 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m12:19:04.894383 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m12:19:04.895914 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m12:19:04.896938 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:19:04.896938 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m12:19:04.896938 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:19:04.901164 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m12:19:04.901164 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:19:04.902188 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "dev"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m12:19:04.915855 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "dev"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m12:19:04.916861 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:19:04.916861 [debug] [Thread-1 (]: On model.archi.cleanpr: ROLLBACK
[0m12:19:04.918386 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanpr'
[0m12:19:04.918386 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m12:19:04.921485 [debug] [Thread-1 (]: Runtime Error in model cleanpr (models\cleansed\cleanpr.sql)
  Catalog Error: Table with name raw_pull_requests does not exist!
  Did you mean "pg_tables"?
  LINE 12:     from raw_pull_requests
                    ^
[0m12:19:04.922504 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c06a68b-f63c-4812-b086-f85f1c8b90e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECEFE72FC0>]}
[0m12:19:04.922504 [error] [Thread-1 (]: 4 of 5 ERROR creating sql view model main_cleansed.cleanpr ..................... [[31mERROR[0m in 0.03s]
[0m12:19:04.922504 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m12:19:04.922504 [debug] [Thread-1 (]: Began running node model.archi.view
[0m12:19:04.924014 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanpr' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanpr (models\cleansed\cleanpr.sql)
  Catalog Error: Table with name raw_pull_requests does not exist!
  Did you mean "pg_tables"?
  LINE 12:     from raw_pull_requests
                    ^.
[0m12:19:04.924014 [info ] [Thread-1 (]: 5 of 5 START sql view model main.view .......................................... [RUN]
[0m12:19:04.924014 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m12:19:04.925045 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m12:19:04.926069 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m12:19:04.926069 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m12:19:04.928114 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m12:19:04.929145 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:19:04.929145 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m12:19:04.929145 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:19:04.933320 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m12:19:04.933320 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:19:04.934322 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "dev"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m12:19:04.948568 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "dev"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m12:19:04.948568 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:19:04.948568 [debug] [Thread-1 (]: On model.archi.view: ROLLBACK
[0m12:19:04.949588 [debug] [Thread-1 (]: Failed to rollback 'model.archi.view'
[0m12:19:04.951097 [debug] [Thread-1 (]: On model.archi.view: Close
[0m12:19:04.953181 [debug] [Thread-1 (]: Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 5:     SELECT * FROM raw_commits
                            ^
[0m12:19:04.954184 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c06a68b-f63c-4812-b086-f85f1c8b90e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECEFDE3BC0>]}
[0m12:19:04.954688 [error] [Thread-1 (]: 5 of 5 ERROR creating sql view model main.view ................................. [[31mERROR[0m in 0.03s]
[0m12:19:04.954688 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m12:19:04.955717 [debug] [Thread-4 (]: Marking all children of 'model.archi.view' to be skipped because of status 'error'.  Reason: Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 5:     SELECT * FROM raw_commits
                            ^.
[0m12:19:04.955717 [debug] [MainThread]: Using duckdb connection "master"
[0m12:19:04.956746 [debug] [MainThread]: On master: BEGIN
[0m12:19:04.956746 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:19:04.959826 [debug] [MainThread]: SQL status: OK in 0.004 seconds
[0m12:19:04.960904 [debug] [MainThread]: On master: COMMIT
[0m12:19:04.960904 [debug] [MainThread]: Using duckdb connection "master"
[0m12:19:04.961425 [debug] [MainThread]: On master: COMMIT
[0m12:19:04.961425 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m12:19:04.961959 [debug] [MainThread]: On master: Close
[0m12:19:04.962987 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:19:04.963991 [debug] [MainThread]: Connection 'create_dev_main' was properly closed.
[0m12:19:04.963991 [debug] [MainThread]: Connection 'list_dev_main' was properly closed.
[0m12:19:04.964494 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m12:19:04.964494 [info ] [MainThread]: 
[0m12:19:04.965001 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.39 seconds (0.39s).
[0m12:19:04.965511 [debug] [MainThread]: Command end result
[0m12:19:04.975198 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m12:19:04.976313 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m12:19:04.979364 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m12:19:04.980383 [info ] [MainThread]: 
[0m12:19:04.980383 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m12:19:04.980383 [info ] [MainThread]: 
[0m12:19:04.981419 [error] [MainThread]:   Runtime Error in model cleancommit (models\cleansed\cleancommit.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 12:     from raw_commits
                    ^
[0m12:19:04.981419 [info ] [MainThread]: 
[0m12:19:04.981943 [error] [MainThread]:   Runtime Error in model cleancontributor (models\cleansed\cleancontributor.sql)
  Catalog Error: Table with name raw_contributors does not exist!
  Did you mean "pg_constraint"?
  LINE 10:     from raw_contributors
                    ^
[0m12:19:04.981943 [info ] [MainThread]: 
[0m12:19:04.982472 [error] [MainThread]:   Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Catalog Error: Table with name raw_issues does not exist!
  Did you mean "pragma_database_list"?
  LINE 12:     from raw_issues
                    ^
[0m12:19:04.982472 [info ] [MainThread]: 
[0m12:19:04.982472 [error] [MainThread]:   Runtime Error in model cleanpr (models\cleansed\cleanpr.sql)
  Catalog Error: Table with name raw_pull_requests does not exist!
  Did you mean "pg_tables"?
  LINE 12:     from raw_pull_requests
                    ^
[0m12:19:04.982472 [info ] [MainThread]: 
[0m12:19:04.983981 [error] [MainThread]:   Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 5:     SELECT * FROM raw_commits
                            ^
[0m12:19:04.983981 [info ] [MainThread]: 
[0m12:19:04.983981 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=0 TOTAL=5
[0m12:19:04.985048 [debug] [MainThread]: Command `dbt build` failed at 12:19:04.985048 after 0.95 seconds
[0m12:19:04.985048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECEDAF9EE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECEB1A5070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ECED493110>]}
[0m12:19:04.985048 [debug] [MainThread]: Flushing usage events
[0m12:19:05.381717 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:19:37.425222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8A0015820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B89D287710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B89FF24EF0>]}


============================== 12:19:37.428372 | a395964c-3bd1-4e37-806c-a256330836c8 ==============================
[0m12:19:37.428372 [info ] [MainThread]: Running with dbt=1.9.1
[0m12:19:37.428372 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:19:37.537464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a395964c-3bd1-4e37-806c-a256330836c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8A0B66E70>]}
[0m12:19:37.567557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a395964c-3bd1-4e37-806c-a256330836c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8A083C380>]}
[0m12:19:37.569603 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m12:19:37.685947 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m12:19:37.748077 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:19:37.748077 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:19:37.752113 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.application
[0m12:19:37.762319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a395964c-3bd1-4e37-806c-a256330836c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8A202FEF0>]}
[0m12:19:37.789767 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m12:19:37.791862 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m12:19:37.814843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a395964c-3bd1-4e37-806c-a256330836c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8A2222FF0>]}
[0m12:19:37.898617 [info ] [MainThread]: Found 5 models, 424 macros
[0m12:19:37.900699 [info ] [MainThread]: 
[0m12:19:37.900699 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:19:37.900699 [info ] [MainThread]: 
[0m12:19:37.900699 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m12:19:37.903250 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev'
[0m12:19:37.946612 [debug] [ThreadPool]: Using duckdb connection "list_dev"
[0m12:19:37.947641 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dev"'
    
  
  
[0m12:19:37.947641 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:19:37.953249 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m12:19:37.954760 [debug] [ThreadPool]: On list_dev: Close
[0m12:19:37.958324 [debug] [ThreadPool]: Using duckdb connection "list_dev"
[0m12:19:37.958324 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dev"'
    
  
  
[0m12:19:37.958324 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:19:37.963462 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m12:19:37.963462 [debug] [ThreadPool]: On list_dev: Close
[0m12:19:37.965698 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now create_dev_main_cleansed)
[0m12:19:37.966723 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "main_cleansed"
"
[0m12:19:37.970146 [debug] [ThreadPool]: Using duckdb connection "create_dev_main_cleansed"
[0m12:19:37.970146 [debug] [ThreadPool]: On create_dev_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dev'
        and type='sqlite'
    
  
[0m12:19:37.970146 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:19:37.974694 [debug] [ThreadPool]: SQL status: OK in 0.004 seconds
[0m12:19:37.975197 [debug] [ThreadPool]: Using duckdb connection "create_dev_main_cleansed"
[0m12:19:37.975197 [debug] [ThreadPool]: On create_dev_main_cleansed: BEGIN
[0m12:19:37.976272 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:19:37.976272 [debug] [ThreadPool]: Using duckdb connection "create_dev_main_cleansed"
[0m12:19:37.976272 [debug] [ThreadPool]: On create_dev_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main_cleansed"} */

    
    
        create schema if not exists "dev"."main_cleansed"
    
[0m12:19:37.977277 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:19:37.977277 [debug] [ThreadPool]: On create_dev_main_cleansed: COMMIT
[0m12:19:37.977277 [debug] [ThreadPool]: Using duckdb connection "create_dev_main_cleansed"
[0m12:19:37.978303 [debug] [ThreadPool]: On create_dev_main_cleansed: COMMIT
[0m12:19:37.978303 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:19:37.978303 [debug] [ThreadPool]: On create_dev_main_cleansed: Close
[0m12:19:37.979330 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_dev_main_cleansed, now create_dev_main)
[0m12:19:37.980850 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "main"
"
[0m12:19:37.981882 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:19:37.981882 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dev'
        and type='sqlite'
    
  
[0m12:19:37.981882 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:19:37.986447 [debug] [ThreadPool]: SQL status: OK in 0.004 seconds
[0m12:19:37.986447 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:19:37.987467 [debug] [ThreadPool]: On create_dev_main: BEGIN
[0m12:19:37.987467 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:19:37.987467 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:19:37.987467 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
    
        create schema if not exists "dev"."main"
    
[0m12:19:37.988511 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:19:37.988511 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m12:19:37.988511 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:19:37.989536 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m12:19:37.989536 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:19:37.989536 [debug] [ThreadPool]: On create_dev_main: Close
[0m12:19:37.991643 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev_main_cleansed'
[0m12:19:37.995761 [debug] [ThreadPool]: Using duckdb connection "list_dev_main_cleansed"
[0m12:19:37.995761 [debug] [ThreadPool]: On list_dev_main_cleansed: BEGIN
[0m12:19:37.996266 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:19:37.999316 [debug] [ThreadPool]: SQL status: OK in 0.004 seconds
[0m12:19:38.000348 [debug] [ThreadPool]: Using duckdb connection "list_dev_main_cleansed"
[0m12:19:38.000348 [debug] [ThreadPool]: On list_dev_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev_main_cleansed"} */
select
      'dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'dev'
  
[0m12:19:38.017196 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m12:19:38.017196 [debug] [ThreadPool]: On list_dev_main_cleansed: ROLLBACK
[0m12:19:38.018227 [debug] [ThreadPool]: Failed to rollback 'list_dev_main_cleansed'
[0m12:19:38.018227 [debug] [ThreadPool]: On list_dev_main_cleansed: Close
[0m12:19:38.020294 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev_main_cleansed, now list_dev_main)
[0m12:19:38.021317 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m12:19:38.022411 [debug] [ThreadPool]: On list_dev_main: BEGIN
[0m12:19:38.022411 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:19:38.025958 [debug] [ThreadPool]: SQL status: OK in 0.004 seconds
[0m12:19:38.025958 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m12:19:38.026982 [debug] [ThreadPool]: On list_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev_main"} */
select
      'dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'dev'
  
[0m12:19:38.042828 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m12:19:38.042828 [debug] [ThreadPool]: On list_dev_main: ROLLBACK
[0m12:19:38.043848 [debug] [ThreadPool]: Failed to rollback 'list_dev_main'
[0m12:19:38.043848 [debug] [ThreadPool]: On list_dev_main: Close
[0m12:19:38.045356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a395964c-3bd1-4e37-806c-a256330836c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8A0C62480>]}
[0m12:19:38.046390 [debug] [MainThread]: Using duckdb connection "master"
[0m12:19:38.046390 [debug] [MainThread]: On master: BEGIN
[0m12:19:38.046390 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:19:38.050488 [debug] [MainThread]: SQL status: OK in 0.004 seconds
[0m12:19:38.050488 [debug] [MainThread]: On master: COMMIT
[0m12:19:38.051505 [debug] [MainThread]: Using duckdb connection "master"
[0m12:19:38.051505 [debug] [MainThread]: On master: COMMIT
[0m12:19:38.051505 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m12:19:38.051505 [debug] [MainThread]: On master: Close
[0m12:19:38.053546 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m12:19:38.054551 [info ] [Thread-1 (]: 1 of 5 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m12:19:38.055056 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m12:19:38.055056 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m12:19:38.058121 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m12:19:38.059134 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m12:19:38.076995 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m12:19:38.076995 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:19:38.078021 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m12:19:38.078021 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:19:38.082108 [debug] [Thread-1 (]: SQL status: OK in 0.005 seconds
[0m12:19:38.083129 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:19:38.083129 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "dev"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m12:19:38.097379 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "dev"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m12:19:38.097379 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:19:38.098400 [debug] [Thread-1 (]: On model.archi.cleancommit: ROLLBACK
[0m12:19:38.101455 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommit'
[0m12:19:38.101455 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m12:19:38.104976 [debug] [Thread-1 (]: Runtime Error in model cleancommit (models\cleansed\cleancommit.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 12:     from raw_commits
                    ^
[0m12:19:38.105980 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a395964c-3bd1-4e37-806c-a256330836c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8A0CF7FE0>]}
[0m12:19:38.106484 [error] [Thread-1 (]: 1 of 5 ERROR creating sql view model main_cleansed.cleancommit ................. [[31mERROR[0m in 0.05s]
[0m12:19:38.107014 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m12:19:38.107014 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m12:19:38.107014 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommit' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommit (models\cleansed\cleancommit.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 12:     from raw_commits
                    ^.
[0m12:19:38.108034 [info ] [Thread-1 (]: 2 of 5 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m12:19:38.108034 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m12:19:38.108034 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m12:19:38.110096 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m12:19:38.110096 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m12:19:38.112144 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m12:19:38.112144 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:19:38.113165 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m12:19:38.113165 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:19:38.117215 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m12:19:38.117215 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:19:38.118239 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "dev"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m12:19:38.131491 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "dev"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m12:19:38.131491 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:19:38.131491 [debug] [Thread-1 (]: On model.archi.cleancontributor: ROLLBACK
[0m12:19:38.133568 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancontributor'
[0m12:19:38.133568 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m12:19:38.137097 [debug] [Thread-1 (]: Runtime Error in model cleancontributor (models\cleansed\cleancontributor.sql)
  Catalog Error: Table with name raw_contributors does not exist!
  Did you mean "pg_constraint"?
  LINE 10:     from raw_contributors
                    ^
[0m12:19:38.137635 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a395964c-3bd1-4e37-806c-a256330836c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8A297A990>]}
[0m12:19:38.137635 [error] [Thread-1 (]: 2 of 5 ERROR creating sql view model main_cleansed.cleancontributor ............ [[31mERROR[0m in 0.03s]
[0m12:19:38.138723 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m12:19:38.138723 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m12:19:38.138723 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancontributor' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancontributor (models\cleansed\cleancontributor.sql)
  Catalog Error: Table with name raw_contributors does not exist!
  Did you mean "pg_constraint"?
  LINE 10:     from raw_contributors
                    ^.
[0m12:19:38.139726 [info ] [Thread-1 (]: 3 of 5 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m12:19:38.139726 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m12:19:38.139726 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m12:19:38.141780 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m12:19:38.141780 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m12:19:38.143834 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m12:19:38.143834 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:19:38.143834 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m12:19:38.144839 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:19:38.148401 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m12:19:38.149440 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:19:38.149440 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "dev"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m12:19:38.162700 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "dev"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m12:19:38.163720 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:19:38.163720 [debug] [Thread-1 (]: On model.archi.cleanissue: ROLLBACK
[0m12:19:38.165227 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanissue'
[0m12:19:38.165227 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m12:19:38.168786 [debug] [Thread-1 (]: Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Catalog Error: Table with name raw_issues does not exist!
  Did you mean "pragma_database_list"?
  LINE 12:     from raw_issues
                    ^
[0m12:19:38.168786 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a395964c-3bd1-4e37-806c-a256330836c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8A298E9C0>]}
[0m12:19:38.169801 [error] [Thread-1 (]: 3 of 5 ERROR creating sql view model main_cleansed.cleanissue .................. [[31mERROR[0m in 0.03s]
[0m12:19:38.169801 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m12:19:38.169801 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m12:19:38.170821 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanissue' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Catalog Error: Table with name raw_issues does not exist!
  Did you mean "pragma_database_list"?
  LINE 12:     from raw_issues
                    ^.
[0m12:19:38.170821 [info ] [Thread-1 (]: 4 of 5 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m12:19:38.171839 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m12:19:38.171839 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m12:19:38.172860 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m12:19:38.173879 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m12:19:38.175388 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m12:19:38.176406 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:19:38.176406 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m12:19:38.176406 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:19:38.181018 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m12:19:38.181018 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:19:38.182038 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "dev"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m12:19:38.195870 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "dev"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m12:19:38.195870 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:19:38.195870 [debug] [Thread-1 (]: On model.archi.cleanpr: ROLLBACK
[0m12:19:38.196895 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanpr'
[0m12:19:38.198404 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m12:19:38.201489 [debug] [Thread-1 (]: Runtime Error in model cleanpr (models\cleansed\cleanpr.sql)
  Catalog Error: Table with name raw_pull_requests does not exist!
  Did you mean "pg_tables"?
  LINE 12:     from raw_pull_requests
                    ^
[0m12:19:38.201489 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a395964c-3bd1-4e37-806c-a256330836c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8A298C7A0>]}
[0m12:19:38.202510 [error] [Thread-1 (]: 4 of 5 ERROR creating sql view model main_cleansed.cleanpr ..................... [[31mERROR[0m in 0.03s]
[0m12:19:38.202510 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m12:19:38.202510 [debug] [Thread-1 (]: Began running node model.archi.view
[0m12:19:38.202510 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanpr' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanpr (models\cleansed\cleanpr.sql)
  Catalog Error: Table with name raw_pull_requests does not exist!
  Did you mean "pg_tables"?
  LINE 12:     from raw_pull_requests
                    ^.
[0m12:19:38.203742 [info ] [Thread-1 (]: 5 of 5 START sql view model main.view .......................................... [RUN]
[0m12:19:38.203742 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m12:19:38.203742 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m12:19:38.205253 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m12:19:38.206279 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m12:19:38.207357 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m12:19:38.207357 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:19:38.208863 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m12:19:38.208863 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:19:38.212956 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m12:19:38.212956 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:19:38.212956 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "dev"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m12:19:38.227440 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "dev"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m12:19:38.227440 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:19:38.227440 [debug] [Thread-1 (]: On model.archi.view: ROLLBACK
[0m12:19:38.229482 [debug] [Thread-1 (]: Failed to rollback 'model.archi.view'
[0m12:19:38.229482 [debug] [Thread-1 (]: On model.archi.view: Close
[0m12:19:38.233597 [debug] [Thread-1 (]: Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 5:     SELECT * FROM raw_commits
                            ^
[0m12:19:38.233597 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a395964c-3bd1-4e37-806c-a256330836c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8A28FE4B0>]}
[0m12:19:38.233597 [error] [Thread-1 (]: 5 of 5 ERROR creating sql view model main.view ................................. [[31mERROR[0m in 0.03s]
[0m12:19:38.234603 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m12:19:38.235108 [debug] [Thread-4 (]: Marking all children of 'model.archi.view' to be skipped because of status 'error'.  Reason: Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 5:     SELECT * FROM raw_commits
                            ^.
[0m12:19:38.236135 [debug] [MainThread]: Using duckdb connection "master"
[0m12:19:38.236135 [debug] [MainThread]: On master: BEGIN
[0m12:19:38.236135 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:19:38.240318 [debug] [MainThread]: SQL status: OK in 0.004 seconds
[0m12:19:38.240318 [debug] [MainThread]: On master: COMMIT
[0m12:19:38.241344 [debug] [MainThread]: Using duckdb connection "master"
[0m12:19:38.241344 [debug] [MainThread]: On master: COMMIT
[0m12:19:38.241344 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m12:19:38.241344 [debug] [MainThread]: On master: Close
[0m12:19:38.243407 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:19:38.243407 [debug] [MainThread]: Connection 'create_dev_main' was properly closed.
[0m12:19:38.243407 [debug] [MainThread]: Connection 'list_dev_main' was properly closed.
[0m12:19:38.243407 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m12:19:38.243407 [info ] [MainThread]: 
[0m12:19:38.243407 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.34 seconds (0.34s).
[0m12:19:38.244919 [debug] [MainThread]: Command end result
[0m12:19:38.254623 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m12:19:38.255627 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m12:19:38.258715 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m12:19:38.258715 [info ] [MainThread]: 
[0m12:19:38.260226 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m12:19:38.260226 [info ] [MainThread]: 
[0m12:19:38.260226 [error] [MainThread]:   Runtime Error in model cleancommit (models\cleansed\cleancommit.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 12:     from raw_commits
                    ^
[0m12:19:38.261278 [info ] [MainThread]: 
[0m12:19:38.261278 [error] [MainThread]:   Runtime Error in model cleancontributor (models\cleansed\cleancontributor.sql)
  Catalog Error: Table with name raw_contributors does not exist!
  Did you mean "pg_constraint"?
  LINE 10:     from raw_contributors
                    ^
[0m12:19:38.261278 [info ] [MainThread]: 
[0m12:19:38.262303 [error] [MainThread]:   Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Catalog Error: Table with name raw_issues does not exist!
  Did you mean "pragma_database_list"?
  LINE 12:     from raw_issues
                    ^
[0m12:19:38.262303 [info ] [MainThread]: 
[0m12:19:38.262303 [error] [MainThread]:   Runtime Error in model cleanpr (models\cleansed\cleanpr.sql)
  Catalog Error: Table with name raw_pull_requests does not exist!
  Did you mean "pg_tables"?
  LINE 12:     from raw_pull_requests
                    ^
[0m12:19:38.263331 [info ] [MainThread]: 
[0m12:19:38.263331 [error] [MainThread]:   Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 5:     SELECT * FROM raw_commits
                            ^
[0m12:19:38.263331 [info ] [MainThread]: 
[0m12:19:38.263331 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=0 TOTAL=5
[0m12:19:38.264843 [debug] [MainThread]: Command `dbt build` failed at 12:19:38.264843 after 0.92 seconds
[0m12:19:38.264843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B89E12A570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B89E0DB440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8A0525F40>]}
[0m12:19:38.264843 [debug] [MainThread]: Flushing usage events
[0m12:19:38.672704 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:24:39.066249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E26628170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E287C2F90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E287C2900>]}


============================== 12:24:39.069849 | ee45088c-1632-4fec-b3d7-4995fa23d2f3 ==============================
[0m12:24:39.069849 [info ] [MainThread]: Running with dbt=1.9.1
[0m12:24:39.070357 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\julie\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt build', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:24:39.183425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ee45088c-1632-4fec-b3d7-4995fa23d2f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E29401A00>]}
[0m12:24:39.213494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ee45088c-1632-4fec-b3d7-4995fa23d2f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E293C3CE0>]}
[0m12:24:39.215522 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m12:24:39.333415 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m12:24:39.367130 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m12:24:39.368150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ee45088c-1632-4fec-b3d7-4995fa23d2f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E29551CA0>]}
[0m12:24:39.901209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ee45088c-1632-4fec-b3d7-4995fa23d2f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E2A719CD0>]}
[0m12:24:39.927857 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m12:24:39.928890 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m12:24:39.980824 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ee45088c-1632-4fec-b3d7-4995fa23d2f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E2A97F290>]}
[0m12:24:39.981851 [info ] [MainThread]: Found 5 models, 424 macros
[0m12:24:39.982878 [info ] [MainThread]: 
[0m12:24:39.983422 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:24:39.983938 [info ] [MainThread]: 
[0m12:24:39.983938 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m12:24:39.985993 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev'
[0m12:24:40.030006 [debug] [ThreadPool]: Using duckdb connection "list_dev"
[0m12:24:40.030006 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dev"'
    
  
  
[0m12:24:40.030006 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:24:40.042278 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m12:24:40.042278 [debug] [ThreadPool]: On list_dev: Close
[0m12:24:40.044861 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now create_dev_main)
[0m12:24:40.044861 [debug] [ThreadPool]: Creating schema "database: "dev"
schema: "main"
"
[0m12:24:40.048957 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:24:40.048957 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dev'
        and type='sqlite'
    
  
[0m12:24:40.048957 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:24:40.057557 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m12:24:40.058598 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:24:40.058598 [debug] [ThreadPool]: On create_dev_main: BEGIN
[0m12:24:40.058598 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:24:40.058598 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:24:40.060110 [debug] [ThreadPool]: On create_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_dev_main"} */

    
    
        create schema if not exists "dev"."main"
    
[0m12:24:40.060110 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:24:40.061194 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m12:24:40.061194 [debug] [ThreadPool]: Using duckdb connection "create_dev_main"
[0m12:24:40.061194 [debug] [ThreadPool]: On create_dev_main: COMMIT
[0m12:24:40.061194 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:24:40.062219 [debug] [ThreadPool]: On create_dev_main: Close
[0m12:24:40.064248 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dev_main'
[0m12:24:40.066840 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m12:24:40.066840 [debug] [ThreadPool]: On list_dev_main: BEGIN
[0m12:24:40.066840 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:24:40.071032 [debug] [ThreadPool]: SQL status: OK in 0.004 seconds
[0m12:24:40.072062 [debug] [ThreadPool]: Using duckdb connection "list_dev_main"
[0m12:24:40.072062 [debug] [ThreadPool]: On list_dev_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_dev_main"} */
select
      'dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'dev'
  
[0m12:24:40.087982 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m12:24:40.089016 [debug] [ThreadPool]: On list_dev_main: ROLLBACK
[0m12:24:40.090020 [debug] [ThreadPool]: Failed to rollback 'list_dev_main'
[0m12:24:40.090020 [debug] [ThreadPool]: On list_dev_main: Close
[0m12:24:40.091544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee45088c-1632-4fec-b3d7-4995fa23d2f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E2A9E5FA0>]}
[0m12:24:40.091544 [debug] [MainThread]: Using duckdb connection "master"
[0m12:24:40.092572 [debug] [MainThread]: On master: BEGIN
[0m12:24:40.092572 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:24:40.096652 [debug] [MainThread]: SQL status: OK in 0.004 seconds
[0m12:24:40.096652 [debug] [MainThread]: On master: COMMIT
[0m12:24:40.096652 [debug] [MainThread]: Using duckdb connection "master"
[0m12:24:40.096652 [debug] [MainThread]: On master: COMMIT
[0m12:24:40.097659 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m12:24:40.097659 [debug] [MainThread]: On master: Close
[0m12:24:40.098706 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m12:24:40.100272 [info ] [Thread-1 (]: 1 of 5 START sql view model main.cleancommit ................................... [RUN]
[0m12:24:40.100272 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m12:24:40.100272 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m12:24:40.104388 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m12:24:40.104388 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m12:24:40.121644 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m12:24:40.122665 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:24:40.122665 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m12:24:40.122665 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:24:40.127267 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m12:24:40.127267 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:24:40.127267 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "dev"."main"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m12:24:40.141128 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "dev"."main"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m12:24:40.142157 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:24:40.142157 [debug] [Thread-1 (]: On model.archi.cleancommit: ROLLBACK
[0m12:24:40.145237 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancommit'
[0m12:24:40.145237 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m12:24:40.148480 [debug] [Thread-1 (]: Runtime Error in model cleancommit (models\cleansed\cleancommit.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 12:     from raw_commits
                    ^
[0m12:24:40.149990 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee45088c-1632-4fec-b3d7-4995fa23d2f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E2A593B90>]}
[0m12:24:40.151018 [error] [Thread-1 (]: 1 of 5 ERROR creating sql view model main.cleancommit .......................... [[31mERROR[0m in 0.05s]
[0m12:24:40.151018 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m12:24:40.152041 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m12:24:40.152041 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancommit' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancommit (models\cleansed\cleancommit.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 12:     from raw_commits
                    ^.
[0m12:24:40.152041 [info ] [Thread-1 (]: 2 of 5 START sql view model main.cleancontributor .............................. [RUN]
[0m12:24:40.153071 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m12:24:40.153071 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m12:24:40.155123 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m12:24:40.155123 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m12:24:40.156637 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m12:24:40.158146 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:24:40.158146 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m12:24:40.158146 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:24:40.162754 [debug] [Thread-1 (]: SQL status: OK in 0.005 seconds
[0m12:24:40.162754 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:24:40.162754 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "dev"."main"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m12:24:40.177942 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "dev"."main"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m12:24:40.177942 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:24:40.177942 [debug] [Thread-1 (]: On model.archi.cleancontributor: ROLLBACK
[0m12:24:40.179970 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleancontributor'
[0m12:24:40.180473 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m12:24:40.183537 [debug] [Thread-1 (]: Runtime Error in model cleancontributor (models\cleansed\cleancontributor.sql)
  Catalog Error: Table with name raw_contributors does not exist!
  Did you mean "pg_constraint"?
  LINE 10:     from raw_contributors
                    ^
[0m12:24:40.183537 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee45088c-1632-4fec-b3d7-4995fa23d2f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E2B1A3D40>]}
[0m12:24:40.184566 [error] [Thread-1 (]: 2 of 5 ERROR creating sql view model main.cleancontributor ..................... [[31mERROR[0m in 0.03s]
[0m12:24:40.184566 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m12:24:40.184566 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m12:24:40.185591 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleancontributor' to be skipped because of status 'error'.  Reason: Runtime Error in model cleancontributor (models\cleansed\cleancontributor.sql)
  Catalog Error: Table with name raw_contributors does not exist!
  Did you mean "pg_constraint"?
  LINE 10:     from raw_contributors
                    ^.
[0m12:24:40.185591 [info ] [Thread-1 (]: 3 of 5 START sql view model main.cleanissue .................................... [RUN]
[0m12:24:40.185591 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m12:24:40.185591 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m12:24:40.188105 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m12:24:40.188609 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m12:24:40.190125 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m12:24:40.190635 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:24:40.190635 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m12:24:40.190635 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:24:40.195764 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m12:24:40.195764 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:24:40.195764 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "dev"."main"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m12:24:40.210971 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "dev"."main"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m12:24:40.210971 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:24:40.210971 [debug] [Thread-1 (]: On model.archi.cleanissue: ROLLBACK
[0m12:24:40.213504 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanissue'
[0m12:24:40.213504 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m12:24:40.216576 [debug] [Thread-1 (]: Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Catalog Error: Table with name raw_issues does not exist!
  Did you mean "pragma_database_list"?
  LINE 12:     from raw_issues
                    ^
[0m12:24:40.216576 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee45088c-1632-4fec-b3d7-4995fa23d2f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E2B1C39B0>]}
[0m12:24:40.217581 [error] [Thread-1 (]: 3 of 5 ERROR creating sql view model main.cleanissue ........................... [[31mERROR[0m in 0.03s]
[0m12:24:40.218087 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m12:24:40.218617 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m12:24:40.218617 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanissue' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Catalog Error: Table with name raw_issues does not exist!
  Did you mean "pragma_database_list"?
  LINE 12:     from raw_issues
                    ^.
[0m12:24:40.219151 [info ] [Thread-1 (]: 4 of 5 START sql view model main.cleanpr ....................................... [RUN]
[0m12:24:40.219151 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m12:24:40.219151 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m12:24:40.220661 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m12:24:40.221683 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m12:24:40.224820 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m12:24:40.224820 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:24:40.225845 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m12:24:40.225845 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:24:40.230411 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m12:24:40.230411 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:24:40.230411 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "dev"."main"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m12:24:40.245650 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "dev"."main"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m12:24:40.245650 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:24:40.245650 [debug] [Thread-1 (]: On model.archi.cleanpr: ROLLBACK
[0m12:24:40.246667 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanpr'
[0m12:24:40.248182 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m12:24:40.251270 [debug] [Thread-1 (]: Runtime Error in model cleanpr (models\cleansed\cleanpr.sql)
  Catalog Error: Table with name raw_pull_requests does not exist!
  Did you mean "pg_tables"?
  LINE 12:     from raw_pull_requests
                    ^
[0m12:24:40.251270 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee45088c-1632-4fec-b3d7-4995fa23d2f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E2B1A23C0>]}
[0m12:24:40.252293 [error] [Thread-1 (]: 4 of 5 ERROR creating sql view model main.cleanpr .............................. [[31mERROR[0m in 0.03s]
[0m12:24:40.252293 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m12:24:40.252293 [debug] [Thread-1 (]: Began running node model.archi.view
[0m12:24:40.253322 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanpr' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanpr (models\cleansed\cleanpr.sql)
  Catalog Error: Table with name raw_pull_requests does not exist!
  Did you mean "pg_tables"?
  LINE 12:     from raw_pull_requests
                    ^.
[0m12:24:40.253322 [info ] [Thread-1 (]: 5 of 5 START sql view model main.view .......................................... [RUN]
[0m12:24:40.253322 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m12:24:40.254371 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m12:24:40.255419 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m12:24:40.256443 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m12:24:40.257467 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m12:24:40.258472 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:24:40.258977 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m12:24:40.259515 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:24:40.264117 [debug] [Thread-1 (]: SQL status: OK in 0.005 seconds
[0m12:24:40.264117 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:24:40.264117 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "dev"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m12:24:40.278935 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "dev"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m12:24:40.278935 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m12:24:40.278935 [debug] [Thread-1 (]: On model.archi.view: ROLLBACK
[0m12:24:40.280444 [debug] [Thread-1 (]: Failed to rollback 'model.archi.view'
[0m12:24:40.281475 [debug] [Thread-1 (]: On model.archi.view: Close
[0m12:24:40.284552 [debug] [Thread-1 (]: Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 5:     SELECT * FROM raw_commits
                            ^
[0m12:24:40.284552 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee45088c-1632-4fec-b3d7-4995fa23d2f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E2B1A3D40>]}
[0m12:24:40.284552 [error] [Thread-1 (]: 5 of 5 ERROR creating sql view model main.view ................................. [[31mERROR[0m in 0.03s]
[0m12:24:40.285642 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m12:24:40.285642 [debug] [Thread-4 (]: Marking all children of 'model.archi.view' to be skipped because of status 'error'.  Reason: Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 5:     SELECT * FROM raw_commits
                            ^.
[0m12:24:40.286645 [debug] [MainThread]: Using duckdb connection "master"
[0m12:24:40.286645 [debug] [MainThread]: On master: BEGIN
[0m12:24:40.287678 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:24:40.291724 [debug] [MainThread]: SQL status: OK in 0.004 seconds
[0m12:24:40.291724 [debug] [MainThread]: On master: COMMIT
[0m12:24:40.291724 [debug] [MainThread]: Using duckdb connection "master"
[0m12:24:40.292751 [debug] [MainThread]: On master: COMMIT
[0m12:24:40.292751 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m12:24:40.292751 [debug] [MainThread]: On master: Close
[0m12:24:40.293774 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:24:40.294827 [debug] [MainThread]: Connection 'create_dev_main' was properly closed.
[0m12:24:40.294827 [debug] [MainThread]: Connection 'list_dev_main' was properly closed.
[0m12:24:40.294827 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m12:24:40.294827 [info ] [MainThread]: 
[0m12:24:40.295856 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.31 seconds (0.31s).
[0m12:24:40.295856 [debug] [MainThread]: Command end result
[0m12:24:40.306120 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m12:24:40.308168 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m12:24:40.311191 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m12:24:40.311191 [info ] [MainThread]: 
[0m12:24:40.312033 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m12:24:40.312539 [info ] [MainThread]: 
[0m12:24:40.312539 [error] [MainThread]:   Runtime Error in model cleancommit (models\cleansed\cleancommit.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 12:     from raw_commits
                    ^
[0m12:24:40.312539 [info ] [MainThread]: 
[0m12:24:40.312539 [error] [MainThread]:   Runtime Error in model cleancontributor (models\cleansed\cleancontributor.sql)
  Catalog Error: Table with name raw_contributors does not exist!
  Did you mean "pg_constraint"?
  LINE 10:     from raw_contributors
                    ^
[0m12:24:40.313582 [info ] [MainThread]: 
[0m12:24:40.313582 [error] [MainThread]:   Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Catalog Error: Table with name raw_issues does not exist!
  Did you mean "pragma_database_list"?
  LINE 12:     from raw_issues
                    ^
[0m12:24:40.313582 [info ] [MainThread]: 
[0m12:24:40.314609 [error] [MainThread]:   Runtime Error in model cleanpr (models\cleansed\cleanpr.sql)
  Catalog Error: Table with name raw_pull_requests does not exist!
  Did you mean "pg_tables"?
  LINE 12:     from raw_pull_requests
                    ^
[0m12:24:40.314609 [info ] [MainThread]: 
[0m12:24:40.314609 [error] [MainThread]:   Runtime Error in model view (models\duckdb\view.sql)
  Catalog Error: Table with name raw_commits does not exist!
  Did you mean "pg_constraint"?
  LINE 5:     SELECT * FROM raw_commits
                            ^
[0m12:24:40.314609 [info ] [MainThread]: 
[0m12:24:40.315634 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=5 SKIP=0 TOTAL=5
[0m12:24:40.315634 [debug] [MainThread]: Command `dbt build` failed at 12:24:40.315634 after 1.34 seconds
[0m12:24:40.316655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E29070AA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E291025A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028E26FD58E0>]}
[0m12:24:40.316713 [debug] [MainThread]: Flushing usage events
[0m12:24:40.778383 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:25:02.345443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002755E849AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002755B2F54F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002755E53A0C0>]}


============================== 12:25:02.348059 | febf4c9e-9a4f-4156-9d75-161241215fcf ==============================
[0m12:25:02.348059 [info ] [MainThread]: Running with dbt=1.9.1
[0m12:25:02.348059 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\julie\\.dbt', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt init', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:25:02.360252 [info ] [MainThread]: Setting up your profile.
[0m12:25:09.728519 [debug] [MainThread]: Command `dbt init` succeeded at 12:25:09.728519 after 7.47 seconds
[0m12:25:09.728519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002755E4FE9F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002755E4FD8E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002755E4FCB00>]}
[0m12:25:09.729547 [debug] [MainThread]: Flushing usage events
[0m12:25:10.118888 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:26:17.657745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C92604CE90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C92531BC80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C922B163C0>]}


============================== 12:26:17.661342 | 19e5afb0-1bf2-4f63-a074-2f17f06f99fe ==============================
[0m12:26:17.661342 [info ] [MainThread]: Running with dbt=1.9.1
[0m12:26:17.661854 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:26:17.771691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '19e5afb0-1bf2-4f63-a074-2f17f06f99fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C92616BA40>]}
[0m12:26:17.801931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '19e5afb0-1bf2-4f63-a074-2f17f06f99fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C925CD1F70>]}
[0m12:26:17.803464 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m12:26:17.915250 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m12:26:17.949288 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m12:26:17.949288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '19e5afb0-1bf2-4f63-a074-2f17f06f99fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C927621700>]}
[0m12:26:18.449459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '19e5afb0-1bf2-4f63-a074-2f17f06f99fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C9277AE060>]}
[0m12:26:18.475509 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m12:26:18.476537 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m12:26:18.534204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '19e5afb0-1bf2-4f63-a074-2f17f06f99fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C927806DE0>]}
[0m12:26:18.534204 [info ] [MainThread]: Found 5 models, 424 macros
[0m12:26:18.535780 [info ] [MainThread]: 
[0m12:26:18.535780 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:26:18.536343 [info ] [MainThread]: 
[0m12:26:18.536343 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m12:26:18.538931 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m12:26:18.581920 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m12:26:18.583027 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m12:26:18.583027 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:18.593190 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m12:26:18.594279 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m12:26:18.595307 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m12:26:18.596333 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m12:26:18.599456 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m12:26:18.600508 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m12:26:18.600508 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:26:18.608663 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m12:26:18.609701 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m12:26:18.609701 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m12:26:18.609701 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:26:18.610705 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m12:26:18.610705 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m12:26:18.610705 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:26:18.611757 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m12:26:18.611757 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m12:26:18.611757 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m12:26:18.611757 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:26:18.612780 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m12:26:18.614896 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m12:26:18.617984 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m12:26:18.617984 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m12:26:18.617984 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:18.626169 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m12:26:18.626169 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m12:26:18.627198 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m12:26:18.643663 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m12:26:18.644672 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m12:26:18.645758 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m12:26:18.645758 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m12:26:18.648850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '19e5afb0-1bf2-4f63-a074-2f17f06f99fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C927B75730>]}
[0m12:26:18.648850 [debug] [MainThread]: Using duckdb connection "master"
[0m12:26:18.649888 [debug] [MainThread]: On master: BEGIN
[0m12:26:18.649888 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:26:18.657081 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m12:26:18.658107 [debug] [MainThread]: On master: COMMIT
[0m12:26:18.658107 [debug] [MainThread]: Using duckdb connection "master"
[0m12:26:18.658107 [debug] [MainThread]: On master: COMMIT
[0m12:26:18.658107 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m12:26:18.659133 [debug] [MainThread]: On master: Close
[0m12:26:18.660210 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m12:26:18.661715 [info ] [Thread-1 (]: 1 of 5 START sql view model main.cleancommit ................................... [RUN]
[0m12:26:18.661715 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m12:26:18.662245 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m12:26:18.665306 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m12:26:18.666324 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m12:26:18.682775 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m12:26:18.682775 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:26:18.683823 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m12:26:18.683823 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:26:18.691718 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m12:26:18.692725 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:26:18.693232 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m12:26:18.693769 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:18.696863 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:26:18.696863 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m12:26:18.697890 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:18.703546 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m12:26:18.703546 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:26:18.704590 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m12:26:18.705632 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:18.707730 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:26:18.708761 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main"."cleancommit__dbt_backup" cascade
[0m12:26:18.708761 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:18.709788 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m12:26:18.730365 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19e5afb0-1bf2-4f63-a074-2f17f06f99fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C92739D4F0>]}
[0m12:26:18.731875 [info ] [Thread-1 (]: 1 of 5 OK created sql view model main.cleancommit .............................. [[32mOK[0m in 0.07s]
[0m12:26:18.731875 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m12:26:18.731875 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m12:26:18.733009 [info ] [Thread-1 (]: 2 of 5 START sql view model main.cleancontributor .............................. [RUN]
[0m12:26:18.733009 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m12:26:18.733009 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m12:26:18.735103 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m12:26:18.735103 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m12:26:18.736610 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m12:26:18.737613 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:26:18.738116 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m12:26:18.738116 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:18.750545 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m12:26:18.750545 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:26:18.750545 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m12:26:18.752059 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:18.754189 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:26:18.755198 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m12:26:18.755708 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:18.755708 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m12:26:18.756715 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:26:18.756715 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m12:26:18.757748 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:18.758782 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:26:18.759813 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main"."cleancontributor__dbt_backup" cascade
[0m12:26:18.759813 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:18.760846 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m12:26:18.779797 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19e5afb0-1bf2-4f63-a074-2f17f06f99fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C927F4FEC0>]}
[0m12:26:18.779797 [info ] [Thread-1 (]: 2 of 5 OK created sql view model main.cleancontributor ......................... [[32mOK[0m in 0.05s]
[0m12:26:18.780825 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m12:26:18.780825 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m12:26:18.781831 [info ] [Thread-1 (]: 3 of 5 START sql view model main.cleanissue .................................... [RUN]
[0m12:26:18.782334 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m12:26:18.782334 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m12:26:18.783930 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m12:26:18.783930 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m12:26:18.785957 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m12:26:18.785957 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:26:18.786990 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m12:26:18.786990 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:18.798819 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m12:26:18.799931 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:26:18.799931 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m12:26:18.800939 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:18.802453 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:26:18.802453 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m12:26:18.803501 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:18.803501 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m12:26:18.804510 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:26:18.804510 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m12:26:18.806044 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:18.807108 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:26:18.807108 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main"."cleanissue__dbt_backup" cascade
[0m12:26:18.808135 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:18.808135 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m12:26:18.828626 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19e5afb0-1bf2-4f63-a074-2f17f06f99fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C927F4FBF0>]}
[0m12:26:18.828626 [info ] [Thread-1 (]: 3 of 5 OK created sql view model main.cleanissue ............................... [[32mOK[0m in 0.05s]
[0m12:26:18.829647 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m12:26:18.829647 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m12:26:18.829647 [info ] [Thread-1 (]: 4 of 5 START sql view model main.cleanpr ....................................... [RUN]
[0m12:26:18.830667 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m12:26:18.830667 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m12:26:18.832174 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m12:26:18.833197 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m12:26:18.834223 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m12:26:18.835226 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:26:18.835729 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m12:26:18.835729 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:18.848123 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m12:26:18.848123 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:26:18.849154 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m12:26:18.849154 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:18.851700 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:26:18.851700 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m12:26:18.851700 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:18.852740 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m12:26:18.852740 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:26:18.852740 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m12:26:18.854809 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:18.855817 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:26:18.856323 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main"."cleanpr__dbt_backup" cascade
[0m12:26:18.856323 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:18.857355 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m12:26:18.876704 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19e5afb0-1bf2-4f63-a074-2f17f06f99fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C927DF0620>]}
[0m12:26:18.876704 [info ] [Thread-1 (]: 4 of 5 OK created sql view model main.cleanpr .................................. [[32mOK[0m in 0.05s]
[0m12:26:18.877785 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m12:26:18.878310 [debug] [Thread-1 (]: Began running node model.archi.view
[0m12:26:18.878310 [info ] [Thread-1 (]: 5 of 5 START sql view model main.view .......................................... [RUN]
[0m12:26:18.878845 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m12:26:18.878845 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m12:26:18.879874 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m12:26:18.880894 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m12:26:18.882402 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m12:26:18.883425 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:26:18.883425 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m12:26:18.883425 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:18.896994 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m12:26:18.897501 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:26:18.897501 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m12:26:18.897501 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:18.900620 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:26:18.900620 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m12:26:18.901628 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:18.903166 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:26:18.903166 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m12:26:18.903166 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:18.905226 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m12:26:18.905226 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:26:18.906261 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m12:26:18.907772 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:18.908820 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:26:18.909360 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m12:26:18.909915 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:18.910946 [debug] [Thread-1 (]: On model.archi.view: Close
[0m12:26:18.930411 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19e5afb0-1bf2-4f63-a074-2f17f06f99fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C927F631A0>]}
[0m12:26:18.930411 [info ] [Thread-1 (]: 5 of 5 OK created sql view model main.view ..................................... [[32mOK[0m in 0.05s]
[0m12:26:18.930411 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m12:26:18.931921 [debug] [MainThread]: Using duckdb connection "master"
[0m12:26:18.931921 [debug] [MainThread]: On master: BEGIN
[0m12:26:18.931921 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:26:18.944709 [debug] [MainThread]: SQL status: OK in 0.013 seconds
[0m12:26:18.945729 [debug] [MainThread]: On master: COMMIT
[0m12:26:18.945729 [debug] [MainThread]: Using duckdb connection "master"
[0m12:26:18.945729 [debug] [MainThread]: On master: COMMIT
[0m12:26:18.946743 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m12:26:18.946743 [debug] [MainThread]: On master: Close
[0m12:26:18.949284 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:26:18.949284 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m12:26:18.949284 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m12:26:18.949284 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m12:26:18.950290 [info ] [MainThread]: 
[0m12:26:18.950290 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.41 seconds (0.41s).
[0m12:26:18.950795 [debug] [MainThread]: Command end result
[0m12:26:18.960556 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m12:26:18.963101 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m12:26:18.965634 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m12:26:18.966653 [info ] [MainThread]: 
[0m12:26:18.966653 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:26:18.966653 [info ] [MainThread]: 
[0m12:26:18.967702 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m12:26:18.967702 [debug] [MainThread]: Command `dbt build` succeeded at 12:26:18.967702 after 1.40 seconds
[0m12:26:18.967702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C925C32420>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C925A5AFF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002C9255B1790>]}
[0m12:26:18.968752 [debug] [MainThread]: Flushing usage events
[0m12:26:19.449802 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:26:38.784768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389B3786B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389B3DE540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389B3DE630>]}


============================== 12:26:38.787302 | 1722d206-a72c-4c5f-95bc-2d240e56fa8b ==============================
[0m12:26:38.787302 [info ] [MainThread]: Running with dbt=1.9.1
[0m12:26:38.787302 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:26:38.898261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1722d206-a72c-4c5f-95bc-2d240e56fa8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389B861130>]}
[0m12:26:38.928240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1722d206-a72c-4c5f-95bc-2d240e56fa8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389B9B2DB0>]}
[0m12:26:38.931337 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m12:26:39.047607 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m12:26:39.082803 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m12:26:39.082803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1722d206-a72c-4c5f-95bc-2d240e56fa8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389CCF1BE0>]}
[0m12:26:39.585632 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.application
[0m12:26:39.587738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1722d206-a72c-4c5f-95bc-2d240e56fa8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389CD267B0>]}
[0m12:26:39.614102 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m12:26:39.615132 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m12:26:39.673793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1722d206-a72c-4c5f-95bc-2d240e56fa8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389CECB440>]}
[0m12:26:39.673793 [info ] [MainThread]: Found 5 models, 424 macros
[0m12:26:39.675301 [info ] [MainThread]: 
[0m12:26:39.675301 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:26:39.676326 [info ] [MainThread]: 
[0m12:26:39.676326 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m12:26:39.678374 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m12:26:39.722359 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m12:26:39.723392 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m12:26:39.723392 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:39.733664 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m12:26:39.734697 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m12:26:39.737231 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m12:26:39.737231 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m12:26:39.738235 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:26:39.745859 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m12:26:39.746879 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m12:26:39.749417 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m12:26:39.749941 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m12:26:39.753008 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m12:26:39.753008 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m12:26:39.753008 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:26:39.760776 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m12:26:39.762284 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m12:26:39.762284 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m12:26:39.763316 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:26:39.763316 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m12:26:39.763316 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m12:26:39.763316 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:26:39.764347 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m12:26:39.764347 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m12:26:39.764347 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m12:26:39.765371 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:26:39.765371 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m12:26:39.767423 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_cleansed)
[0m12:26:39.767423 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m12:26:39.768450 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m12:26:39.768450 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m12:26:39.769481 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:26:39.777200 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m12:26:39.778711 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m12:26:39.778711 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m12:26:39.778711 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:26:39.778711 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m12:26:39.779737 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m12:26:39.779737 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:26:39.779737 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m12:26:39.780743 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m12:26:39.780743 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m12:26:39.780743 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:26:39.780743 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m12:26:39.783285 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m12:26:39.786384 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m12:26:39.786384 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m12:26:39.786384 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:39.795082 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m12:26:39.795082 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m12:26:39.796105 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m12:26:39.812102 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m12:26:39.812102 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m12:26:39.813613 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m12:26:39.813613 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m12:26:39.816690 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_cleansed)
[0m12:26:39.818098 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m12:26:39.818098 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m12:26:39.819124 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:26:39.826797 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m12:26:39.826797 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m12:26:39.827819 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m12:26:39.844118 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m12:26:39.844118 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m12:26:39.845166 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m12:26:39.845166 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m12:26:39.848237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1722d206-a72c-4c5f-95bc-2d240e56fa8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389CF3E0F0>]}
[0m12:26:39.848237 [debug] [MainThread]: Using duckdb connection "master"
[0m12:26:39.849260 [debug] [MainThread]: On master: BEGIN
[0m12:26:39.849260 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:26:39.857553 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m12:26:39.857553 [debug] [MainThread]: On master: COMMIT
[0m12:26:39.857553 [debug] [MainThread]: Using duckdb connection "master"
[0m12:26:39.857553 [debug] [MainThread]: On master: COMMIT
[0m12:26:39.858584 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m12:26:39.858584 [debug] [MainThread]: On master: Close
[0m12:26:39.861118 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m12:26:39.861118 [info ] [Thread-1 (]: 1 of 5 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m12:26:39.862122 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m12:26:39.862122 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m12:26:39.865754 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m12:26:39.866787 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m12:26:39.882632 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m12:26:39.883636 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:26:39.883636 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m12:26:39.883636 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:26:39.892299 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m12:26:39.892299 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:26:39.892299 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m12:26:39.893325 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:39.896458 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:26:39.896458 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m12:26:39.897547 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:39.898583 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:26:39.899619 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m12:26:39.899619 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:39.907283 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m12:26:39.907283 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:26:39.907283 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m12:26:39.909361 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:39.911400 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m12:26:39.911400 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m12:26:39.912960 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:39.914691 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m12:26:39.935201 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1722d206-a72c-4c5f-95bc-2d240e56fa8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023898B84170>]}
[0m12:26:39.935905 [info ] [Thread-1 (]: 1 of 5 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.07s]
[0m12:26:39.935905 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m12:26:39.936932 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m12:26:39.936932 [info ] [Thread-1 (]: 2 of 5 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m12:26:39.936932 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m12:26:39.936932 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m12:26:39.939176 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m12:26:39.939176 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m12:26:39.941219 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m12:26:39.941219 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:26:39.942224 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m12:26:39.942224 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:39.954612 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m12:26:39.954612 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:26:39.954612 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m12:26:39.955616 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:39.957736 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:26:39.957736 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m12:26:39.957736 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:39.959785 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:26:39.959837 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m12:26:39.959837 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:39.960843 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m12:26:39.960843 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:26:39.960843 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m12:26:39.962359 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:39.963396 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m12:26:39.964430 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m12:26:39.965463 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:39.965994 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m12:26:39.984994 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1722d206-a72c-4c5f-95bc-2d240e56fa8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389D5ECAA0>]}
[0m12:26:39.984994 [info ] [Thread-1 (]: 2 of 5 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m12:26:39.986020 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m12:26:39.986546 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m12:26:39.986546 [info ] [Thread-1 (]: 3 of 5 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m12:26:39.987075 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m12:26:39.987075 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m12:26:39.988098 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m12:26:39.989121 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m12:26:39.990700 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m12:26:39.991712 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:26:39.991712 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m12:26:39.992224 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:40.004415 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m12:26:40.005446 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:26:40.005446 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m12:26:40.005446 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:40.007548 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:26:40.007548 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m12:26:40.008568 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:40.009601 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:26:40.009601 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m12:26:40.009601 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:40.011110 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m12:26:40.011110 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:26:40.012115 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m12:26:40.012623 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:40.013664 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m12:26:40.014694 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m12:26:40.015719 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:40.015719 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m12:26:40.035722 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1722d206-a72c-4c5f-95bc-2d240e56fa8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389D5ED010>]}
[0m12:26:40.036802 [info ] [Thread-1 (]: 3 of 5 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m12:26:40.036802 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m12:26:40.037829 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m12:26:40.037829 [info ] [Thread-1 (]: 4 of 5 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m12:26:40.037829 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m12:26:40.037829 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m12:26:40.039893 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m12:26:40.039893 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m12:26:40.042430 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m12:26:40.043476 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:26:40.043476 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m12:26:40.044501 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:40.056458 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m12:26:40.057479 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:26:40.057479 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m12:26:40.058516 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:40.059547 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:26:40.060580 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m12:26:40.060580 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:40.062092 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:26:40.062092 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m12:26:40.062092 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:40.063121 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m12:26:40.064147 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:26:40.064147 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m12:26:40.065176 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:40.066201 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m12:26:40.066201 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m12:26:40.067228 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:40.068355 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m12:26:40.087370 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1722d206-a72c-4c5f-95bc-2d240e56fa8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389E612750>]}
[0m12:26:40.087370 [info ] [Thread-1 (]: 4 of 5 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m12:26:40.088410 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m12:26:40.088410 [debug] [Thread-1 (]: Began running node model.archi.view
[0m12:26:40.089438 [info ] [Thread-1 (]: 5 of 5 START sql view model main.view .......................................... [RUN]
[0m12:26:40.089438 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m12:26:40.089438 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m12:26:40.090473 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m12:26:40.090473 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m12:26:40.093023 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m12:26:40.094051 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:26:40.094051 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m12:26:40.094051 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:26:40.106413 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m12:26:40.107433 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:26:40.107433 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m12:26:40.107433 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:40.110034 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:26:40.110034 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m12:26:40.110034 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:40.112078 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:26:40.112078 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m12:26:40.112580 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:26:40.112580 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m12:26:40.113599 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:26:40.113599 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m12:26:40.114651 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:40.115689 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m12:26:40.116718 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m12:26:40.116718 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m12:26:40.117743 [debug] [Thread-1 (]: On model.archi.view: Close
[0m12:26:40.137600 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1722d206-a72c-4c5f-95bc-2d240e56fa8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389AC74BC0>]}
[0m12:26:40.137600 [info ] [Thread-1 (]: 5 of 5 OK created sql view model main.view ..................................... [[32mOK[0m in 0.05s]
[0m12:26:40.137600 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m12:26:40.139110 [debug] [MainThread]: Using duckdb connection "master"
[0m12:26:40.139110 [debug] [MainThread]: On master: BEGIN
[0m12:26:40.140137 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:26:40.152952 [debug] [MainThread]: SQL status: OK in 0.013 seconds
[0m12:26:40.152952 [debug] [MainThread]: On master: COMMIT
[0m12:26:40.152952 [debug] [MainThread]: Using duckdb connection "master"
[0m12:26:40.153973 [debug] [MainThread]: On master: COMMIT
[0m12:26:40.153973 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m12:26:40.153973 [debug] [MainThread]: On master: Close
[0m12:26:40.156034 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:26:40.156034 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m12:26:40.156034 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m12:26:40.157059 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m12:26:40.157059 [info ] [MainThread]: 
[0m12:26:40.157059 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.48 seconds (0.48s).
[0m12:26:40.158125 [debug] [MainThread]: Command end result
[0m12:26:40.168831 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m12:26:40.169834 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m12:26:40.172859 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m12:26:40.172859 [info ] [MainThread]: 
[0m12:26:40.172859 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:26:40.172859 [info ] [MainThread]: 
[0m12:26:40.174365 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m12:26:40.175442 [debug] [MainThread]: Command `dbt build` succeeded at 12:26:40.175442 after 1.47 seconds
[0m12:26:40.175442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389B7B0B30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389B7B0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002389B7B09B0>]}
[0m12:26:40.175442 [debug] [MainThread]: Flushing usage events
[0m12:26:40.624258 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:19:03.779263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F7375D8E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F735D1D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F735D20F0>]}


============================== 13:19:03.782350 | 8b2dee96-319b-4bed-b2cf-99ec769dfdca ==============================
[0m13:19:03.782350 [info ] [MainThread]: Running with dbt=1.9.1
[0m13:19:03.783357 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:19:03.896518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8b2dee96-319b-4bed-b2cf-99ec769dfdca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F73A87080>]}
[0m13:19:03.928102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8b2dee96-319b-4bed-b2cf-99ec769dfdca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F73884E60>]}
[0m13:19:03.930523 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m13:19:04.045794 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m13:19:04.079146 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:19:04.079146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8b2dee96-319b-4bed-b2cf-99ec769dfdca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F735D0470>]}
[0m13:19:04.607225 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.application
[0m13:19:04.610783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8b2dee96-319b-4bed-b2cf-99ec769dfdca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F74FCE180>]}
[0m13:19:04.637228 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m13:19:04.637732 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m13:19:04.690322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8b2dee96-319b-4bed-b2cf-99ec769dfdca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F75073110>]}
[0m13:19:04.691329 [info ] [MainThread]: Found 5 models, 424 macros
[0m13:19:04.691834 [info ] [MainThread]: 
[0m13:19:04.692891 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:19:04.692891 [info ] [MainThread]: 
[0m13:19:04.693438 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m13:19:04.695996 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m13:19:04.740850 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m13:19:04.740850 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m13:19:04.742361 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:19:04.752496 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m13:19:04.753519 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m13:19:04.756582 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m13:19:04.757586 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m13:19:04.757586 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:19:04.765779 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m13:19:04.765779 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m13:19:04.769335 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m13:19:04.769335 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m13:19:04.772891 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m13:19:04.772891 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m13:19:04.772891 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:19:04.782020 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m13:19:04.783026 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m13:19:04.783026 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m13:19:04.783531 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:19:04.783531 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m13:19:04.783531 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m13:19:04.784565 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:19:04.785090 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m13:19:04.785090 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m13:19:04.785613 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m13:19:04.785613 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:19:04.785613 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m13:19:04.787641 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_cleansed)
[0m13:19:04.788144 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m13:19:04.789167 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m13:19:04.789167 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m13:19:04.789167 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:19:04.798408 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m13:19:04.798408 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m13:19:04.798408 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m13:19:04.799450 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:19:04.799450 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m13:19:04.799450 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m13:19:04.800474 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:19:04.800474 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m13:19:04.800474 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m13:19:04.800474 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m13:19:04.801501 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:19:04.801501 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m13:19:04.804034 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m13:19:04.806104 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m13:19:04.807640 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m13:19:04.807640 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:19:04.816321 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m13:19:04.816321 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m13:19:04.816321 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m13:19:04.834169 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m13:19:04.834673 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m13:19:04.835697 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m13:19:04.835697 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m13:19:04.838228 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_cleansed)
[0m13:19:04.839254 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m13:19:04.840729 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m13:19:04.840729 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:19:04.848915 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m13:19:04.849949 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m13:19:04.849949 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m13:19:04.867666 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m13:19:04.868174 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m13:19:04.869196 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m13:19:04.869196 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m13:19:04.872281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8b2dee96-319b-4bed-b2cf-99ec769dfdca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F7509C800>]}
[0m13:19:04.872281 [debug] [MainThread]: Using duckdb connection "master"
[0m13:19:04.872281 [debug] [MainThread]: On master: BEGIN
[0m13:19:04.872281 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:19:04.880993 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m13:19:04.880993 [debug] [MainThread]: On master: COMMIT
[0m13:19:04.880993 [debug] [MainThread]: Using duckdb connection "master"
[0m13:19:04.880993 [debug] [MainThread]: On master: COMMIT
[0m13:19:04.882017 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:19:04.882017 [debug] [MainThread]: On master: Close
[0m13:19:04.884133 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m13:19:04.884133 [info ] [Thread-1 (]: 1 of 5 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m13:19:04.885142 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m13:19:04.885646 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m13:19:04.888703 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m13:19:04.889730 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m13:19:04.906273 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m13:19:04.906273 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m13:19:04.907277 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m13:19:04.907780 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:19:04.915111 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m13:19:04.916119 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m13:19:04.916119 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m13:19:04.916626 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:04.920230 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m13:19:04.920230 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m13:19:04.921255 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:04.922285 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m13:19:04.922285 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m13:19:04.923340 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:04.930235 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m13:19:04.931241 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m13:19:04.931241 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m13:19:05.033066 [debug] [Thread-1 (]: SQL status: OK in 0.102 seconds
[0m13:19:05.036145 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m13:19:05.036145 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m13:19:05.038172 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:05.039729 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m13:19:05.060349 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b2dee96-319b-4bed-b2cf-99ec769dfdca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F72F04CB0>]}
[0m13:19:05.060349 [info ] [Thread-1 (]: 1 of 5 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.17s]
[0m13:19:05.061410 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m13:19:05.061410 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m13:19:05.061410 [info ] [Thread-1 (]: 2 of 5 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m13:19:05.062433 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m13:19:05.062433 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m13:19:05.063754 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m13:19:05.064762 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m13:19:05.066298 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m13:19:05.067303 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m13:19:05.067810 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m13:19:05.067810 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:05.080202 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m13:19:05.081231 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m13:19:05.081231 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m13:19:05.081231 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:05.083319 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m13:19:05.083319 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m13:19:05.084350 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:05.085867 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m13:19:05.085867 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m13:19:05.085867 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:05.087387 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m13:19:05.087387 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m13:19:05.087902 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m13:19:05.088930 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:05.089964 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m13:19:05.090998 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m13:19:05.092023 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:05.092023 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m13:19:05.111933 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b2dee96-319b-4bed-b2cf-99ec769dfdca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F75833290>]}
[0m13:19:05.111933 [info ] [Thread-1 (]: 2 of 5 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m13:19:05.113030 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m13:19:05.113030 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m13:19:05.113554 [info ] [Thread-1 (]: 3 of 5 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m13:19:05.114090 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m13:19:05.114090 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m13:19:05.115131 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m13:19:05.116137 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m13:19:05.117199 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m13:19:05.118230 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m13:19:05.118230 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m13:19:05.119253 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:05.131185 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m13:19:05.132236 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m13:19:05.132236 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        pull_request.html_url
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m13:19:05.133271 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        pull_request.html_url
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m13:19:05.133271 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m13:19:05.133271 [debug] [Thread-1 (]: On model.archi.cleanissue: ROLLBACK
[0m13:19:05.136824 [debug] [Thread-1 (]: Failed to rollback 'model.archi.cleanissue'
[0m13:19:05.137328 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m13:19:05.140443 [debug] [Thread-1 (]: Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Binder Error: Referenced table "pull_request" not found!
  Candidate tables: "raw_issues"
  LINE 12:         pull_request.html_url
                   ^
[0m13:19:05.140443 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b2dee96-319b-4bed-b2cf-99ec769dfdca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F7583F980>]}
[0m13:19:05.140443 [error] [Thread-1 (]: 3 of 5 ERROR creating sql view model main_cleansed.cleanissue .................. [[31mERROR[0m in 0.03s]
[0m13:19:05.141460 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m13:19:05.141460 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m13:19:05.141460 [debug] [Thread-4 (]: Marking all children of 'model.archi.cleanissue' to be skipped because of status 'error'.  Reason: Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Binder Error: Referenced table "pull_request" not found!
  Candidate tables: "raw_issues"
  LINE 12:         pull_request.html_url
                   ^.
[0m13:19:05.142486 [info ] [Thread-1 (]: 4 of 5 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m13:19:05.142486 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m13:19:05.143514 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m13:19:05.144617 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m13:19:05.145658 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m13:19:05.147169 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m13:19:05.147723 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m13:19:05.148236 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m13:19:05.148236 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:05.156547 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m13:19:05.156547 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m13:19:05.157551 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m13:19:05.158055 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:05.160104 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m13:19:05.160104 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m13:19:05.160104 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:05.163235 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m13:19:05.163235 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m13:19:05.163235 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:05.164240 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m13:19:05.165275 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m13:19:05.165275 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m13:19:05.166314 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:05.167829 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m13:19:05.167829 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m13:19:05.168860 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:05.169895 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m13:19:05.189329 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b2dee96-319b-4bed-b2cf-99ec769dfdca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F768A6FF0>]}
[0m13:19:05.189329 [info ] [Thread-1 (]: 4 of 5 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m13:19:05.190355 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m13:19:05.190355 [debug] [Thread-1 (]: Began running node model.archi.view
[0m13:19:05.190355 [info ] [Thread-1 (]: 5 of 5 START sql view model main.view .......................................... [RUN]
[0m13:19:05.191377 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m13:19:05.191377 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m13:19:05.192398 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m13:19:05.193909 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m13:19:05.194962 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m13:19:05.195993 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m13:19:05.195993 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m13:19:05.195993 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:05.208790 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m13:19:05.208790 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m13:19:05.209895 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m13:19:05.209895 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:05.211954 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m13:19:05.212979 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m13:19:05.212979 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:05.214491 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m13:19:05.214491 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m13:19:05.215520 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:05.215520 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m13:19:05.216546 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m13:19:05.216546 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m13:19:05.218056 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:05.219086 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m13:19:05.219086 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m13:19:05.220117 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:05.221141 [debug] [Thread-1 (]: On model.archi.view: Close
[0m13:19:05.239573 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b2dee96-319b-4bed-b2cf-99ec769dfdca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F7571E510>]}
[0m13:19:05.239573 [info ] [Thread-1 (]: 5 of 5 OK created sql view model main.view ..................................... [[32mOK[0m in 0.05s]
[0m13:19:05.240578 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m13:19:05.241604 [debug] [MainThread]: Using duckdb connection "master"
[0m13:19:05.241604 [debug] [MainThread]: On master: BEGIN
[0m13:19:05.241604 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:19:05.253877 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m13:19:05.253877 [debug] [MainThread]: On master: COMMIT
[0m13:19:05.254996 [debug] [MainThread]: Using duckdb connection "master"
[0m13:19:05.254996 [debug] [MainThread]: On master: COMMIT
[0m13:19:05.254996 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:19:05.254996 [debug] [MainThread]: On master: Close
[0m13:19:05.257514 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:19:05.257514 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m13:19:05.258060 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m13:19:05.258060 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m13:19:05.258579 [info ] [MainThread]: 
[0m13:19:05.258579 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.57 seconds (0.57s).
[0m13:19:05.258579 [debug] [MainThread]: Command end result
[0m13:19:05.270347 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m13:19:05.271351 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m13:19:05.275460 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m13:19:05.275460 [info ] [MainThread]: 
[0m13:19:05.275460 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m13:19:05.275460 [info ] [MainThread]: 
[0m13:19:05.276480 [error] [MainThread]:   Runtime Error in model cleanissue (models\cleansed\cleanissue.sql)
  Binder Error: Referenced table "pull_request" not found!
  Candidate tables: "raw_issues"
  LINE 12:         pull_request.html_url
                   ^
[0m13:19:05.276480 [info ] [MainThread]: 
[0m13:19:05.276480 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m13:19:05.277990 [debug] [MainThread]: Command `dbt build` failed at 13:19:05.277486 after 1.58 seconds
[0m13:19:05.277990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F73596540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F7356B170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F73569940>]}
[0m13:19:05.278515 [debug] [MainThread]: Flushing usage events
[0m13:19:05.775294 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:19:16.193122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B0B1AD4F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B0E85E780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B0E85E240>]}


============================== 13:19:16.197216 | 4eca9d6e-b957-4670-b281-4c54e2b191ee ==============================
[0m13:19:16.197216 [info ] [MainThread]: Running with dbt=1.9.1
[0m13:19:16.197730 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:19:16.310760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4eca9d6e-b957-4670-b281-4c54e2b191ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B0E73B530>]}
[0m13:19:16.341778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4eca9d6e-b957-4670-b281-4c54e2b191ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B0E38F110>]}
[0m13:19:16.343843 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m13:19:16.473642 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m13:19:16.543050 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:19:16.544557 [debug] [MainThread]: Partial parsing: updated file: archi://models\cleansed\cleanissue.sql
[0m13:19:16.666614 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.archi.application
[0m13:19:16.725635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4eca9d6e-b957-4670-b281-4c54e2b191ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B0FDB7CE0>]}
[0m13:19:16.752993 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m13:19:16.754009 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m13:19:16.776634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4eca9d6e-b957-4670-b281-4c54e2b191ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B10144050>]}
[0m13:19:16.777638 [info ] [MainThread]: Found 5 models, 424 macros
[0m13:19:16.778144 [info ] [MainThread]: 
[0m13:19:16.779167 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:19:16.779167 [info ] [MainThread]: 
[0m13:19:16.779167 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m13:19:16.781703 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m13:19:16.826798 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m13:19:16.827801 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m13:19:16.827801 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:19:16.837492 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m13:19:16.838526 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m13:19:16.842116 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m13:19:16.842116 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m13:19:16.842116 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:19:16.850842 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m13:19:16.852351 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m13:19:16.854415 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m13:19:16.854415 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m13:19:16.857986 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m13:19:16.857986 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m13:19:16.859011 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:19:16.866298 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m13:19:16.867814 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m13:19:16.867814 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m13:19:16.867814 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:19:16.868864 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m13:19:16.868864 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m13:19:16.868864 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:19:16.869896 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m13:19:16.869896 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m13:19:16.869896 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m13:19:16.870929 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:19:16.870929 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m13:19:16.872960 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main)
[0m13:19:16.872960 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m13:19:16.873999 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m13:19:16.873999 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m13:19:16.873999 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:19:16.881693 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m13:19:16.883201 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m13:19:16.883201 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m13:19:16.884242 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:19:16.884242 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m13:19:16.884242 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m13:19:16.884242 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:19:16.885267 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m13:19:16.885267 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m13:19:16.885267 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m13:19:16.886289 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:19:16.886289 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m13:19:16.888829 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m13:19:16.891916 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m13:19:16.891916 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m13:19:16.891916 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:19:16.900744 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m13:19:16.900744 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m13:19:16.900744 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m13:19:16.918187 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m13:19:16.919208 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m13:19:16.919208 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m13:19:16.920240 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m13:19:16.922285 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main)
[0m13:19:16.923300 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m13:19:16.924303 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m13:19:16.924303 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:19:16.931991 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m13:19:16.931991 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m13:19:16.933015 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m13:19:16.949469 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m13:19:16.950493 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m13:19:16.951521 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m13:19:16.951521 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m13:19:16.954591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4eca9d6e-b957-4670-b281-4c54e2b191ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B106897C0>]}
[0m13:19:16.955119 [debug] [MainThread]: Using duckdb connection "master"
[0m13:19:16.955119 [debug] [MainThread]: On master: BEGIN
[0m13:19:16.955119 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:19:16.963745 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m13:19:16.964777 [debug] [MainThread]: On master: COMMIT
[0m13:19:16.964777 [debug] [MainThread]: Using duckdb connection "master"
[0m13:19:16.965316 [debug] [MainThread]: On master: COMMIT
[0m13:19:16.965316 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:19:16.965316 [debug] [MainThread]: On master: Close
[0m13:19:16.967838 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m13:19:16.967838 [info ] [Thread-1 (]: 1 of 5 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m13:19:16.968867 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m13:19:16.968867 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m13:19:16.973019 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m13:19:16.973019 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m13:19:16.989437 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m13:19:16.990440 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m13:19:16.990440 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m13:19:16.990440 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:19:16.999827 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m13:19:16.999827 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m13:19:16.999827 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m13:19:17.000852 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.004482 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m13:19:17.005513 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m13:19:17.005513 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.007535 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m13:19:17.007535 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m13:19:17.008051 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.014227 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m13:19:17.014227 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m13:19:17.015253 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m13:19:17.016815 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:17.019395 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m13:19:17.019395 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m13:19:17.020400 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:17.021433 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m13:19:17.043138 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eca9d6e-b957-4670-b281-4c54e2b191ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B1071B800>]}
[0m13:19:17.043138 [info ] [Thread-1 (]: 1 of 5 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.07s]
[0m13:19:17.044163 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m13:19:17.044163 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m13:19:17.044163 [info ] [Thread-1 (]: 2 of 5 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m13:19:17.045169 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m13:19:17.045672 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m13:19:17.046702 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m13:19:17.046702 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m13:19:17.049241 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m13:19:17.049241 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m13:19:17.049241 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m13:19:17.050315 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:17.062584 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m13:19:17.062584 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m13:19:17.063624 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m13:19:17.063624 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.065650 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m13:19:17.066154 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m13:19:17.066154 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.067663 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m13:19:17.067663 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m13:19:17.068666 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.069705 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m13:19:17.069705 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m13:19:17.069705 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m13:19:17.071744 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:17.072776 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m13:19:17.072776 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m13:19:17.073807 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:17.074840 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m13:19:17.093720 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eca9d6e-b957-4670-b281-4c54e2b191ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B106FCB90>]}
[0m13:19:17.094746 [info ] [Thread-1 (]: 2 of 5 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m13:19:17.094746 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m13:19:17.094746 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m13:19:17.096253 [info ] [Thread-1 (]: 3 of 5 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m13:19:17.096253 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m13:19:17.096253 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m13:19:17.097838 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m13:19:17.097838 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m13:19:17.099897 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m13:19:17.100915 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m13:19:17.100915 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m13:19:17.100915 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:17.114237 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m13:19:17.114237 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m13:19:17.114237 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m13:19:17.115264 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.116774 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m13:19:17.116774 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m13:19:17.117779 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.119309 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m13:19:17.119309 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m13:19:17.119836 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.121382 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m13:19:17.121382 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m13:19:17.121382 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m13:19:17.122408 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:17.124483 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m13:19:17.124483 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m13:19:17.125506 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:17.125506 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m13:19:17.145483 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eca9d6e-b957-4670-b281-4c54e2b191ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B1075FE30>]}
[0m13:19:17.145483 [info ] [Thread-1 (]: 3 of 5 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m13:19:17.146516 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m13:19:17.146516 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m13:19:17.146516 [info ] [Thread-1 (]: 4 of 5 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m13:19:17.147520 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m13:19:17.147520 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m13:19:17.149052 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m13:19:17.149052 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m13:19:17.150403 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m13:19:17.151440 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m13:19:17.151440 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m13:19:17.151440 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:17.164344 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m13:19:17.164344 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m13:19:17.165374 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m13:19:17.165374 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.167415 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m13:19:17.167922 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m13:19:17.167922 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.169985 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m13:19:17.169985 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m13:19:17.169985 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.171011 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m13:19:17.171011 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m13:19:17.172056 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m13:19:17.173083 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:17.174115 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m13:19:17.174115 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m13:19:17.175145 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:17.176230 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m13:19:17.195688 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eca9d6e-b957-4670-b281-4c54e2b191ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B10699A30>]}
[0m13:19:17.195688 [info ] [Thread-1 (]: 4 of 5 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m13:19:17.196712 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m13:19:17.196712 [debug] [Thread-1 (]: Began running node model.archi.view
[0m13:19:17.196712 [info ] [Thread-1 (]: 5 of 5 START sql view model main.view .......................................... [RUN]
[0m13:19:17.197715 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.view)
[0m13:19:17.197715 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m13:19:17.199243 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m13:19:17.199243 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m13:19:17.200272 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m13:19:17.201780 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m13:19:17.202291 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m13:19:17.202291 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:19:17.215054 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m13:19:17.215054 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m13:19:17.215054 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m13:19:17.216076 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.217586 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m13:19:17.217586 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m13:19:17.218615 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.219639 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m13:19:17.219639 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m13:19:17.220667 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:19:17.220667 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m13:19:17.220667 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m13:19:17.222241 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m13:19:17.223244 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:17.224279 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m13:19:17.224279 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m13:19:17.225305 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:19:17.226336 [debug] [Thread-1 (]: On model.archi.view: Close
[0m13:19:17.245211 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eca9d6e-b957-4670-b281-4c54e2b191ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B10714500>]}
[0m13:19:17.245211 [info ] [Thread-1 (]: 5 of 5 OK created sql view model main.view ..................................... [[32mOK[0m in 0.05s]
[0m13:19:17.246230 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m13:19:17.246230 [debug] [MainThread]: Using duckdb connection "master"
[0m13:19:17.246230 [debug] [MainThread]: On master: BEGIN
[0m13:19:17.246230 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:19:17.258927 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m13:19:17.259960 [debug] [MainThread]: On master: COMMIT
[0m13:19:17.259960 [debug] [MainThread]: Using duckdb connection "master"
[0m13:19:17.259960 [debug] [MainThread]: On master: COMMIT
[0m13:19:17.259960 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:19:17.259960 [debug] [MainThread]: On master: Close
[0m13:19:17.262008 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:19:17.262008 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m13:19:17.263011 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m13:19:17.263011 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m13:19:17.263011 [info ] [MainThread]: 
[0m13:19:17.263011 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 0.48 seconds (0.48s).
[0m13:19:17.264053 [debug] [MainThread]: Command end result
[0m13:19:17.274344 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m13:19:17.275368 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m13:19:17.278916 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m13:19:17.278916 [info ] [MainThread]: 
[0m13:19:17.278916 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:19:17.279944 [info ] [MainThread]: 
[0m13:19:17.279944 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m13:19:17.280967 [debug] [MainThread]: Command `dbt build` succeeded at 13:19:17.280967 after 1.17 seconds
[0m13:19:17.280967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B0E85E240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B0E512FF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024B0DD24950>]}
[0m13:19:17.280967 [debug] [MainThread]: Flushing usage events
[0m13:19:17.678279 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:37:48.222145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017210D2F9B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017210D2F5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017210D2D820>]}


============================== 14:37:48.224704 | 75fd384e-cbda-42a9-b794-867dec96b8a9 ==============================
[0m14:37:48.224704 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:37:48.224704 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:37:48.363941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '75fd384e-cbda-42a9-b794-867dec96b8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172113430E0>]}
[0m14:37:48.394703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '75fd384e-cbda-42a9-b794-867dec96b8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017211272A80>]}
[0m14:37:48.404897 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:37:48.568870 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:37:48.922840 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m14:37:48.922840 [debug] [MainThread]: Partial parsing: added file: archi://models\application\fcommits.sql
[0m14:37:48.922840 [debug] [MainThread]: Partial parsing: added file: archi://models\application\dcontributeur.sql
[0m14:37:49.046488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '75fd384e-cbda-42a9-b794-867dec96b8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172112B3AD0>]}
[0m14:37:49.072519 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:37:49.079641 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:37:49.116071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '75fd384e-cbda-42a9-b794-867dec96b8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172128C2F90>]}
[0m14:37:49.117102 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:37:49.118137 [info ] [MainThread]: 
[0m14:37:49.118137 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:37:49.119175 [info ] [MainThread]: 
[0m14:37:49.119175 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:37:49.122220 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:37:49.818509 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:37:49.818509 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:37:49.818509 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:37:49.831210 [debug] [ThreadPool]: SQL status: OK in 0.013 seconds
[0m14:37:49.832717 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:37:49.835785 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:37:49.835785 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:37:49.835785 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:37:49.844445 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:37:49.845478 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:37:49.847527 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:37:49.847527 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:37:49.849036 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:37:49.856769 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:37:49.857798 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:37:49.859309 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m14:37:49.859309 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:37:49.863925 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:37:49.863925 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:37:49.863925 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:37:49.872123 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:37:49.873188 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:37:49.873188 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:37:49.873188 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:37:49.873188 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:37:49.874220 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:37:49.874220 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:37:49.875247 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:37:49.875247 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:37:49.875247 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:37:49.875247 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:37:49.876273 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:37:49.877297 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_cleansed)
[0m14:37:49.878321 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:37:49.878321 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:37:49.879831 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:37:49.879831 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:37:49.887510 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:37:49.888578 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:37:49.888578 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:37:49.888578 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:37:49.888578 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:37:49.888578 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:37:49.890091 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:37:49.890091 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:37:49.890091 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:37:49.891118 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:37:49.891118 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:37:49.891118 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:37:49.892628 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main_application)
[0m14:37:49.893658 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:37:49.894695 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:37:49.894695 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:37:49.894695 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:37:49.902913 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:37:49.903978 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:37:49.903978 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:37:49.905011 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:37:49.905011 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:37:49.905011 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:37:49.905011 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:37:49.906035 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:37:49.906035 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:37:49.907058 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:37:49.908082 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m14:37:49.909111 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:37:49.929514 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m14:37:49.932532 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:37:49.932532 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:37:49.932532 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:37:49.944822 [debug] [ThreadPool]: SQL status: OK in 0.012 seconds
[0m14:37:49.945845 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:37:49.945845 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:37:49.962165 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:37:49.963171 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:37:49.970461 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:37:49.970461 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:37:49.973989 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_cleansed)
[0m14:37:49.977040 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:37:49.977040 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:37:49.977040 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:37:49.985717 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:37:49.986743 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:37:49.986743 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:37:50.003086 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:37:50.004103 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:37:50.005131 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:37:50.005131 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:37:50.007193 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main_application)
[0m14:37:50.009245 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:37:50.009245 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:37:50.009245 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:37:50.017956 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:37:50.017956 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:37:50.018978 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:37:50.034824 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:37:50.034824 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:37:50.036248 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:37:50.036248 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:37:50.038331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '75fd384e-cbda-42a9-b794-867dec96b8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017211340D40>]}
[0m14:37:50.039361 [debug] [MainThread]: Using duckdb connection "master"
[0m14:37:50.039361 [debug] [MainThread]: On master: BEGIN
[0m14:37:50.039361 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:37:50.048096 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m14:37:50.048096 [debug] [MainThread]: On master: COMMIT
[0m14:37:50.048096 [debug] [MainThread]: Using duckdb connection "master"
[0m14:37:50.048096 [debug] [MainThread]: On master: COMMIT
[0m14:37:50.049139 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:37:50.049139 [debug] [MainThread]: On master: Close
[0m14:37:50.051198 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:37:50.052202 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:37:50.052706 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:37:50.052706 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:37:50.056794 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:37:50.056794 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:37:50.073209 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:37:50.074216 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:37:50.074723 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:37:50.074723 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:37:50.083350 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:37:50.083350 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:37:50.084356 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:37:50.084861 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.087982 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:37:50.087982 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:37:50.088987 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.090016 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:37:50.091039 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:37:50.091039 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.097126 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:37:50.098147 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:37:50.098147 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:37:50.099167 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:37:50.102218 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:37:50.102723 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:37:50.102723 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:37:50.104757 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:37:50.125043 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75fd384e-cbda-42a9-b794-867dec96b8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001720E5ABEF0>]}
[0m14:37:50.125043 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.07s]
[0m14:37:50.126305 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:37:50.126305 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:37:50.126305 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:37:50.127646 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:37:50.127646 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:37:50.128674 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:37:50.129695 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:37:50.130722 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:37:50.130722 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:37:50.130722 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:37:50.132235 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:37:50.143988 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:37:50.145043 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:37:50.145043 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:37:50.145553 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.148134 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:37:50.148134 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:37:50.148134 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.150212 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:37:50.150212 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:37:50.150212 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.151238 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:37:50.151238 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:37:50.152245 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:37:50.152748 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:37:50.153988 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:37:50.155016 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:37:50.155016 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:37:50.156525 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:37:50.174798 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75fd384e-cbda-42a9-b794-867dec96b8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001721313F440>]}
[0m14:37:50.176306 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:37:50.176306 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:37:50.177333 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:37:50.177333 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:37:50.177333 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:37:50.177333 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:37:50.179390 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:37:50.179390 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:37:50.181471 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:37:50.182476 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:37:50.182476 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:37:50.182980 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:37:50.195307 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:37:50.195307 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:37:50.195307 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:37:50.196815 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.197878 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:37:50.197878 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:37:50.198994 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.200024 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:37:50.200024 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:37:50.201047 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.202052 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:37:50.202052 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:37:50.202555 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:37:50.203578 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:37:50.204610 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:37:50.204610 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:37:50.205634 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:37:50.207147 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:37:50.226742 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75fd384e-cbda-42a9-b794-867dec96b8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001721313E3F0>]}
[0m14:37:50.226742 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:37:50.227746 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:37:50.227746 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:37:50.227746 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:37:50.227746 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:37:50.229102 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:37:50.230135 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:37:50.230135 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:37:50.232169 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:37:50.232672 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:37:50.232672 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:37:50.232672 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:37:50.245798 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:37:50.245798 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:37:50.246971 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:37:50.246971 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.248480 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:37:50.249483 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:37:50.249483 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.250504 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:37:50.251528 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:37:50.251528 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.252534 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:37:50.253036 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:37:50.253036 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:37:50.254066 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:37:50.256159 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:37:50.256159 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:37:50.257183 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:37:50.258189 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:37:50.277024 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75fd384e-cbda-42a9-b794-867dec96b8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172141763F0>]}
[0m14:37:50.278153 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:37:50.278681 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:37:50.279210 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:37:50.279210 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:37:50.279210 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:37:50.279210 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:37:50.281275 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:37:50.281275 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:37:50.282785 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:37:50.284295 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:37:50.284295 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:37:50.284295 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:37:50.296833 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:37:50.296833 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:37:50.297855 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:37:50.297855 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.299975 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:37:50.299975 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:37:50.299975 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.300996 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:37:50.300996 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:37:50.300996 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:37:50.302505 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:37:50.303544 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:37:50.303544 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:37:50.305054 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.305054 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:37:50.324696 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75fd384e-cbda-42a9-b794-867dec96b8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017214176F00>]}
[0m14:37:50.325212 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:37:50.325212 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:37:50.326217 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:37:50.326217 [info ] [Thread-1 (]: 6 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m14:37:50.326217 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:37:50.326217 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:37:50.328643 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:37:50.328643 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:37:50.330675 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:37:50.330675 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:37:50.330675 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:37:50.330675 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:37:50.344016 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:37:50.345044 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:37:50.345044 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits, raw_contributors
left join commits c on raw_commits."author.id" = raw_contributors.id
  );

[0m14:37:50.345044 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits, raw_contributors
left join commits c on raw_commits."author.id" = raw_contributors.id
  );

[0m14:37:50.346072 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:37:50.346072 [debug] [Thread-1 (]: On model.archi.fcommits: ROLLBACK
[0m14:37:50.395874 [debug] [Thread-1 (]: Failed to rollback 'model.archi.fcommits'
[0m14:37:50.395874 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:37:50.400012 [debug] [Thread-1 (]: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:37:50.400012 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75fd384e-cbda-42a9-b794-867dec96b8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017212A72690>]}
[0m14:37:50.400012 [error] [Thread-1 (]: 6 of 7 ERROR creating sql view model main_application.fcommits ................. [[31mERROR[0m in 0.07s]
[0m14:37:50.401084 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:37:50.401084 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:37:50.401591 [debug] [Thread-4 (]: Marking all children of 'model.archi.fcommits' to be skipped because of status 'error'.  Reason: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema).
[0m14:37:50.402104 [info ] [Thread-1 (]: 7 of 7 START sql view model main.view .......................................... [RUN]
[0m14:37:50.402104 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:37:50.402104 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:37:50.404138 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:37:50.404643 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:37:50.405671 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:37:50.406696 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:37:50.406696 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:37:50.406696 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:37:50.415438 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m14:37:50.415438 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:37:50.415438 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:37:50.416465 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.418512 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:37:50.418512 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:37:50.418512 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.420553 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:37:50.420553 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:37:50.420553 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:37:50.420553 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:37:50.422060 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:37:50.422060 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:37:50.423124 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:37:50.424207 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:37:50.425233 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:37:50.426248 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:37:50.426248 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:37:50.445956 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75fd384e-cbda-42a9-b794-867dec96b8a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001721315CB30>]}
[0m14:37:50.445956 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.04s]
[0m14:37:50.445956 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:37:50.447433 [debug] [MainThread]: Using duckdb connection "master"
[0m14:37:50.447433 [debug] [MainThread]: On master: BEGIN
[0m14:37:50.448458 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:37:50.460125 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m14:37:50.461130 [debug] [MainThread]: On master: COMMIT
[0m14:37:50.461130 [debug] [MainThread]: Using duckdb connection "master"
[0m14:37:50.461130 [debug] [MainThread]: On master: COMMIT
[0m14:37:50.461130 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:37:50.462111 [debug] [MainThread]: On master: Close
[0m14:37:50.463652 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:37:50.464184 [debug] [MainThread]: Connection 'create_pytorch_data_main_application' was properly closed.
[0m14:37:50.464184 [debug] [MainThread]: Connection 'list_pytorch_data_main_application' was properly closed.
[0m14:37:50.464711 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:37:50.464711 [info ] [MainThread]: 
[0m14:37:50.464711 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 1.35 seconds (1.35s).
[0m14:37:50.465736 [debug] [MainThread]: Command end result
[0m14:37:50.475957 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:37:50.477034 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:37:50.480097 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:37:50.480097 [info ] [MainThread]: 
[0m14:37:50.480097 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:37:50.481603 [info ] [MainThread]: 
[0m14:37:50.482113 [error] [MainThread]:   Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:37:50.482113 [info ] [MainThread]: 
[0m14:37:50.482113 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m14:37:50.483117 [debug] [MainThread]: Command `dbt build` failed at 14:37:50.483117 after 2.37 seconds
[0m14:37:50.483117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172110DB2C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172110DB440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000172110D9820>]}
[0m14:37:50.483117 [debug] [MainThread]: Flushing usage events
[0m14:37:50.989256 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:38:30.335742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D44944260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D470702C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D47073BF0>]}


============================== 14:38:30.338431 | 9f01bae6-df94-4da5-abdf-e8e6f7e0ce69 ==============================
[0m14:38:30.338431 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:38:30.338431 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:38:30.451725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9f01bae6-df94-4da5-abdf-e8e6f7e0ce69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4774C980>]}
[0m14:38:30.483639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9f01bae6-df94-4da5-abdf-e8e6f7e0ce69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D44AD5BB0>]}
[0m14:38:30.485705 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:38:30.606426 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:38:30.670248 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:38:30.670248 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m14:38:30.794187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9f01bae6-df94-4da5-abdf-e8e6f7e0ce69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D488FFFE0>]}
[0m14:38:30.821095 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:38:30.823126 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:38:30.845626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9f01bae6-df94-4da5-abdf-e8e6f7e0ce69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D48D5CC50>]}
[0m14:38:30.845626 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:38:30.846649 [info ] [MainThread]: 
[0m14:38:30.847894 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:38:30.847894 [info ] [MainThread]: 
[0m14:38:30.848444 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:38:30.851015 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:38:30.895982 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:38:30.895982 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:38:30.895982 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:38:30.906639 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m14:38:30.907657 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:38:30.910763 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:38:30.911291 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:38:30.911291 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:38:30.920429 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:38:30.920954 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:38:30.924015 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:38:30.924015 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:38:30.924015 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:38:30.931733 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:38:30.933244 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:38:30.934602 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m14:38:30.934602 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:38:30.939677 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:38:30.939677 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:38:30.939677 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:38:30.948404 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:38:30.949914 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:38:30.949914 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:38:30.949914 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:38:30.949914 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:38:30.949914 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:38:30.949914 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:38:30.951422 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:38:30.951422 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:38:30.951422 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:38:30.951422 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:38:30.952930 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:38:30.953961 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main)
[0m14:38:30.954987 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:38:30.956011 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:38:30.956011 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:38:30.956011 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:38:30.964153 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:38:30.965177 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:38:30.966200 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:38:30.966200 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:38:30.966200 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:38:30.966200 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:38:30.967225 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:38:30.967225 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:38:30.967225 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:38:30.968235 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:38:30.968235 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:38:30.968746 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:38:30.970254 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_application)
[0m14:38:30.970254 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:38:30.971847 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:38:30.971847 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:38:30.971847 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:38:30.980445 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:38:30.980948 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:38:30.980948 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:38:30.981953 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:38:30.981953 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:38:30.981953 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:38:30.981953 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:38:30.983161 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:38:30.983161 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:38:30.983161 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:38:30.983161 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:38:30.984199 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:38:30.986249 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m14:38:30.989357 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:38:30.989357 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:38:30.989357 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:38:30.998106 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:38:30.998106 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:38:30.999148 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:38:31.016055 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:38:31.016055 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:38:31.017134 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:38:31.017134 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:38:31.020185 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main)
[0m14:38:31.021694 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:38:31.021694 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:38:31.021694 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:38:31.029334 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:38:31.030353 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:38:31.030353 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:38:31.047650 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:38:31.047736 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:38:31.048740 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:38:31.048740 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:38:31.050798 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_application)
[0m14:38:31.053823 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:38:31.053823 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:38:31.053823 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:38:31.063526 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:38:31.063526 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:38:31.064050 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:38:31.080839 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:38:31.080839 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:38:31.082339 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:38:31.082847 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:38:31.084878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9f01bae6-df94-4da5-abdf-e8e6f7e0ce69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D49536090>]}
[0m14:38:31.084878 [debug] [MainThread]: Using duckdb connection "master"
[0m14:38:31.086130 [debug] [MainThread]: On master: BEGIN
[0m14:38:31.086130 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:38:31.093766 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m14:38:31.094816 [debug] [MainThread]: On master: COMMIT
[0m14:38:31.094816 [debug] [MainThread]: Using duckdb connection "master"
[0m14:38:31.094816 [debug] [MainThread]: On master: COMMIT
[0m14:38:31.094816 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:38:31.095852 [debug] [MainThread]: On master: Close
[0m14:38:31.097923 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:38:31.097923 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:38:31.098950 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:38:31.098950 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:38:31.103021 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:38:31.103523 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:38:31.119291 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:38:31.120317 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:38:31.120317 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:38:31.120317 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:38:31.129558 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:38:31.129558 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:38:31.130579 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:38:31.130579 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.134147 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:38:31.135172 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:38:31.135172 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.136682 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:38:31.136682 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:38:31.137686 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.143759 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:38:31.144780 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:38:31.144780 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:38:31.246581 [debug] [Thread-1 (]: SQL status: OK in 0.102 seconds
[0m14:38:31.249700 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:38:31.249700 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:38:31.251212 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:38:31.253418 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:38:31.274168 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f01bae6-df94-4da5-abdf-e8e6f7e0ce69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D48D5CA40>]}
[0m14:38:31.274168 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.17s]
[0m14:38:31.275463 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:38:31.275463 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:38:31.275463 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:38:31.276588 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:38:31.276588 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:38:31.277659 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:38:31.278868 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:38:31.279872 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:38:31.280897 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:38:31.280897 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:38:31.280897 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:38:31.293641 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:38:31.294646 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:38:31.294646 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:38:31.294646 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.296711 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:38:31.296711 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:38:31.297737 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.299834 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:38:31.299834 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:38:31.300851 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.300851 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:38:31.300851 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:38:31.300851 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:38:31.302871 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:38:31.303876 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:38:31.304915 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:38:31.305943 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:38:31.305943 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:38:31.326384 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f01bae6-df94-4da5-abdf-e8e6f7e0ce69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D495736B0>]}
[0m14:38:31.326384 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:38:31.327411 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:38:31.327411 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:38:31.327411 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:38:31.328540 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:38:31.328540 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:38:31.330104 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:38:31.330625 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:38:31.331647 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:38:31.331647 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:38:31.333156 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:38:31.333156 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:38:31.345425 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:38:31.345425 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:38:31.346450 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:38:31.346450 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.348505 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:38:31.348505 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:38:31.349535 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.351045 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:38:31.351045 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:38:31.351045 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.352049 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:38:31.352049 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:38:31.353054 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:38:31.354592 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:38:31.355625 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:38:31.355625 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:38:31.356687 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:38:31.357707 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:38:31.376798 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f01bae6-df94-4da5-abdf-e8e6f7e0ce69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D495795E0>]}
[0m14:38:31.377822 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:38:31.377822 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:38:31.377822 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:38:31.378847 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:38:31.378847 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:38:31.378847 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:38:31.379870 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:38:31.381378 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:38:31.382887 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:38:31.382887 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:38:31.382887 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:38:31.383916 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:38:31.396109 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:38:31.397153 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:38:31.397153 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:38:31.398180 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.399205 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:38:31.400229 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:38:31.400229 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.401799 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:38:31.401799 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:38:31.402803 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.403311 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:38:31.403311 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:38:31.403311 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:38:31.405369 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:38:31.406394 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:38:31.406394 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:38:31.407418 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:38:31.408456 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:38:31.428300 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f01bae6-df94-4da5-abdf-e8e6f7e0ce69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D495362A0>]}
[0m14:38:31.429322 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:38:31.429322 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:38:31.429322 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:38:31.430346 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:38:31.430346 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:38:31.430346 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:38:31.432884 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:38:31.433888 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:38:31.434938 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:38:31.435967 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:38:31.435967 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:38:31.435967 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:38:31.448744 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:38:31.449769 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:38:31.449769 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:38:31.450786 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.451808 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:38:31.452813 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:38:31.453318 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.454323 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:38:31.454323 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:38:31.455347 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.456372 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:38:31.456372 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:38:31.456372 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:38:31.457397 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:38:31.458803 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:38:31.459828 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:38:31.459828 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:38:31.461328 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:38:31.482854 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f01bae6-df94-4da5-abdf-e8e6f7e0ce69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D49536660>]}
[0m14:38:31.483358 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:38:31.483358 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:38:31.483358 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:38:31.484795 [info ] [Thread-1 (]: 6 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m14:38:31.484795 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:38:31.484795 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:38:31.486105 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:38:31.487133 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:38:31.488153 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:38:31.489179 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:38:31.489179 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:38:31.489179 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:38:31.502993 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:38:31.502993 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:38:31.502993 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  main.raw_commits, main.raw_contributors
left join commits c on raw_commits."author.id" = raw_contributors.id
  );

[0m14:38:31.517433 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  main.raw_commits, main.raw_contributors
left join commits c on raw_commits."author.id" = raw_contributors.id
  );

[0m14:38:31.517433 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:38:31.518449 [debug] [Thread-1 (]: On model.archi.fcommits: ROLLBACK
[0m14:38:31.521552 [debug] [Thread-1 (]: Failed to rollback 'model.archi.fcommits'
[0m14:38:31.521552 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:38:31.524572 [debug] [Thread-1 (]: Runtime Error in model fcommits (models\application\fcommits.sql)
  Catalog Error: Table with name commits does not exist!
  Did you mean "raw_commits"?
  LINE 28: left join commits c on raw_commits."author.id" = raw_contributors.id
    );
  ...
                     ^
[0m14:38:31.525630 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f01bae6-df94-4da5-abdf-e8e6f7e0ce69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D495B2450>]}
[0m14:38:31.525630 [error] [Thread-1 (]: 6 of 7 ERROR creating sql view model main_application.fcommits ................. [[31mERROR[0m in 0.04s]
[0m14:38:31.526653 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:38:31.526653 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:38:31.526653 [debug] [Thread-4 (]: Marking all children of 'model.archi.fcommits' to be skipped because of status 'error'.  Reason: Runtime Error in model fcommits (models\application\fcommits.sql)
  Catalog Error: Table with name commits does not exist!
  Did you mean "raw_commits"?
  LINE 28: left join commits c on raw_commits."author.id" = raw_contributors.id
    );
  ...
                     ^.
[0m14:38:31.527676 [info ] [Thread-1 (]: 7 of 7 START sql view model main.view .......................................... [RUN]
[0m14:38:31.527676 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:38:31.527676 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:38:31.529734 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:38:31.529734 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:38:31.531780 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:38:31.531780 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:38:31.531780 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:38:31.531780 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:38:31.541493 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:38:31.541493 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:38:31.541493 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:38:31.543005 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.544029 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:38:31.545035 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:38:31.545035 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.546545 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:38:31.546545 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:38:31.546545 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:38:31.547568 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:38:31.548599 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:38:31.548599 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:38:31.549625 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:38:31.550651 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:38:31.551678 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:38:31.551678 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:38:31.553189 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:38:31.573162 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f01bae6-df94-4da5-abdf-e8e6f7e0ce69', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4965BB30>]}
[0m14:38:31.573162 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.05s]
[0m14:38:31.574186 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:38:31.574186 [debug] [MainThread]: Using duckdb connection "master"
[0m14:38:31.574186 [debug] [MainThread]: On master: BEGIN
[0m14:38:31.575700 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:38:31.588015 [debug] [MainThread]: SQL status: OK in 0.013 seconds
[0m14:38:31.588015 [debug] [MainThread]: On master: COMMIT
[0m14:38:31.588015 [debug] [MainThread]: Using duckdb connection "master"
[0m14:38:31.589051 [debug] [MainThread]: On master: COMMIT
[0m14:38:31.589051 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:38:31.589051 [debug] [MainThread]: On master: Close
[0m14:38:31.591126 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:38:31.591126 [debug] [MainThread]: Connection 'create_pytorch_data_main_application' was properly closed.
[0m14:38:31.592154 [debug] [MainThread]: Connection 'list_pytorch_data_main_application' was properly closed.
[0m14:38:31.592154 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:38:31.592154 [info ] [MainThread]: 
[0m14:38:31.592154 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.74 seconds (0.74s).
[0m14:38:31.593666 [debug] [MainThread]: Command end result
[0m14:38:31.604577 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:38:31.605613 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:38:31.609166 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:38:31.609166 [info ] [MainThread]: 
[0m14:38:31.610189 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:38:31.610189 [info ] [MainThread]: 
[0m14:38:31.610189 [error] [MainThread]:   Runtime Error in model fcommits (models\application\fcommits.sql)
  Catalog Error: Table with name commits does not exist!
  Did you mean "raw_commits"?
  LINE 28: left join commits c on raw_commits."author.id" = raw_contributors.id
    );
  ...
                     ^
[0m14:38:31.610189 [info ] [MainThread]: 
[0m14:38:31.611214 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m14:38:31.611214 [debug] [MainThread]: Command `dbt build` failed at 14:38:31.611214 after 1.36 seconds
[0m14:38:31.612241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4719A300>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D47199B20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D4719B1D0>]}
[0m14:38:31.612241 [debug] [MainThread]: Flushing usage events
[0m14:38:32.094192 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:39:25.269805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C51997AD80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C5197B8C20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C51997A030>]}


============================== 14:39:25.272386 | 0d9fba10-e211-4d48-99b5-cd0b639048fd ==============================
[0m14:39:25.272386 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:39:25.272386 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m14:39:25.382489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0d9fba10-e211-4d48-99b5-cd0b639048fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C519B40B30>]}
[0m14:39:25.413848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0d9fba10-e211-4d48-99b5-cd0b639048fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C519370590>]}
[0m14:39:25.415927 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:39:25.531377 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:39:25.594289 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:39:25.595297 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m14:39:25.716160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0d9fba10-e211-4d48-99b5-cd0b639048fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C519F01BE0>]}
[0m14:39:25.741736 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:39:25.742769 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:39:25.765316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0d9fba10-e211-4d48-99b5-cd0b639048fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C51B5652E0>]}
[0m14:39:25.765316 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:39:25.767459 [info ] [MainThread]: 
[0m14:39:25.767459 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:39:25.767459 [info ] [MainThread]: 
[0m14:39:25.768462 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:39:25.770518 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:39:25.817355 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:39:25.817355 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:39:25.818380 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:39:25.828087 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m14:39:25.829106 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:39:25.831203 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:39:25.832229 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:39:25.832229 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:39:25.840419 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:39:25.841435 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:39:25.843963 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:39:25.843963 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:39:25.844476 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:39:25.852117 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:39:25.853140 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:39:25.855683 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_application)
[0m14:39:25.855683 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:39:25.858744 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:39:25.859760 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:39:25.859760 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:39:25.867453 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:39:25.868493 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:39:25.868493 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:39:25.869516 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:39:25.869516 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:39:25.869516 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:39:25.869516 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:39:25.870538 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:39:25.870538 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:39:25.870538 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:39:25.871570 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:39:25.871570 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:39:25.872593 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_application, now create_pytorch_data_main)
[0m14:39:25.872593 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:39:25.874103 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:39:25.875107 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:39:25.875107 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:39:25.882306 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:39:25.883815 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:39:25.883815 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:39:25.883815 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:39:25.883815 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:39:25.885328 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:39:25.885328 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:39:25.885328 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:39:25.886367 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:39:25.886367 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:39:25.886367 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:39:25.886367 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:39:25.888420 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_cleansed)
[0m14:39:25.888420 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:39:25.889444 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:39:25.890469 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:39:25.890469 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:39:25.898685 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:39:25.899708 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:39:25.899708 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:39:25.900737 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:39:25.900737 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:39:25.900737 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:39:25.901763 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:39:25.901763 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:39:25.901763 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:39:25.901763 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:39:25.902791 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:39:25.902791 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:39:25.905807 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_application'
[0m14:39:25.907942 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:39:25.908964 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:39:25.908964 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:39:25.917154 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:39:25.917154 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:39:25.917154 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:39:25.933967 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:39:25.934993 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:39:25.934993 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:39:25.936000 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:39:25.938082 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_application, now list_pytorch_data_main)
[0m14:39:25.939589 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:39:25.939589 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:39:25.939589 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:39:25.947766 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:39:25.947766 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:39:25.947766 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:39:25.964572 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:39:25.965596 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:39:25.965596 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:39:25.965596 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:39:25.968139 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_cleansed)
[0m14:39:25.971260 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:39:25.971260 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:39:25.971260 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:39:25.979448 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:39:25.980471 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:39:25.980471 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:39:25.996359 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:39:25.997864 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:39:25.997864 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:39:25.998937 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:39:26.001008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0d9fba10-e211-4d48-99b5-cd0b639048fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C51B522BD0>]}
[0m14:39:26.001008 [debug] [MainThread]: Using duckdb connection "master"
[0m14:39:26.002274 [debug] [MainThread]: On master: BEGIN
[0m14:39:26.002274 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:39:26.009948 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m14:39:26.009948 [debug] [MainThread]: On master: COMMIT
[0m14:39:26.009948 [debug] [MainThread]: Using duckdb connection "master"
[0m14:39:26.010967 [debug] [MainThread]: On master: COMMIT
[0m14:39:26.010967 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:39:26.010967 [debug] [MainThread]: On master: Close
[0m14:39:26.013024 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:39:26.014029 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:39:26.014029 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:39:26.014534 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:39:26.018165 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:39:26.019168 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:39:26.036005 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:39:26.036005 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:39:26.036005 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:39:26.037023 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:39:26.045199 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m14:39:26.045199 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:39:26.045199 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:39:26.046303 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.049859 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:39:26.049859 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:39:26.049859 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.051917 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:39:26.051917 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:39:26.052943 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.059023 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:39:26.059023 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:39:26.059023 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:39:26.061090 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:39:26.063195 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:39:26.063195 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:39:26.064705 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:39:26.065725 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:39:26.086563 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0d9fba10-e211-4d48-99b5-cd0b639048fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C51B549EE0>]}
[0m14:39:26.086563 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.07s]
[0m14:39:26.087710 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:39:26.087710 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:39:26.087710 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:39:26.088874 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:39:26.088874 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:39:26.089877 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:39:26.090912 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:39:26.091928 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:39:26.092949 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:39:26.092949 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:39:26.093954 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:39:26.106756 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:39:26.106756 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:39:26.106756 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:39:26.107775 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.109861 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:39:26.109861 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:39:26.110372 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.111923 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:39:26.112946 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:39:26.112946 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.113951 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:39:26.114455 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:39:26.114455 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:39:26.115478 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:39:26.116504 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:39:26.117531 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:39:26.117531 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:39:26.118555 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:39:26.139861 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0d9fba10-e211-4d48-99b5-cd0b639048fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C51BDC4EC0>]}
[0m14:39:26.140370 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:39:26.140879 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:39:26.140879 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:39:26.141481 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:39:26.141481 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:39:26.141481 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:39:26.142504 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:39:26.144018 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:39:26.146072 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:39:26.146072 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:39:26.146072 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:39:26.147091 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:39:26.159340 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:39:26.160359 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:39:26.160359 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:39:26.160359 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.162874 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:39:26.162874 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:39:26.162874 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.164384 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:39:26.164384 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:39:26.165408 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.166434 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:39:26.166434 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:39:26.166434 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:39:26.167458 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:39:26.169501 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:39:26.169501 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:39:26.169501 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:39:26.170770 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:39:26.190938 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0d9fba10-e211-4d48-99b5-cd0b639048fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C51BCA9EB0>]}
[0m14:39:26.190938 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:39:26.191942 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:39:26.191942 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:39:26.191942 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:39:26.192994 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:39:26.192994 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:39:26.194500 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:39:26.194500 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:39:26.196546 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:39:26.196546 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:39:26.197562 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:39:26.197562 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:39:26.210344 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:39:26.210344 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:39:26.210344 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:39:26.211363 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.212873 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:39:26.212873 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:39:26.213877 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.214899 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:39:26.215925 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:39:26.215925 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.216952 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:39:26.216952 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:39:26.216952 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:39:26.218047 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:39:26.219051 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:39:26.220081 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:39:26.221177 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:39:26.221177 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:39:26.241304 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0d9fba10-e211-4d48-99b5-cd0b639048fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C51BD87A10>]}
[0m14:39:26.241304 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:39:26.242331 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:39:26.242331 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:39:26.242331 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:39:26.242331 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:39:26.243337 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:39:26.245347 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:39:26.245347 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:39:26.247382 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:39:26.248476 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:39:26.248476 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:39:26.248476 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:39:26.261636 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:39:26.261636 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:39:26.262655 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:39:26.262655 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.264166 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:39:26.265171 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:39:26.265676 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.266680 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:39:26.266680 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:39:26.267708 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.268730 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:39:26.268730 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:39:26.268730 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:39:26.269757 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:39:26.270787 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:39:26.271814 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:39:26.272840 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:39:26.272840 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:39:26.293028 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0d9fba10-e211-4d48-99b5-cd0b639048fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C51BD75130>]}
[0m14:39:26.293028 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:39:26.294033 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:39:26.294033 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:39:26.294595 [info ] [Thread-1 (]: 6 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m14:39:26.294595 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:39:26.294595 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:39:26.296684 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:39:26.296684 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:39:26.298733 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:39:26.298733 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:39:26.299758 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:39:26.299758 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:39:26.312549 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:39:26.314060 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:39:26.314060 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  main.raw_commits as rc, main.raw_contributors as c
left join rc on rc."author.id" = c.id
  );

[0m14:39:26.327892 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  main.raw_commits as rc, main.raw_contributors as c
left join rc on rc."author.id" = c.id
  );

[0m14:39:26.328908 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:39:26.328908 [debug] [Thread-1 (]: On model.archi.fcommits: ROLLBACK
[0m14:39:26.331965 [debug] [Thread-1 (]: Failed to rollback 'model.archi.fcommits'
[0m14:39:26.331965 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:39:26.335828 [debug] [Thread-1 (]: Runtime Error in model fcommits (models\application\fcommits.sql)
  Catalog Error: Table with name rc does not exist!
  Did you mean "raw_commits"?
  LINE 28: left join rc on rc."author.id" = c.id
                     ^
[0m14:39:26.335828 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0d9fba10-e211-4d48-99b5-cd0b639048fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C51BC51BE0>]}
[0m14:39:26.336337 [error] [Thread-1 (]: 6 of 7 ERROR creating sql view model main_application.fcommits ................. [[31mERROR[0m in 0.04s]
[0m14:39:26.336337 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:39:26.337364 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:39:26.337364 [debug] [Thread-4 (]: Marking all children of 'model.archi.fcommits' to be skipped because of status 'error'.  Reason: Runtime Error in model fcommits (models\application\fcommits.sql)
  Catalog Error: Table with name rc does not exist!
  Did you mean "raw_commits"?
  LINE 28: left join rc on rc."author.id" = c.id
                     ^.
[0m14:39:26.337364 [info ] [Thread-1 (]: 7 of 7 START sql view model main.view .......................................... [RUN]
[0m14:39:26.338395 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:39:26.338395 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:39:26.340582 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:39:26.341086 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:39:26.342620 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:39:26.342620 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:39:26.342620 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:39:26.342620 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:39:26.351768 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:39:26.352788 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:39:26.352788 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:39:26.353793 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.354298 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:39:26.354298 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:39:26.355869 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.356874 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:39:26.357902 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:39:26.357902 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:39:26.358928 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:39:26.358928 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:39:26.358928 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:39:26.359952 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:39:26.361999 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:39:26.361999 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:39:26.363284 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:39:26.363794 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:39:26.382602 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0d9fba10-e211-4d48-99b5-cd0b639048fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C51BCE83E0>]}
[0m14:39:26.382602 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.04s]
[0m14:39:26.384110 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:39:26.385140 [debug] [MainThread]: Using duckdb connection "master"
[0m14:39:26.385140 [debug] [MainThread]: On master: BEGIN
[0m14:39:26.385140 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:39:26.397936 [debug] [MainThread]: SQL status: OK in 0.013 seconds
[0m14:39:26.397936 [debug] [MainThread]: On master: COMMIT
[0m14:39:26.397936 [debug] [MainThread]: Using duckdb connection "master"
[0m14:39:26.398956 [debug] [MainThread]: On master: COMMIT
[0m14:39:26.398956 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:39:26.398956 [debug] [MainThread]: On master: Close
[0m14:39:26.401020 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:39:26.401020 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m14:39:26.401020 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m14:39:26.402049 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:39:26.402049 [info ] [MainThread]: 
[0m14:39:26.402049 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.63 seconds (0.63s).
[0m14:39:26.403074 [debug] [MainThread]: Command end result
[0m14:39:26.414276 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:39:26.416323 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:39:26.419414 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:39:26.419414 [info ] [MainThread]: 
[0m14:39:26.419414 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:39:26.420441 [info ] [MainThread]: 
[0m14:39:26.420441 [error] [MainThread]:   Runtime Error in model fcommits (models\application\fcommits.sql)
  Catalog Error: Table with name rc does not exist!
  Did you mean "raw_commits"?
  LINE 28: left join rc on rc."author.id" = c.id
                     ^
[0m14:39:26.420441 [info ] [MainThread]: 
[0m14:39:26.421465 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m14:39:26.421465 [debug] [MainThread]: Command `dbt build` failed at 14:39:26.421465 after 1.24 seconds
[0m14:39:26.421465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C519D5CDD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C519D5C4A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C51902DDF0>]}
[0m14:39:26.422517 [debug] [MainThread]: Flushing usage events
[0m14:39:26.911895 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:40:08.499085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002004F9006B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200501232F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020050123FB0>]}


============================== 14:40:08.502183 | 00c7c87a-b8f8-44fd-bd76-db7c9cce48fd ==============================
[0m14:40:08.502183 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:40:08.502183 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt build', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:40:08.611257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '00c7c87a-b8f8-44fd-bd76-db7c9cce48fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200514965D0>]}
[0m14:40:08.641838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '00c7c87a-b8f8-44fd-bd76-db7c9cce48fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020051495B80>]}
[0m14:40:08.643874 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:40:08.761478 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:40:08.822850 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:40:08.822850 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m14:40:08.944883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '00c7c87a-b8f8-44fd-bd76-db7c9cce48fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020051A48920>]}
[0m14:40:08.971787 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:40:08.972792 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:40:08.995573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '00c7c87a-b8f8-44fd-bd76-db7c9cce48fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020051A44E90>]}
[0m14:40:08.995573 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:40:08.997641 [info ] [MainThread]: 
[0m14:40:08.997641 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:40:08.997641 [info ] [MainThread]: 
[0m14:40:08.998698 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:40:09.000754 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:40:09.045958 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:40:09.045958 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:40:09.045958 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:40:09.056217 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m14:40:09.057248 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:40:09.060342 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:40:09.060342 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:40:09.060342 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:40:09.070047 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:40:09.070047 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:40:09.073664 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:40:09.073664 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:40:09.074191 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:40:09.082886 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:40:09.082886 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:40:09.085137 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m14:40:09.086161 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:40:09.089313 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:40:09.089313 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:40:09.089313 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:40:09.098533 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:40:09.098533 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:40:09.099624 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:40:09.099624 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:40:09.099624 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:40:09.099624 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:40:09.100654 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:40:09.100654 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:40:09.100654 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:40:09.101683 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:40:09.101683 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:40:09.101683 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:40:09.103735 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main_application)
[0m14:40:09.103735 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:40:09.105243 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:40:09.105243 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:40:09.105243 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:40:09.113892 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:40:09.114896 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:40:09.114896 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:40:09.115398 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:40:09.115398 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:40:09.115398 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:40:09.116402 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:40:09.116905 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:40:09.116905 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:40:09.116905 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:40:09.116905 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:40:09.116905 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:40:09.120011 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_application, now create_pytorch_data_main)
[0m14:40:09.120011 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:40:09.121041 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:40:09.121041 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:40:09.121041 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:40:09.130347 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:40:09.130347 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:40:09.131366 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:40:09.131366 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:40:09.131366 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:40:09.131366 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:40:09.132391 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:40:09.132391 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:40:09.133434 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:40:09.133434 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:40:09.133434 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:40:09.133434 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:40:09.136486 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m14:40:09.139547 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:40:09.140051 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:40:09.140051 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:40:09.148157 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:40:09.148157 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:40:09.148157 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:40:09.167022 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:40:09.167555 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:40:09.168576 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:40:09.168576 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:40:09.171110 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main_application)
[0m14:40:09.172128 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:40:09.173146 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:40:09.173146 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:40:09.181332 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:40:09.181332 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:40:09.182361 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:40:09.198551 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:40:09.199584 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:40:09.199584 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:40:09.199584 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:40:09.202112 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_application, now list_pytorch_data_main)
[0m14:40:09.204651 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:40:09.204651 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:40:09.204651 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:40:09.213386 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:40:09.213386 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:40:09.213386 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:40:09.231299 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:40:09.232323 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:40:09.233347 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:40:09.233347 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:40:09.236917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '00c7c87a-b8f8-44fd-bd76-db7c9cce48fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002005221A150>]}
[0m14:40:09.236917 [debug] [MainThread]: Using duckdb connection "master"
[0m14:40:09.236917 [debug] [MainThread]: On master: BEGIN
[0m14:40:09.236917 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:40:09.246085 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m14:40:09.246085 [debug] [MainThread]: On master: COMMIT
[0m14:40:09.246085 [debug] [MainThread]: Using duckdb connection "master"
[0m14:40:09.246085 [debug] [MainThread]: On master: COMMIT
[0m14:40:09.246085 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:40:09.247109 [debug] [MainThread]: On master: Close
[0m14:40:09.249188 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:40:09.250208 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:40:09.250208 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:40:09.250208 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:40:09.254774 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:40:09.255278 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:40:09.272209 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:40:09.273237 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:40:09.273237 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:40:09.273237 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:40:09.282446 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:40:09.282446 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:40:09.282446 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:40:09.283469 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.287051 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:40:09.288078 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:40:09.288078 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.290186 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:40:09.290186 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:40:09.290186 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.297296 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:40:09.297296 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:40:09.297296 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:40:09.399899 [debug] [Thread-1 (]: SQL status: OK in 0.102 seconds
[0m14:40:09.402982 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:40:09.402982 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:40:09.404494 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:40:09.406009 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:40:09.425895 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00c7c87a-b8f8-44fd-bd76-db7c9cce48fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200514CEBA0>]}
[0m14:40:09.426923 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.17s]
[0m14:40:09.426923 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:40:09.427964 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:40:09.427964 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:40:09.427964 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:40:09.429000 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:40:09.430021 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:40:09.431041 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:40:09.432072 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:40:09.433341 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:40:09.433341 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:40:09.433341 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:40:09.446686 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:40:09.446686 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:40:09.446686 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:40:09.447707 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.449742 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:40:09.449742 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:40:09.449742 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.451777 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:40:09.452782 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:40:09.452782 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.452782 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:40:09.454126 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:40:09.454126 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:40:09.455642 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:40:09.456665 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:40:09.456665 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:40:09.457778 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:40:09.458783 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:40:09.477788 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00c7c87a-b8f8-44fd-bd76-db7c9cce48fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002005224BB90>]}
[0m14:40:09.478814 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:40:09.478814 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:40:09.479838 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:40:09.479838 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:40:09.479838 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:40:09.480874 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:40:09.481899 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:40:09.481899 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:40:09.483407 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:40:09.484918 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:40:09.484918 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:40:09.484918 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:40:09.498289 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:40:09.498289 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:40:09.499310 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:40:09.499310 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.501354 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:40:09.501354 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:40:09.502375 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.503884 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:40:09.503884 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:40:09.503884 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.505391 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:40:09.505391 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:40:09.505391 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:40:09.507437 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:40:09.508463 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:40:09.508463 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:40:09.509487 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:40:09.510509 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:40:09.529298 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00c7c87a-b8f8-44fd-bd76-db7c9cce48fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200520DA2A0>]}
[0m14:40:09.530323 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:40:09.530323 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:40:09.530323 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:40:09.531346 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:40:09.531346 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:40:09.531346 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:40:09.533390 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:40:09.533390 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:40:09.534964 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:40:09.536411 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:40:09.536411 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:40:09.536411 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:40:09.548667 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:40:09.549670 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:40:09.549670 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:40:09.550722 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.552231 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:40:09.552231 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:40:09.552231 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.553235 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:40:09.554744 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:40:09.554744 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.555789 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:40:09.555789 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:40:09.555789 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:40:09.557838 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:40:09.558876 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:40:09.558876 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:40:09.559881 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:40:09.560385 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:40:09.578643 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00c7c87a-b8f8-44fd-bd76-db7c9cce48fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000200532ABD40>]}
[0m14:40:09.580222 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:40:09.580222 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:40:09.581225 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:40:09.581225 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:40:09.581225 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:40:09.582252 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:40:09.583270 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:40:09.584778 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:40:09.585782 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:40:09.586835 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:40:09.586835 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:40:09.586835 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:40:09.600545 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:40:09.601049 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:40:09.601049 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:40:09.601049 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.603092 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:40:09.603092 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:40:09.603092 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.605629 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:40:09.606151 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:40:09.606689 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.606689 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:40:09.607710 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:40:09.607710 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:40:09.608734 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:40:09.609757 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:40:09.610761 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:40:09.611318 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:40:09.612323 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:40:09.631705 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00c7c87a-b8f8-44fd-bd76-db7c9cce48fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002005222D7C0>]}
[0m14:40:09.631705 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:40:09.632724 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:40:09.632724 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:40:09.633755 [info ] [Thread-1 (]: 6 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m14:40:09.633755 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:40:09.633755 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:40:09.635262 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:40:09.636284 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:40:09.637335 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:40:09.638370 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:40:09.638370 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:40:09.638370 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:40:09.651677 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:40:09.651677 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:40:09.652181 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits, raw_contributors
left join commits on raw_commits."author.id" = raw_contributors.id
  );

[0m14:40:09.652181 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits, raw_contributors
left join commits on raw_commits."author.id" = raw_contributors.id
  );

[0m14:40:09.653203 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:40:09.653203 [debug] [Thread-1 (]: On model.archi.fcommits: ROLLBACK
[0m14:40:09.655748 [debug] [Thread-1 (]: Failed to rollback 'model.archi.fcommits'
[0m14:40:09.656777 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:40:09.659945 [debug] [Thread-1 (]: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:40:09.659945 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00c7c87a-b8f8-44fd-bd76-db7c9cce48fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020052239430>]}
[0m14:40:09.659945 [error] [Thread-1 (]: 6 of 7 ERROR creating sql view model main_application.fcommits ................. [[31mERROR[0m in 0.03s]
[0m14:40:09.660961 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:40:09.660961 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:40:09.660961 [debug] [Thread-4 (]: Marking all children of 'model.archi.fcommits' to be skipped because of status 'error'.  Reason: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema).
[0m14:40:09.661966 [info ] [Thread-1 (]: 7 of 7 START sql view model main.view .......................................... [RUN]
[0m14:40:09.662470 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:40:09.662470 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:40:09.663494 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:40:09.663494 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:40:09.666034 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:40:09.667058 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:40:09.667058 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:40:09.667582 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:40:09.675241 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m14:40:09.676264 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:40:09.676264 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:40:09.677286 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.678329 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:40:09.678329 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:40:09.679345 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.680367 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:40:09.681382 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:40:09.681382 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:40:09.682387 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:40:09.682890 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:40:09.682890 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:40:09.683912 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:40:09.685421 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:40:09.685421 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:40:09.686443 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:40:09.687472 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:40:09.705912 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '00c7c87a-b8f8-44fd-bd76-db7c9cce48fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002005221B020>]}
[0m14:40:09.705912 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.04s]
[0m14:40:09.706943 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:40:09.706943 [debug] [MainThread]: Using duckdb connection "master"
[0m14:40:09.708107 [debug] [MainThread]: On master: BEGIN
[0m14:40:09.708107 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:40:09.720323 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m14:40:09.720323 [debug] [MainThread]: On master: COMMIT
[0m14:40:09.721357 [debug] [MainThread]: Using duckdb connection "master"
[0m14:40:09.721357 [debug] [MainThread]: On master: COMMIT
[0m14:40:09.721357 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:40:09.721357 [debug] [MainThread]: On master: Close
[0m14:40:09.723909 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:40:09.723909 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m14:40:09.723909 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m14:40:09.723909 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:40:09.724913 [info ] [MainThread]: 
[0m14:40:09.725416 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.73 seconds (0.73s).
[0m14:40:09.725416 [debug] [MainThread]: Command end result
[0m14:40:09.737134 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:40:09.738286 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:40:09.741305 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:40:09.742310 [info ] [MainThread]: 
[0m14:40:09.742310 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:40:09.742310 [info ] [MainThread]: 
[0m14:40:09.742310 [error] [MainThread]:   Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:40:09.743627 [info ] [MainThread]: 
[0m14:40:09.743627 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m14:40:09.744633 [debug] [MainThread]: Command `dbt build` failed at 14:40:09.744633 after 1.33 seconds
[0m14:40:09.744633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002004FC8AFF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002004CBEFC50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002004FFCFFE0>]}
[0m14:40:09.745136 [debug] [MainThread]: Flushing usage events
[0m14:40:10.209237 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:42:54.149077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020887FB06B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020887AA5FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020885BFA330>]}


============================== 14:42:54.152615 | a70dc2d0-91cf-404d-a958-f267767a17a8 ==============================
[0m14:42:54.152615 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:42:54.153141 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:42:54.264055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a70dc2d0-91cf-404d-a958-f267767a17a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020888A6A900>]}
[0m14:42:54.293407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a70dc2d0-91cf-404d-a958-f267767a17a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002088844E120>]}
[0m14:42:54.296968 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:42:54.415097 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:42:54.476204 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:42:54.476204 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m14:42:54.599009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a70dc2d0-91cf-404d-a958-f267767a17a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002088A1186B0>]}
[0m14:42:54.685353 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:42:54.686360 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:42:54.709467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a70dc2d0-91cf-404d-a958-f267767a17a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002088A0F9A90>]}
[0m14:42:54.709467 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:42:54.710494 [info ] [MainThread]: 
[0m14:42:54.711780 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:42:54.711780 [info ] [MainThread]: 
[0m14:42:54.711780 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:42:54.714867 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:42:54.757779 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:42:54.758283 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:42:54.758283 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:42:54.768440 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m14:42:54.769500 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:42:54.771534 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:42:54.772564 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:42:54.772564 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:42:54.781210 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:42:54.782215 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:42:54.784262 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:42:54.784262 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:42:54.785338 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:42:54.793003 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:42:54.794024 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:42:54.796556 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_application)
[0m14:42:54.796556 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:42:54.800082 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:42:54.800082 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:42:54.800082 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:42:54.808277 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:42:54.809313 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:42:54.809313 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:42:54.810335 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:42:54.810335 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:42:54.810335 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:42:54.810335 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:42:54.811358 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:42:54.811358 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:42:54.811358 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:42:54.812382 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:42:54.812382 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:42:54.814434 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_application, now create_pytorch_data_main_cleansed)
[0m14:42:54.814434 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:42:54.814434 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:42:54.815940 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:42:54.815940 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:42:54.823799 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:42:54.824827 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:42:54.824827 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:42:54.825848 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:42:54.825848 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:42:54.825848 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:42:54.825848 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:42:54.826870 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:42:54.826870 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:42:54.826870 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:42:54.827874 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:42:54.828378 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:42:54.829429 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main)
[0m14:42:54.830458 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:42:54.831553 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:42:54.831553 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:42:54.831553 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:42:54.840278 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:42:54.840278 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:42:54.840278 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:42:54.840278 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:42:54.841792 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:42:54.841792 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:42:54.841792 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:42:54.842834 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:42:54.842834 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:42:54.842834 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:42:54.842834 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:42:54.843865 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:42:54.845926 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_application'
[0m14:42:54.848518 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:42:54.849544 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:42:54.849544 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:42:54.857693 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:42:54.857693 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:42:54.857693 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:42:54.874953 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:42:54.874953 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:42:54.875984 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:42:54.875984 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:42:54.878579 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_application, now list_pytorch_data_main_cleansed)
[0m14:42:54.880120 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:42:54.880120 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:42:54.880647 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:42:54.887758 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:42:54.888794 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:42:54.888794 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:42:54.904716 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:42:54.905732 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:42:54.905732 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:42:54.905732 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:42:54.908261 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main)
[0m14:42:54.910822 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:42:54.911347 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:42:54.911347 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:42:54.919448 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:42:54.919448 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:42:54.919448 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:42:54.935733 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:42:54.936766 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:42:54.937772 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:42:54.937772 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:42:54.940344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a70dc2d0-91cf-404d-a958-f267767a17a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002088A8E6E40>]}
[0m14:42:54.941359 [debug] [MainThread]: Using duckdb connection "master"
[0m14:42:54.941359 [debug] [MainThread]: On master: BEGIN
[0m14:42:54.941359 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:42:54.949473 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m14:42:54.949473 [debug] [MainThread]: On master: COMMIT
[0m14:42:54.949473 [debug] [MainThread]: Using duckdb connection "master"
[0m14:42:54.950495 [debug] [MainThread]: On master: COMMIT
[0m14:42:54.950495 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:42:54.950495 [debug] [MainThread]: On master: Close
[0m14:42:54.952598 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:42:54.952598 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:42:54.954107 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:42:54.954107 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:42:54.957741 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:42:54.958766 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:42:54.975244 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:42:54.976267 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:42:54.976267 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:42:54.976267 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:42:54.985424 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:42:54.985424 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:42:54.985424 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:42:54.986443 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:54.989525 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:42:54.990555 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:42:54.990555 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:54.992601 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:42:54.992601 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:42:54.992601 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:54.999190 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:42:54.999190 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:42:55.000213 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:42:55.101247 [debug] [Thread-1 (]: SQL status: OK in 0.101 seconds
[0m14:42:55.104865 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:42:55.105394 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:42:55.106414 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:42:55.107925 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:42:55.128397 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a70dc2d0-91cf-404d-a958-f267767a17a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020887EE48F0>]}
[0m14:42:55.128397 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.17s]
[0m14:42:55.129418 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:42:55.129418 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:42:55.129418 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:42:55.130440 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:42:55.130440 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:42:55.131463 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:42:55.132486 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:42:55.134552 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:42:55.134552 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:42:55.134552 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:42:55.134552 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:42:55.147750 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:42:55.147750 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:42:55.148787 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:42:55.148787 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.150841 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:42:55.150841 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:42:55.150841 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.153376 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:42:55.153376 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:42:55.154406 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.154406 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:42:55.155432 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:42:55.155432 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:42:55.156436 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:42:55.157562 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:42:55.157562 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:42:55.158566 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:42:55.159595 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:42:55.179031 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a70dc2d0-91cf-404d-a958-f267767a17a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002088B914EC0>]}
[0m14:42:55.180059 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:42:55.180059 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:42:55.180059 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:42:55.181204 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:42:55.181204 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:42:55.181204 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:42:55.182713 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:42:55.183740 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:42:55.184768 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:42:55.185794 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:42:55.185794 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:42:55.185794 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:42:55.198564 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:42:55.198564 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:42:55.198564 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:42:55.199585 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.201633 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:42:55.201633 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:42:55.201633 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.203740 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:42:55.203740 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:42:55.203740 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.204773 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:42:55.204773 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:42:55.205800 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:42:55.206823 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:42:55.207829 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:42:55.208334 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:42:55.209357 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:42:55.209357 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:42:55.231137 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a70dc2d0-91cf-404d-a958-f267767a17a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002088A84B590>]}
[0m14:42:55.231137 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:42:55.232157 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:42:55.232157 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:42:55.232157 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:42:55.233166 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:42:55.233166 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:42:55.234761 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:42:55.234761 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:42:55.236812 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:42:55.237817 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:42:55.237817 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:42:55.238324 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:42:55.250671 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:42:55.250671 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:42:55.250671 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:42:55.251695 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.253732 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:42:55.254239 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:42:55.254239 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.255264 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:42:55.256290 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:42:55.256290 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.256290 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:42:55.257798 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:42:55.257798 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:42:55.259360 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:42:55.259895 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:42:55.259895 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:42:55.260922 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:42:55.261943 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:42:55.281392 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a70dc2d0-91cf-404d-a958-f267767a17a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002088A8F9B20>]}
[0m14:42:55.281392 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:42:55.282418 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:42:55.282418 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:42:55.282418 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:42:55.283462 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:42:55.283462 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:42:55.286000 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:42:55.286000 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:42:55.287510 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:42:55.288537 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:42:55.288537 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:42:55.288537 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:42:55.301403 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:42:55.301403 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:42:55.302427 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:42:55.302427 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.303452 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:42:55.304959 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:42:55.304959 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.306008 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:42:55.306008 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:42:55.307517 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.307517 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:42:55.308541 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:42:55.308541 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:42:55.309567 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:42:55.310679 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:42:55.310679 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:42:55.311683 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:42:55.312709 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:42:55.333117 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a70dc2d0-91cf-404d-a958-f267767a17a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020889F775C0>]}
[0m14:42:55.333117 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:42:55.334142 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:42:55.334142 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:42:55.334142 [info ] [Thread-1 (]: 6 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m14:42:55.334142 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:42:55.334142 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:42:55.336165 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:42:55.337169 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:42:55.338679 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:42:55.339184 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:42:55.339184 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:42:55.340189 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:42:55.351927 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:42:55.352944 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:42:55.352944 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits, raw_contributors
left join commits on raw_contributors.id = raw_commits."author.id"
  );

[0m14:42:55.353958 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits, raw_contributors
left join commits on raw_contributors.id = raw_commits."author.id"
  );

[0m14:42:55.353958 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:42:55.353958 [debug] [Thread-1 (]: On model.archi.fcommits: ROLLBACK
[0m14:42:55.356498 [debug] [Thread-1 (]: Failed to rollback 'model.archi.fcommits'
[0m14:42:55.357501 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:42:55.360668 [debug] [Thread-1 (]: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:42:55.360668 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a70dc2d0-91cf-404d-a958-f267767a17a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002088A921340>]}
[0m14:42:55.360668 [error] [Thread-1 (]: 6 of 7 ERROR creating sql view model main_application.fcommits ................. [[31mERROR[0m in 0.03s]
[0m14:42:55.361673 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:42:55.362179 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:42:55.362179 [debug] [Thread-4 (]: Marking all children of 'model.archi.fcommits' to be skipped because of status 'error'.  Reason: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema).
[0m14:42:55.362179 [info ] [Thread-1 (]: 7 of 7 START sql view model main.view .......................................... [RUN]
[0m14:42:55.363182 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:42:55.363182 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:42:55.364209 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:42:55.365230 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:42:55.366738 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:42:55.367744 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:42:55.367744 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:42:55.368247 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:42:55.375471 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m14:42:55.376474 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:42:55.376979 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:42:55.377488 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.378494 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:42:55.378494 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:42:55.379658 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.380687 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:42:55.380687 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:42:55.381711 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:42:55.382769 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:42:55.382769 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:42:55.382769 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:42:55.383790 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:42:55.384815 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:42:55.385839 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:42:55.386843 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:42:55.387348 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:42:55.405767 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a70dc2d0-91cf-404d-a958-f267767a17a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002088B9734D0>]}
[0m14:42:55.407278 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.04s]
[0m14:42:55.407789 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:42:55.408297 [debug] [MainThread]: Using duckdb connection "master"
[0m14:42:55.408297 [debug] [MainThread]: On master: BEGIN
[0m14:42:55.408297 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:42:55.421158 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m14:42:55.421158 [debug] [MainThread]: On master: COMMIT
[0m14:42:55.422180 [debug] [MainThread]: Using duckdb connection "master"
[0m14:42:55.422180 [debug] [MainThread]: On master: COMMIT
[0m14:42:55.422180 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:42:55.422180 [debug] [MainThread]: On master: Close
[0m14:42:55.424255 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:42:55.424255 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m14:42:55.424255 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m14:42:55.425285 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:42:55.425285 [info ] [MainThread]: 
[0m14:42:55.425285 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.71 seconds (0.71s).
[0m14:42:55.426310 [debug] [MainThread]: Command end result
[0m14:42:55.438094 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:42:55.439099 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:42:55.442173 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:42:55.442173 [info ] [MainThread]: 
[0m14:42:55.443192 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:42:55.443731 [info ] [MainThread]: 
[0m14:42:55.444256 [error] [MainThread]:   Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:42:55.444256 [info ] [MainThread]: 
[0m14:42:55.444256 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m14:42:55.445282 [debug] [MainThread]: Command `dbt build` failed at 14:42:55.445282 after 1.38 seconds
[0m14:42:55.445282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000208880085C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002088854F1A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002088854ED20>]}
[0m14:42:55.445282 [debug] [MainThread]: Flushing usage events
[0m14:42:55.913983 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:45:10.511213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00A7F54F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00D445880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00D4464B0>]}


============================== 14:45:10.513277 | 183496cc-1f05-4633-82f2-11658b9375a4 ==============================
[0m14:45:10.513277 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:45:10.514306 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt build', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:45:10.624105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '183496cc-1f05-4633-82f2-11658b9375a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00DD03740>]}
[0m14:45:10.654813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '183496cc-1f05-4633-82f2-11658b9375a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00DD947D0>]}
[0m14:45:10.656848 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:45:10.775785 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:45:10.840595 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:45:10.841624 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m14:45:10.968852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '183496cc-1f05-4633-82f2-11658b9375a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00F6F8800>]}
[0m14:45:10.996373 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:45:10.997452 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:45:11.020222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '183496cc-1f05-4633-82f2-11658b9375a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00F7E2780>]}
[0m14:45:11.021408 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:45:11.022433 [info ] [MainThread]: 
[0m14:45:11.022433 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:45:11.022433 [info ] [MainThread]: 
[0m14:45:11.023460 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:45:11.026000 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:45:11.070080 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:45:11.070601 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:45:11.070601 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:45:11.080906 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m14:45:11.081412 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:45:11.084506 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:45:11.084506 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:45:11.085527 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:11.093677 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:45:11.094705 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:45:11.096733 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:45:11.097881 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:45:11.097881 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:11.105552 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:45:11.107061 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:45:11.109133 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m14:45:11.109133 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:45:11.112766 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:45:11.113795 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:45:11.113795 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:11.121961 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:45:11.121961 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:45:11.123184 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:45:11.123184 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:11.123184 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:45:11.124226 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:45:11.124226 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:11.124226 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:45:11.125258 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:45:11.125258 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:45:11.125258 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:11.125258 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:45:11.127812 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_application)
[0m14:45:11.127812 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:45:11.128859 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:45:11.129872 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:45:11.129872 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:11.137966 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:45:11.138990 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:45:11.138990 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:45:11.139995 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:11.139995 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:45:11.139995 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:45:11.140499 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:11.140499 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:45:11.141524 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:45:11.141524 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:45:11.141524 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:11.141524 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:45:11.144253 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_application, now create_pytorch_data_main_cleansed)
[0m14:45:11.144762 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:45:11.145787 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:45:11.145787 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:45:11.145787 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:11.154381 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:45:11.155425 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:45:11.155425 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:45:11.156447 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:11.156447 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:45:11.156447 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:45:11.156447 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:11.157474 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:45:11.157474 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:45:11.157474 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:45:11.158479 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:11.158479 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:45:11.161105 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m14:45:11.163665 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:45:11.164668 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:45:11.164668 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:45:11.172788 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:45:11.173373 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:45:11.173373 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:45:11.191691 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m14:45:11.192733 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:45:11.192733 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:45:11.193739 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:45:11.196265 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_application)
[0m14:45:11.197297 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:45:11.198327 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:45:11.198327 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:11.207189 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:45:11.207189 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:45:11.207189 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:45:11.223032 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:45:11.224543 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:45:11.225572 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:45:11.225572 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:45:11.227752 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_application, now list_pytorch_data_main_cleansed)
[0m14:45:11.230302 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:45:11.230302 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:45:11.230302 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:11.239095 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:45:11.239095 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:45:11.239095 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:45:11.256016 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:45:11.257022 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:45:11.257022 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:45:11.257022 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:45:11.260593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '183496cc-1f05-4633-82f2-11658b9375a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00F56DDC0>]}
[0m14:45:11.260593 [debug] [MainThread]: Using duckdb connection "master"
[0m14:45:11.261626 [debug] [MainThread]: On master: BEGIN
[0m14:45:11.261626 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:45:11.270272 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m14:45:11.270775 [debug] [MainThread]: On master: COMMIT
[0m14:45:11.270775 [debug] [MainThread]: Using duckdb connection "master"
[0m14:45:11.270775 [debug] [MainThread]: On master: COMMIT
[0m14:45:11.271796 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:45:11.271796 [debug] [MainThread]: On master: Close
[0m14:45:11.274882 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:45:11.274882 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:45:11.275887 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:45:11.275887 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:45:11.279918 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:45:11.279918 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:45:11.297353 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:45:11.298387 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:45:11.298387 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:45:11.298387 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:45:11.307567 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:45:11.308585 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:45:11.308585 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:45:11.308585 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.313208 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:45:11.313208 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:45:11.313208 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.315260 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:45:11.315260 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:45:11.315260 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.323414 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:45:11.323414 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:45:11.323414 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:45:11.431116 [debug] [Thread-1 (]: SQL status: OK in 0.107 seconds
[0m14:45:11.433645 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:45:11.433645 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:45:11.434668 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:11.436714 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:45:11.457178 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183496cc-1f05-4633-82f2-11658b9375a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00F26D100>]}
[0m14:45:11.457178 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.18s]
[0m14:45:11.458488 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:45:11.458488 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:45:11.458488 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:45:11.458488 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:45:11.459999 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:45:11.461028 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:45:11.461028 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:45:11.463085 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:45:11.464111 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:45:11.464111 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:45:11.464111 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:45:11.477440 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:45:11.477440 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:45:11.477440 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:45:11.478951 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.481505 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:45:11.481505 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:45:11.481505 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.484684 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:45:11.484684 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:45:11.484684 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.485689 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:45:11.485689 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:45:11.486724 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:45:11.487753 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:11.489264 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:45:11.490270 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:45:11.490774 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:11.491817 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:45:11.512351 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183496cc-1f05-4633-82f2-11658b9375a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00FF14EC0>]}
[0m14:45:11.513384 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:45:11.514411 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:45:11.514411 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:45:11.515440 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:45:11.515494 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:45:11.515494 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:45:11.517524 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:45:11.517524 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:45:11.520054 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:45:11.521088 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:45:11.521088 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:45:11.521615 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:45:11.534542 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:45:11.534542 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:45:11.534542 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:45:11.536050 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.537083 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:45:11.538107 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:45:11.538107 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.540137 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:45:11.540642 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:45:11.540642 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.541669 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:45:11.542201 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:45:11.542201 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:45:11.543763 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:11.544785 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:45:11.544785 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:45:11.546368 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:11.546878 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:45:11.566735 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183496cc-1f05-4633-82f2-11658b9375a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00FDAFAA0>]}
[0m14:45:11.566735 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:45:11.568245 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:45:11.568245 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:45:11.568245 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:45:11.569268 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:45:11.569268 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:45:11.570777 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:45:11.570777 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:45:11.572806 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:45:11.573310 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:45:11.573310 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:45:11.574316 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:45:11.587049 [debug] [Thread-1 (]: SQL status: OK in 0.014 seconds
[0m14:45:11.588072 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:45:11.588072 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:45:11.589100 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.590610 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:45:11.590610 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:45:11.591632 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.592728 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:45:11.593257 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:45:11.593790 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.594814 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:45:11.594814 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:45:11.594814 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:45:11.595842 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:11.597352 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:45:11.597352 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:45:11.598378 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:11.599888 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:45:11.619889 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183496cc-1f05-4633-82f2-11658b9375a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00FED7DA0>]}
[0m14:45:11.619889 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:45:11.620917 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:45:11.620917 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:45:11.620917 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:45:11.621944 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:45:11.621944 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:45:11.624167 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:45:11.624167 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:45:11.626337 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:45:11.626337 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:45:11.627364 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:45:11.627364 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:45:11.640071 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:45:11.640575 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:45:11.640575 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:45:11.641593 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.642616 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:45:11.643622 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:45:11.643622 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.645186 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:45:11.645186 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:45:11.646202 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.646202 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:45:11.647224 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:45:11.647224 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:45:11.648248 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:11.650294 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:45:11.650294 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:45:11.650798 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:11.651871 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:45:11.672742 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183496cc-1f05-4633-82f2-11658b9375a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00FED79B0>]}
[0m14:45:11.672742 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:45:11.672742 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:45:11.674255 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:45:11.674255 [info ] [Thread-1 (]: 6 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m14:45:11.674255 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:45:11.675312 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:45:11.676355 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:45:11.676355 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:45:11.678428 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:45:11.678428 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:45:11.678428 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:45:11.679940 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:45:11.691611 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:45:11.692640 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:45:11.692640 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits
left join commits on raw_contributors.id = raw_commits."author.id"
  );

[0m14:45:11.693665 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits
left join commits on raw_contributors.id = raw_commits."author.id"
  );

[0m14:45:11.693665 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:45:11.693665 [debug] [Thread-1 (]: On model.archi.fcommits: ROLLBACK
[0m14:45:11.697236 [debug] [Thread-1 (]: Failed to rollback 'model.archi.fcommits'
[0m14:45:11.697236 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:45:11.700290 [debug] [Thread-1 (]: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:45:11.700290 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183496cc-1f05-4633-82f2-11658b9375a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00FDFFC20>]}
[0m14:45:11.701367 [error] [Thread-1 (]: 6 of 7 ERROR creating sql view model main_application.fcommits ................. [[31mERROR[0m in 0.03s]
[0m14:45:11.701367 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:45:11.701367 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:45:11.702393 [debug] [Thread-4 (]: Marking all children of 'model.archi.fcommits' to be skipped because of status 'error'.  Reason: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema).
[0m14:45:11.702393 [info ] [Thread-1 (]: 7 of 7 START sql view model main.view .......................................... [RUN]
[0m14:45:11.702393 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:45:11.703421 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:45:11.704930 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:45:11.704930 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:45:11.706981 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:45:11.706981 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:45:11.707998 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:45:11.707998 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:45:11.716176 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m14:45:11.716176 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:45:11.717181 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:45:11.717181 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.719229 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:45:11.719229 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:45:11.720235 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.721768 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:45:11.721768 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:45:11.721768 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:11.722792 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:45:11.722792 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:45:11.723832 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:45:11.723832 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:11.726348 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:45:11.726348 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:45:11.727571 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:11.728599 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:45:11.747050 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183496cc-1f05-4633-82f2-11658b9375a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F010F0C500>]}
[0m14:45:11.748075 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.04s]
[0m14:45:11.748075 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:45:11.749092 [debug] [MainThread]: Using duckdb connection "master"
[0m14:45:11.749092 [debug] [MainThread]: On master: BEGIN
[0m14:45:11.749092 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:45:11.761363 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m14:45:11.762417 [debug] [MainThread]: On master: COMMIT
[0m14:45:11.762417 [debug] [MainThread]: Using duckdb connection "master"
[0m14:45:11.762417 [debug] [MainThread]: On master: COMMIT
[0m14:45:11.762417 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:45:11.763451 [debug] [MainThread]: On master: Close
[0m14:45:11.764479 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:45:11.765510 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m14:45:11.765510 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m14:45:11.765510 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:45:11.765510 [info ] [MainThread]: 
[0m14:45:11.766515 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.74 seconds (0.74s).
[0m14:45:11.767527 [debug] [MainThread]: Command end result
[0m14:45:11.777824 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:45:11.778857 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:45:11.782407 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:45:11.782407 [info ] [MainThread]: 
[0m14:45:11.783441 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:45:11.783441 [info ] [MainThread]: 
[0m14:45:11.783441 [error] [MainThread]:   Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:45:11.784465 [info ] [MainThread]: 
[0m14:45:11.784465 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m14:45:11.785498 [debug] [MainThread]: Command `dbt build` failed at 14:45:11.785498 after 1.36 seconds
[0m14:45:11.785498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00A92A240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00DF4D2E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F00A7F54F0>]}
[0m14:45:11.785498 [debug] [MainThread]: Flushing usage events
[0m14:45:12.286418 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:45:45.779603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEEFE386B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEEFB67EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEEFB67350>]}


============================== 14:45:45.782381 | 183bdb1c-6a08-49f2-be7c-ca7fec134fcc ==============================
[0m14:45:45.782381 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:45:45.782381 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:45:45.894386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '183bdb1c-6a08-49f2-be7c-ca7fec134fcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEF06B6CF0>]}
[0m14:45:45.925902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '183bdb1c-6a08-49f2-be7c-ca7fec134fcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEEF738890>]}
[0m14:45:45.927934 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:45:46.047738 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:45:46.111905 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:45:46.112410 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m14:45:46.236463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '183bdb1c-6a08-49f2-be7c-ca7fec134fcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEF1CF3CE0>]}
[0m14:45:46.263020 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:45:46.264102 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:45:46.287182 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '183bdb1c-6a08-49f2-be7c-ca7fec134fcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEF1D30950>]}
[0m14:45:46.287182 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:45:46.288263 [info ] [MainThread]: 
[0m14:45:46.288263 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:45:46.289283 [info ] [MainThread]: 
[0m14:45:46.289283 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:45:46.292859 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:45:46.335808 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:45:46.336833 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:45:46.336833 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:45:46.347113 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m14:45:46.347113 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:45:46.351232 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:45:46.351232 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:45:46.351232 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:46.360981 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:45:46.361485 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:45:46.363540 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:45:46.364566 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:45:46.364566 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:46.372778 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:45:46.373823 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:45:46.375880 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m14:45:46.376417 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:45:46.379488 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:45:46.380564 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:45:46.380564 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:46.388262 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:45:46.389777 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:45:46.389777 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:45:46.389777 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:46.389777 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:45:46.390786 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:45:46.390786 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:46.391294 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:45:46.391294 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:45:46.391294 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:45:46.392326 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:46.392326 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:45:46.394385 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_application)
[0m14:45:46.394385 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:45:46.395408 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:45:46.395408 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:45:46.396496 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:46.404795 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:45:46.405815 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:45:46.405815 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:45:46.405815 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:46.405815 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:45:46.406838 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:45:46.406838 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:46.407363 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:45:46.407884 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:45:46.407884 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:45:46.407884 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:46.407884 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:45:46.410416 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_application, now create_pytorch_data_main_cleansed)
[0m14:45:46.410924 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:45:46.411928 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:45:46.411928 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:45:46.411928 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:46.420714 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:45:46.420714 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:45:46.421796 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:45:46.421796 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:46.421796 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:45:46.421796 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:45:46.422824 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:46.422824 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:45:46.423847 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:45:46.423847 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:45:46.423847 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:46.423847 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:45:46.426924 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m14:45:46.429019 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:45:46.429019 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:45:46.430536 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:45:46.438290 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:45:46.438820 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:45:46.438820 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:45:46.455762 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:45:46.456791 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:45:46.457818 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:45:46.457818 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:45:46.460329 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_application)
[0m14:45:46.461348 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:45:46.461348 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:45:46.461348 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:46.470474 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:45:46.470982 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:45:46.470982 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:45:46.487280 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:45:46.488299 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:45:46.489401 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:45:46.489401 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:45:46.490911 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_application, now list_pytorch_data_main_cleansed)
[0m14:45:46.493451 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:45:46.493451 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:45:46.494488 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:46.502125 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:45:46.502125 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:45:46.502125 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:45:46.519940 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:45:46.521173 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:45:46.521173 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:45:46.521173 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:45:46.525795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '183bdb1c-6a08-49f2-be7c-ca7fec134fcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEF1CC32C0>]}
[0m14:45:46.525795 [debug] [MainThread]: Using duckdb connection "master"
[0m14:45:46.525795 [debug] [MainThread]: On master: BEGIN
[0m14:45:46.525795 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:45:46.536208 [debug] [MainThread]: SQL status: OK in 0.010 seconds
[0m14:45:46.536208 [debug] [MainThread]: On master: COMMIT
[0m14:45:46.536208 [debug] [MainThread]: Using duckdb connection "master"
[0m14:45:46.536208 [debug] [MainThread]: On master: COMMIT
[0m14:45:46.537234 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:45:46.537234 [debug] [MainThread]: On master: Close
[0m14:45:46.540404 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:45:46.540404 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:45:46.540913 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:45:46.540913 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:45:46.544930 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:45:46.544930 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:45:46.562781 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:45:46.562781 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:45:46.562781 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:45:46.563810 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:45:46.572010 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:45:46.573041 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:45:46.573041 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:45:46.573041 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.576625 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:45:46.576625 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:45:46.577661 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.578693 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:45:46.578693 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:45:46.579723 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.585829 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:45:46.585829 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:45:46.586860 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:45:46.688373 [debug] [Thread-1 (]: SQL status: OK in 0.101 seconds
[0m14:45:46.690926 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:45:46.690926 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:45:46.691982 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:46.693549 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:45:46.718105 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183bdb1c-6a08-49f2-be7c-ca7fec134fcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEF1CEA1B0>]}
[0m14:45:46.719226 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.18s]
[0m14:45:46.719226 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:45:46.719226 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:45:46.720229 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:45:46.720739 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:45:46.720739 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:45:46.722276 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:45:46.722276 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:45:46.724810 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:45:46.724810 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:45:46.724810 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:45:46.725814 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:45:46.738050 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:45:46.738050 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:45:46.739081 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:45:46.739081 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.740597 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:45:46.741629 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:45:46.741629 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.743691 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:45:46.743691 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:45:46.744699 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.745208 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:45:46.745208 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:45:46.746215 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:45:46.747242 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:46.748274 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:45:46.748274 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:45:46.749304 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:46.750313 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:45:46.769438 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183bdb1c-6a08-49f2-be7c-ca7fec134fcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEF255F350>]}
[0m14:45:46.769438 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:45:46.769438 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:45:46.770948 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:45:46.770948 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:45:46.770948 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:45:46.770948 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:45:46.772996 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:45:46.772996 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:45:46.775054 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:45:46.775587 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:45:46.776109 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:45:46.776109 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:45:46.789529 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:45:46.789529 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:45:46.789529 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:45:46.790537 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.792080 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:45:46.792080 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:45:46.793117 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.794161 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:45:46.794161 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:45:46.795197 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.795197 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:45:46.796331 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:45:46.796331 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:45:46.797337 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:46.798371 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:45:46.799409 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:45:46.799409 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:46.800924 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:45:46.819953 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183bdb1c-6a08-49f2-be7c-ca7fec134fcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEF23E78F0>]}
[0m14:45:46.819953 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:45:46.820961 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:45:46.821465 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:45:46.821973 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:45:46.821973 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:45:46.822487 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:45:46.823531 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:45:46.824549 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:45:46.825603 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:45:46.826624 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:45:46.827200 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:45:46.827200 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:45:46.839990 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:45:46.839990 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:45:46.839990 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:45:46.841506 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.842537 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:45:46.842537 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:45:46.843594 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.844629 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:45:46.845663 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:45:46.845663 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.846693 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:45:46.846693 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:45:46.846693 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:45:46.848207 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:46.849213 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:45:46.849213 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:45:46.850730 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:46.851762 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:45:46.870708 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183bdb1c-6a08-49f2-be7c-ca7fec134fcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEF2530E30>]}
[0m14:45:46.871740 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:45:46.871740 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:45:46.872768 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:45:46.872768 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:45:46.872768 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:45:46.873843 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:45:46.875870 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:45:46.875870 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:45:46.877902 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:45:46.878942 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:45:46.878942 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:45:46.878942 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:45:46.891777 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:45:46.891777 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:45:46.892820 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:45:46.892820 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.894335 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:45:46.895367 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:45:46.895367 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.896402 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:45:46.897436 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:45:46.897436 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.898486 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:45:46.899012 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:45:46.899012 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:45:46.900550 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:46.901058 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:45:46.902091 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:45:46.903120 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:46.903120 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:45:46.922652 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183bdb1c-6a08-49f2-be7c-ca7fec134fcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEF35A40B0>]}
[0m14:45:46.923692 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:45:46.923692 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:45:46.924726 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:45:46.924726 [info ] [Thread-1 (]: 6 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m14:45:46.924726 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:45:46.925752 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:45:46.926776 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:45:46.927799 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:45:46.928820 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:45:46.929838 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:45:46.929838 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:45:46.929838 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:45:46.943162 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:45:46.943162 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:45:46.943162 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits
left join raw_commits on raw_contributors.id = raw_commits."author.id"
  );

[0m14:45:46.944205 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits
left join raw_commits on raw_contributors.id = raw_commits."author.id"
  );

[0m14:45:46.944205 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:45:46.944205 [debug] [Thread-1 (]: On model.archi.fcommits: ROLLBACK
[0m14:45:46.947302 [debug] [Thread-1 (]: Failed to rollback 'model.archi.fcommits'
[0m14:45:46.947302 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:45:46.950864 [debug] [Thread-1 (]: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:45:46.951380 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183bdb1c-6a08-49f2-be7c-ca7fec134fcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEF2489A90>]}
[0m14:45:46.951936 [error] [Thread-1 (]: 6 of 7 ERROR creating sql view model main_application.fcommits ................. [[31mERROR[0m in 0.03s]
[0m14:45:46.951936 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:45:46.951936 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:45:46.952968 [debug] [Thread-4 (]: Marking all children of 'model.archi.fcommits' to be skipped because of status 'error'.  Reason: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema).
[0m14:45:46.952968 [info ] [Thread-1 (]: 7 of 7 START sql view model main.view .......................................... [RUN]
[0m14:45:46.952968 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:45:46.953997 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:45:46.955029 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:45:46.956062 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:45:46.957096 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:45:46.958129 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:45:46.958129 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:45:46.958129 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:45:46.966950 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m14:45:46.966950 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:45:46.966950 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:45:46.967957 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.970002 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:45:46.970002 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:45:46.970509 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.972053 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:45:46.972053 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:45:46.972053 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:45:46.973060 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:45:46.973060 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:45:46.974104 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:45:46.975137 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:46.976173 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:45:46.977181 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:45:46.977685 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:45:46.978712 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:45:46.997630 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183bdb1c-6a08-49f2-be7c-ca7fec134fcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEF35D3290>]}
[0m14:45:46.997630 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.04s]
[0m14:45:46.998680 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:45:46.998680 [debug] [MainThread]: Using duckdb connection "master"
[0m14:45:46.999713 [debug] [MainThread]: On master: BEGIN
[0m14:45:46.999713 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:45:47.011415 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m14:45:47.011415 [debug] [MainThread]: On master: COMMIT
[0m14:45:47.012434 [debug] [MainThread]: Using duckdb connection "master"
[0m14:45:47.012434 [debug] [MainThread]: On master: COMMIT
[0m14:45:47.012434 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:45:47.012434 [debug] [MainThread]: On master: Close
[0m14:45:47.014575 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:45:47.015605 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m14:45:47.015605 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m14:45:47.015605 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:45:47.015605 [info ] [MainThread]: 
[0m14:45:47.016627 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.73 seconds (0.73s).
[0m14:45:47.016627 [debug] [MainThread]: Command end result
[0m14:45:47.028305 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:45:47.029416 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:45:47.032970 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:45:47.032970 [info ] [MainThread]: 
[0m14:45:47.032970 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:45:47.034014 [info ] [MainThread]: 
[0m14:45:47.034014 [error] [MainThread]:   Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:45:47.034014 [info ] [MainThread]: 
[0m14:45:47.035045 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m14:45:47.035045 [debug] [MainThread]: Command `dbt build` failed at 14:45:47.035045 after 1.34 seconds
[0m14:45:47.036069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEF0423FB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEF0549BB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DEEFAE2CC0>]}
[0m14:45:47.036069 [debug] [MainThread]: Flushing usage events
[0m14:45:47.513156 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:46:00.311976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DA0C2900>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0D996E1B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DA0C0800>]}


============================== 14:46:00.315078 | f4dde37f-8b0b-411d-bb9e-bd0013a2a61b ==============================
[0m14:46:00.315078 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:46:00.316105 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m14:46:00.428683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f4dde37f-8b0b-411d-bb9e-bd0013a2a61b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DA54FA70>]}
[0m14:46:00.461035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f4dde37f-8b0b-411d-bb9e-bd0013a2a61b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0D8304110>]}
[0m14:46:00.463109 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:46:00.584971 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:46:00.649618 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:46:00.649618 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m14:46:00.774283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f4dde37f-8b0b-411d-bb9e-bd0013a2a61b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DB81FC20>]}
[0m14:46:00.801392 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:46:00.803445 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:46:00.825523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f4dde37f-8b0b-411d-bb9e-bd0013a2a61b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DBC84890>]}
[0m14:46:00.826602 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:46:00.827753 [info ] [MainThread]: 
[0m14:46:00.827753 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:46:00.827753 [info ] [MainThread]: 
[0m14:46:00.828784 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:46:00.831322 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:46:00.876021 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:46:00.876021 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:46:00.876021 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:46:00.886225 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m14:46:00.887247 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:46:00.889355 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:46:00.890865 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:46:00.890865 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:46:00.900070 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:46:00.901074 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:46:00.903623 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:46:00.903623 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:46:00.903623 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:46:00.912394 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:46:00.912394 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:46:00.914932 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_application)
[0m14:46:00.915956 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:46:00.919084 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:46:00.919084 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:46:00.920119 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:46:00.928269 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:46:00.929290 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:46:00.929290 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:46:00.929290 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:46:00.929290 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:46:00.929290 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:46:00.930798 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:46:00.930798 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:46:00.930798 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:46:00.931829 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:46:00.931829 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:46:00.931829 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:46:00.934382 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_application, now create_pytorch_data_main_cleansed)
[0m14:46:00.934382 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:46:00.935920 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:46:00.935920 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:46:00.935920 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:46:00.945117 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:46:00.946145 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:46:00.946145 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:46:00.946145 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:46:00.946145 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:46:00.947173 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:46:00.947173 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:46:00.947173 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:46:00.948201 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:46:00.948201 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:46:00.948201 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:46:00.948201 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:46:00.950822 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main)
[0m14:46:00.950822 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:46:00.951826 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:46:00.951826 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:46:00.952985 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:46:00.961211 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:46:00.961211 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:46:00.962214 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:46:00.962214 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:46:00.962214 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:46:00.962214 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:46:00.963272 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:46:00.963272 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:46:00.963272 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:46:00.964304 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:46:00.964304 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:46:00.964304 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:46:00.966839 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_application'
[0m14:46:00.970427 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:46:00.970427 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:46:00.970933 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:46:00.978080 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:46:00.979100 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:46:00.979100 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:46:00.997061 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m14:46:00.998094 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:46:00.999127 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:46:00.999127 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:46:01.001665 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_application, now list_pytorch_data_main_cleansed)
[0m14:46:01.002670 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:46:01.002670 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:46:01.003698 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:46:01.011865 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:46:01.011865 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:46:01.011865 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:46:01.028831 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:46:01.028831 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:46:01.030146 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:46:01.030146 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:46:01.032700 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main)
[0m14:46:01.034758 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:46:01.034758 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:46:01.035782 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:46:01.042997 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:46:01.044138 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:46:01.044138 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:46:01.060106 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:46:01.061109 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:46:01.061611 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:46:01.061611 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:46:01.064697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f4dde37f-8b0b-411d-bb9e-bd0013a2a61b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DC47A120>]}
[0m14:46:01.064697 [debug] [MainThread]: Using duckdb connection "master"
[0m14:46:01.064697 [debug] [MainThread]: On master: BEGIN
[0m14:46:01.064697 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:46:01.073913 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m14:46:01.073913 [debug] [MainThread]: On master: COMMIT
[0m14:46:01.073913 [debug] [MainThread]: Using duckdb connection "master"
[0m14:46:01.073913 [debug] [MainThread]: On master: COMMIT
[0m14:46:01.074937 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:46:01.074937 [debug] [MainThread]: On master: Close
[0m14:46:01.077474 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:46:01.077474 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:46:01.078503 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:46:01.078503 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:46:01.082083 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:46:01.083091 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:46:01.099432 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:46:01.099432 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:46:01.100948 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:46:01.100948 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:46:01.109756 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:46:01.110765 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:46:01.110765 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:46:01.111323 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.114424 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:46:01.115440 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:46:01.115440 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.117480 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:46:01.117480 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:46:01.118055 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.124206 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:46:01.124726 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:46:01.124726 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:46:01.226536 [debug] [Thread-1 (]: SQL status: OK in 0.102 seconds
[0m14:46:01.230138 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:46:01.230138 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:46:01.231645 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:46:01.232670 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:46:01.254166 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4dde37f-8b0b-411d-bb9e-bd0013a2a61b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DC3C1CA0>]}
[0m14:46:01.254166 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.18s]
[0m14:46:01.255190 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:46:01.255190 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:46:01.255190 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:46:01.256219 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:46:01.256219 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:46:01.258313 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:46:01.258313 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:46:01.259344 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:46:01.260859 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:46:01.260859 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:46:01.260859 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:46:01.273760 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:46:01.273760 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:46:01.275004 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:46:01.275004 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.277055 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:46:01.277055 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:46:01.278128 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.280176 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:46:01.280176 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:46:01.281180 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.281683 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:46:01.281683 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:46:01.281683 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:46:01.283744 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:46:01.284768 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:46:01.284768 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:46:01.285793 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:46:01.286817 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:46:01.305813 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4dde37f-8b0b-411d-bb9e-bd0013a2a61b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DC4AF4A0>]}
[0m14:46:01.305813 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:46:01.306851 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:46:01.306851 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:46:01.306851 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:46:01.307879 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:46:01.307879 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:46:01.308910 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:46:01.309953 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:46:01.311467 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:46:01.311980 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:46:01.312497 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:46:01.312497 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:46:01.325391 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:46:01.325391 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:46:01.326416 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:46:01.326416 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.327440 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:46:01.328952 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:46:01.329486 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.330020 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:46:01.331024 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:46:01.331527 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.331527 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:46:01.332554 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:46:01.332554 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:46:01.333592 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:46:01.334639 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:46:01.335697 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:46:01.336206 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:46:01.337211 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:46:01.355554 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4dde37f-8b0b-411d-bb9e-bd0013a2a61b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DC3FA900>]}
[0m14:46:01.356587 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:46:01.356587 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:46:01.357617 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:46:01.357617 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:46:01.357617 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:46:01.358661 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:46:01.359670 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:46:01.360176 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:46:01.361689 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:46:01.362721 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:46:01.362721 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:46:01.362721 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:46:01.376108 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:46:01.376108 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:46:01.376108 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:46:01.377136 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.379183 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:46:01.379183 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:46:01.379183 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.381197 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:46:01.381705 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:46:01.381705 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.382733 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:46:01.382733 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:46:01.382733 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:46:01.385040 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:46:01.386066 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:46:01.386066 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:46:01.387091 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:46:01.387091 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:46:01.406763 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4dde37f-8b0b-411d-bb9e-bd0013a2a61b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DC48D970>]}
[0m14:46:01.407785 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:46:01.407785 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:46:01.407785 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:46:01.408806 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:46:01.408806 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:46:01.408806 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:46:01.411886 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:46:01.411886 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:46:01.413947 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:46:01.413947 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:46:01.414982 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:46:01.414982 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:46:01.427337 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:46:01.427337 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:46:01.428361 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:46:01.428361 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.429383 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:46:01.429383 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:46:01.430890 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.431895 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:46:01.433063 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:46:01.433063 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.434101 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:46:01.434101 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:46:01.434101 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:46:01.435126 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:46:01.436634 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:46:01.436634 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:46:01.437661 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:46:01.438739 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:46:01.458360 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4dde37f-8b0b-411d-bb9e-bd0013a2a61b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DC508E90>]}
[0m14:46:01.458360 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:46:01.459406 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:46:01.459406 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:46:01.459406 [info ] [Thread-1 (]: 6 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m14:46:01.459406 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:46:01.460920 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:46:01.461957 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:46:01.462990 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:46:01.464037 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:46:01.465071 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:46:01.465071 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:46:01.465071 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:46:01.478018 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:46:01.478018 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:46:01.479058 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits
left join raw_commits on raw_commits."author.id" = raw_contributors.id
  );

[0m14:46:01.479058 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits
left join raw_commits on raw_commits."author.id" = raw_contributors.id
  );

[0m14:46:01.480079 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:46:01.480079 [debug] [Thread-1 (]: On model.archi.fcommits: ROLLBACK
[0m14:46:01.482617 [debug] [Thread-1 (]: Failed to rollback 'model.archi.fcommits'
[0m14:46:01.482617 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:46:01.485790 [debug] [Thread-1 (]: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:46:01.486816 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4dde37f-8b0b-411d-bb9e-bd0013a2a61b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DC47A5A0>]}
[0m14:46:01.486816 [error] [Thread-1 (]: 6 of 7 ERROR creating sql view model main_application.fcommits ................. [[31mERROR[0m in 0.03s]
[0m14:46:01.486816 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:46:01.486816 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:46:01.488330 [debug] [Thread-4 (]: Marking all children of 'model.archi.fcommits' to be skipped because of status 'error'.  Reason: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema).
[0m14:46:01.488330 [info ] [Thread-1 (]: 7 of 7 START sql view model main.view .......................................... [RUN]
[0m14:46:01.489361 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:46:01.489361 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:46:01.490868 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:46:01.490868 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:46:01.492938 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:46:01.493967 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:46:01.493967 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:46:01.493967 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:46:01.502135 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:46:01.503159 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:46:01.503159 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:46:01.504162 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.505217 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:46:01.505217 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:46:01.506239 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.507308 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:46:01.507308 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:46:01.508817 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:46:01.508817 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:46:01.509847 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:46:01.509847 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:46:01.511358 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:46:01.512423 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:46:01.513456 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:46:01.513456 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:46:01.514541 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:46:01.534065 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4dde37f-8b0b-411d-bb9e-bd0013a2a61b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DC47BBF0>]}
[0m14:46:01.534065 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.05s]
[0m14:46:01.535069 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:46:01.536081 [debug] [MainThread]: Using duckdb connection "master"
[0m14:46:01.536590 [debug] [MainThread]: On master: BEGIN
[0m14:46:01.536590 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:46:01.549538 [debug] [MainThread]: SQL status: OK in 0.013 seconds
[0m14:46:01.549538 [debug] [MainThread]: On master: COMMIT
[0m14:46:01.549538 [debug] [MainThread]: Using duckdb connection "master"
[0m14:46:01.549538 [debug] [MainThread]: On master: COMMIT
[0m14:46:01.551047 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:46:01.551047 [debug] [MainThread]: On master: Close
[0m14:46:01.553105 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:46:01.553105 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m14:46:01.553105 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m14:46:01.553105 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:46:01.554188 [info ] [MainThread]: 
[0m14:46:01.554188 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.72 seconds (0.72s).
[0m14:46:01.555217 [debug] [MainThread]: Command end result
[0m14:46:01.566537 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:46:01.567560 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:46:01.571190 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:46:01.571190 [info ] [MainThread]: 
[0m14:46:01.572221 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:46:01.572221 [info ] [MainThread]: 
[0m14:46:01.572221 [error] [MainThread]:   Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:46:01.572221 [info ] [MainThread]: 
[0m14:46:01.572221 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m14:46:01.573732 [debug] [MainThread]: Command `dbt build` failed at 14:46:01.573732 after 1.35 seconds
[0m14:46:01.573732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0D996E1B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DA15D460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0DA15D8E0>]}
[0m14:46:01.573732 [debug] [MainThread]: Flushing usage events
[0m14:46:02.025537 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:46:52.793577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021EC6B161B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021EC83020F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021EC8302C30>]}


============================== 14:46:52.796774 | 9ba5c266-c1c8-4758-871c-807cd91f7857 ==============================
[0m14:46:52.796774 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:46:52.797824 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m14:46:52.908062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9ba5c266-c1c8-4758-871c-807cd91f7857', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021EC8D6B740>]}
[0m14:46:52.937752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9ba5c266-c1c8-4758-871c-807cd91f7857', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021EC6B161B0>]}
[0m14:46:52.940872 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:46:53.055688 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:46:53.116588 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:46:53.118101 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m14:46:53.219191 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.archi.fcommits' (models\application\fcommits.sql) depends on a source named 'main.raw_commits' which was not found
[0m14:46:53.220374 [debug] [MainThread]: Command `dbt build` failed at 14:46:53.220374 after 0.51 seconds
[0m14:46:53.220374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021EC8ABEDB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021ECA454650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021EC8331310>]}
[0m14:46:53.220374 [debug] [MainThread]: Flushing usage events
[0m14:46:53.611856 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:47:22.364876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011B55BD41A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011B58745DF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011B58744770>]}


============================== 14:47:22.366932 | bc3b9ed4-4ada-48f7-8544-f1f567e8a084 ==============================
[0m14:47:22.366932 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:47:22.367938 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:47:22.477569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bc3b9ed4-4ada-48f7-8544-f1f567e8a084', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011B5894AFC0>]}
[0m14:47:22.507345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bc3b9ed4-4ada-48f7-8544-f1f567e8a084', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011B58A781A0>]}
[0m14:47:22.509408 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:47:22.625982 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:47:22.687582 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:47:22.687582 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m14:47:22.790668 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.archi.fcommits' (models\application\fcommits.sql) depends on a source named 'cleansed.raw_commits' which was not found
[0m14:47:22.791690 [debug] [MainThread]: Command `dbt build` failed at 14:47:22.791690 after 0.51 seconds
[0m14:47:22.792695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011B57FD05C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011B59E94AA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011B59E94A40>]}
[0m14:47:22.792695 [debug] [MainThread]: Flushing usage events
[0m14:47:23.153762 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:49:42.737322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002489B6186B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002489B5510D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002489B5516D0>]}


============================== 14:49:42.739517 | 46a06ad3-1abf-40f5-8f07-48f061fe4c05 ==============================
[0m14:49:42.739517 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:49:42.740525 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:49:42.851386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '46a06ad3-1abf-40f5-8f07-48f061fe4c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002489BAA1070>]}
[0m14:49:42.882114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '46a06ad3-1abf-40f5-8f07-48f061fe4c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002489914DF70>]}
[0m14:49:42.883653 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:49:42.999685 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:49:43.063361 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m14:49:43.063898 [debug] [MainThread]: Partial parsing: added file: archi://models\application\lecture.sql
[0m14:49:43.063898 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m14:49:43.169005 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.archi.fcommits' (models\application\fcommits.sql) depends on a source named 'cleansed.raw_commits' which was not found
[0m14:49:43.170030 [debug] [MainThread]: Command `dbt run` failed at 14:49:43.170030 after 0.52 seconds
[0m14:49:43.170030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002489B6186B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024899647B00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002489CF4B1A0>]}
[0m14:49:43.170030 [debug] [MainThread]: Flushing usage events
[0m14:49:43.572444 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:50:10.723397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001430F5EF4A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001430EB825A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001430EB83440>]}


============================== 14:50:10.726938 | fc0f7bbb-47cd-4cee-9071-94d368128760 ==============================
[0m14:50:10.726938 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:50:10.726938 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:50:10.846178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fc0f7bbb-47cd-4cee-9071-94d368128760', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001430F3C3740>]}
[0m14:50:10.878994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fc0f7bbb-47cd-4cee-9071-94d368128760', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001430EC679E0>]}
[0m14:50:10.881100 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:50:11.000084 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:50:11.065366 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m14:50:11.065366 [debug] [MainThread]: Partial parsing: added file: archi://models\application\lecture.sql
[0m14:50:11.065366 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m14:50:11.299730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fc0f7bbb-47cd-4cee-9071-94d368128760', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001430F891A30>]}
[0m14:50:11.326891 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:50:11.328930 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:50:11.343740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fc0f7bbb-47cd-4cee-9071-94d368128760', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014310DF0980>]}
[0m14:50:11.344245 [info ] [MainThread]: Found 8 models, 424 macros
[0m14:50:11.344245 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fc0f7bbb-47cd-4cee-9071-94d368128760', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014310AD8EF0>]}
[0m14:50:11.345249 [info ] [MainThread]: 
[0m14:50:11.345249 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:50:11.346444 [info ] [MainThread]: 
[0m14:50:11.346444 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:50:11.349514 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:50:11.390957 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:50:11.390957 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:50:11.391982 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:50:11.401785 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m14:50:11.402817 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:50:11.405419 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:50:11.405419 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:50:11.405419 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:11.413992 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:50:11.415514 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:50:11.418606 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:50:11.418606 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:50:11.418606 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:11.426877 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:50:11.427900 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:50:11.430046 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_application)
[0m14:50:11.430046 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:50:11.433599 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:50:11.433599 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:50:11.434625 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:11.441801 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:50:11.442835 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:50:11.442835 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:50:11.443864 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:11.443864 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:50:11.443864 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:50:11.443864 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:11.445374 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:50:11.445374 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:50:11.445374 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:50:11.445374 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:11.446382 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:50:11.447610 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_application, now create_pytorch_data_main)
[0m14:50:11.447610 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:50:11.448634 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:50:11.449661 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:50:11.449661 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:11.457893 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:50:11.458917 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:50:11.458917 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:50:11.458917 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:11.458917 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:50:11.459943 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:50:11.459943 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:11.459943 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:50:11.460965 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:50:11.460965 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:50:11.460965 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:11.460965 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:50:11.463536 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_cleansed)
[0m14:50:11.463536 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:50:11.464576 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:50:11.464576 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:50:11.464576 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:11.473187 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:50:11.474211 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:50:11.474211 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:50:11.475215 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:11.475215 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:50:11.475720 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:50:11.475720 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:11.475720 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:50:11.476746 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:50:11.476746 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:50:11.477275 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:11.477275 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:50:11.479886 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_application'
[0m14:50:11.482938 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:50:11.482938 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:50:11.483443 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:50:11.491068 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:50:11.491068 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:50:11.492091 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:50:11.509470 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:50:11.509470 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:50:11.510487 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:50:11.510487 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:50:11.513540 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_application, now list_pytorch_data_main)
[0m14:50:11.515050 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:50:11.515050 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:50:11.515555 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:11.523661 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:50:11.523661 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:50:11.523661 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:50:11.540097 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:50:11.541138 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:50:11.542162 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:50:11.542162 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:50:11.544695 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_cleansed)
[0m14:50:11.546750 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:50:11.546750 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:50:11.546750 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:11.555345 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:50:11.555345 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:50:11.555345 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:50:11.571011 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:50:11.572035 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:50:11.573074 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:50:11.573074 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:50:11.575590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fc0f7bbb-47cd-4cee-9071-94d368128760', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000143111744A0>]}
[0m14:50:11.576094 [debug] [MainThread]: Using duckdb connection "master"
[0m14:50:11.576094 [debug] [MainThread]: On master: BEGIN
[0m14:50:11.576094 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:50:11.583745 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m14:50:11.584749 [debug] [MainThread]: On master: COMMIT
[0m14:50:11.584749 [debug] [MainThread]: Using duckdb connection "master"
[0m14:50:11.585254 [debug] [MainThread]: On master: COMMIT
[0m14:50:11.585254 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:50:11.585254 [debug] [MainThread]: On master: Close
[0m14:50:11.588364 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:50:11.588364 [info ] [Thread-1 (]: 1 of 8 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:50:11.588364 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:50:11.589369 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:50:11.592921 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:50:11.592921 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:50:11.610478 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:50:11.610478 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:50:11.610478 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:50:11.611501 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:50:11.620235 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:50:11.620235 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:50:11.621271 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:50:11.621271 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.625932 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:50:11.625932 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:50:11.625932 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.627979 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:50:11.627979 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:50:11.627979 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.634354 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:50:11.635359 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:50:11.635359 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:50:11.737476 [debug] [Thread-1 (]: SQL status: OK in 0.101 seconds
[0m14:50:11.739506 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:50:11.740522 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:50:11.741590 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:11.742625 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:50:11.762802 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc0f7bbb-47cd-4cee-9071-94d368128760', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014310C57890>]}
[0m14:50:11.763809 [info ] [Thread-1 (]: 1 of 8 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.17s]
[0m14:50:11.764313 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:50:11.764313 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:50:11.764313 [info ] [Thread-1 (]: 2 of 8 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:50:11.765318 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:50:11.765318 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:50:11.766848 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:50:11.766848 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:50:11.768912 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:50:11.768912 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:50:11.769932 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:50:11.769932 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:11.782155 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:50:11.782155 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:50:11.783159 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:50:11.783159 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.784405 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:50:11.785409 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:50:11.785913 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.786941 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:50:11.786941 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:50:11.786941 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.787968 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:50:11.788994 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:50:11.788994 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:50:11.790021 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:11.791052 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:50:11.792108 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:50:11.793140 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:11.793677 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:50:11.812640 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc0f7bbb-47cd-4cee-9071-94d368128760', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001431220F7A0>]}
[0m14:50:11.814149 [info ] [Thread-1 (]: 2 of 8 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:50:11.814149 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:50:11.815154 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:50:11.815154 [info ] [Thread-1 (]: 3 of 8 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:50:11.815659 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:50:11.815659 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:50:11.816689 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:50:11.817717 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:50:11.818764 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:50:11.819794 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:50:11.819794 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:50:11.819794 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:11.833373 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:50:11.833373 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:50:11.833373 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:50:11.834402 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.836458 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:50:11.836458 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:50:11.836458 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.838543 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:50:11.838543 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:50:11.838543 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.840598 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:50:11.840598 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:50:11.840598 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:50:11.841616 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:11.842862 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:50:11.842862 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:50:11.843904 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:11.845417 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:50:11.863750 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc0f7bbb-47cd-4cee-9071-94d368128760', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001431120F710>]}
[0m14:50:11.865263 [info ] [Thread-1 (]: 3 of 8 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:50:11.865793 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:50:11.866322 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:50:11.866322 [info ] [Thread-1 (]: 4 of 8 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:50:11.866322 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:50:11.867348 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:50:11.868786 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:50:11.868786 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:50:11.870872 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:50:11.870872 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:50:11.871892 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:50:11.871892 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:11.884640 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:50:11.884640 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:50:11.884640 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:50:11.885646 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.887189 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:50:11.887189 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:50:11.888196 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.889725 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:50:11.889725 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:50:11.889725 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.890741 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:50:11.890741 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:50:11.891765 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:50:11.891765 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:11.893276 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:50:11.894303 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:50:11.895308 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:11.895812 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:50:11.915237 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc0f7bbb-47cd-4cee-9071-94d368128760', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014311155880>]}
[0m14:50:11.915237 [info ] [Thread-1 (]: 4 of 8 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:50:11.916350 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:50:11.916350 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:50:11.916873 [info ] [Thread-1 (]: 5 of 8 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:50:11.917403 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:50:11.917403 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:50:11.918439 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:50:11.919459 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:50:11.920480 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:50:11.921505 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:50:11.921505 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:50:11.921505 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:11.934304 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:50:11.934304 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:50:11.935308 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:50:11.935811 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.937371 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:50:11.937371 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:50:11.937898 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.938923 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:50:11.938923 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:50:11.939949 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:11.940973 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:50:11.940973 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:50:11.940973 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:50:11.941995 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:11.943022 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:50:11.943022 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:50:11.944533 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:11.946043 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:50:11.965586 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc0f7bbb-47cd-4cee-9071-94d368128760', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014311222EA0>]}
[0m14:50:11.966616 [info ] [Thread-1 (]: 5 of 8 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:50:11.966616 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:50:11.966616 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:50:11.967641 [info ] [Thread-1 (]: 6 of 8 START sql view model main_application.fcommits .......................... [RUN]
[0m14:50:11.967641 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:50:11.968166 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:50:11.968695 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:50:11.969710 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:50:11.971744 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:50:11.972762 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:50:11.972762 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:50:11.972762 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:11.986165 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:50:11.987191 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:50:11.987191 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits
left join raw_commits on raw_commits."author.id" = raw_contributors.id
  );

[0m14:50:11.988215 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits
left join raw_commits on raw_commits."author.id" = raw_contributors.id
  );

[0m14:50:11.988215 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:50:11.988754 [debug] [Thread-1 (]: On model.archi.fcommits: ROLLBACK
[0m14:50:11.991321 [debug] [Thread-1 (]: Failed to rollback 'model.archi.fcommits'
[0m14:50:11.991321 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:50:11.994447 [debug] [Thread-1 (]: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:50:11.995452 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc0f7bbb-47cd-4cee-9071-94d368128760', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014312209DC0>]}
[0m14:50:11.995452 [error] [Thread-1 (]: 6 of 8 ERROR creating sql view model main_application.fcommits ................. [[31mERROR[0m in 0.03s]
[0m14:50:11.995957 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:50:11.995957 [debug] [Thread-1 (]: Began running node model.archi.lecture
[0m14:50:11.996980 [debug] [Thread-4 (]: Marking all children of 'model.archi.fcommits' to be skipped because of status 'error'.  Reason: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema).
[0m14:50:11.996980 [info ] [Thread-1 (]: 7 of 8 START sql view model main_application.lecture ........................... [RUN]
[0m14:50:11.996980 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.lecture)
[0m14:50:11.998207 [debug] [Thread-1 (]: Began compiling node model.archi.lecture
[0m14:50:11.999212 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.lecture"
[0m14:50:11.999212 [debug] [Thread-1 (]: Began executing node model.archi.lecture
[0m14:50:12.001270 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.lecture"
[0m14:50:12.001270 [debug] [Thread-1 (]: Using duckdb connection "model.archi.lecture"
[0m14:50:12.002295 [debug] [Thread-1 (]: On model.archi.lecture: BEGIN
[0m14:50:12.002295 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:12.009970 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m14:50:12.009970 [debug] [Thread-1 (]: Using duckdb connection "model.archi.lecture"
[0m14:50:12.010991 [debug] [Thread-1 (]: On model.archi.lecture: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.lecture"} */

  
  create view "pytorch_data"."main_application"."lecture__dbt_tmp" as (
    SELECT table_schema, table_name
FROM information_schema.tables
WHERE table_name = 'raw_commits';
  );

[0m14:50:12.012018 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.lecture"} */

  
  create view "pytorch_data"."main_application"."lecture__dbt_tmp" as (
    SELECT table_schema, table_name
FROM information_schema.tables
WHERE table_name = 'raw_commits';
  );

[0m14:50:12.012018 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:50:12.013047 [debug] [Thread-1 (]: On model.archi.lecture: ROLLBACK
[0m14:50:12.014555 [debug] [Thread-1 (]: Failed to rollback 'model.archi.lecture'
[0m14:50:12.014555 [debug] [Thread-1 (]: On model.archi.lecture: Close
[0m14:50:12.017085 [debug] [Thread-1 (]: Runtime Error in model lecture (models\application\lecture.sql)
  Parser Error: syntax error at or near ";"
[0m14:50:12.018111 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc0f7bbb-47cd-4cee-9071-94d368128760', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000143122379E0>]}
[0m14:50:12.018111 [error] [Thread-1 (]: 7 of 8 ERROR creating sql view model main_application.lecture .................. [[31mERROR[0m in 0.02s]
[0m14:50:12.019117 [debug] [Thread-1 (]: Finished running node model.archi.lecture
[0m14:50:12.019117 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:50:12.019621 [debug] [Thread-4 (]: Marking all children of 'model.archi.lecture' to be skipped because of status 'error'.  Reason: Runtime Error in model lecture (models\application\lecture.sql)
  Parser Error: syntax error at or near ";".
[0m14:50:12.019621 [info ] [Thread-1 (]: 8 of 8 START sql view model main.view .......................................... [RUN]
[0m14:50:12.020665 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.lecture, now model.archi.view)
[0m14:50:12.020665 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:50:12.021691 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:50:12.022714 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:50:12.023761 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:50:12.023761 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:50:12.023761 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:50:12.025296 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:12.032939 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m14:50:12.032939 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:50:12.032939 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:50:12.033965 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:12.035478 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:50:12.035478 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:50:12.036506 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:12.037535 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:50:12.037535 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:50:12.038577 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:12.038577 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:50:12.039583 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:50:12.039583 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:50:12.040628 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:12.041659 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:50:12.041659 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:50:12.042684 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:12.043708 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:50:12.063198 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc0f7bbb-47cd-4cee-9071-94d368128760', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001431122EBD0>]}
[0m14:50:12.064226 [info ] [Thread-1 (]: 8 of 8 OK created sql view model main.view ..................................... [[32mOK[0m in 0.04s]
[0m14:50:12.064226 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:50:12.065230 [debug] [MainThread]: Using duckdb connection "master"
[0m14:50:12.065733 [debug] [MainThread]: On master: BEGIN
[0m14:50:12.065733 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:50:12.078121 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m14:50:12.078121 [debug] [MainThread]: On master: COMMIT
[0m14:50:12.078121 [debug] [MainThread]: Using duckdb connection "master"
[0m14:50:12.079147 [debug] [MainThread]: On master: COMMIT
[0m14:50:12.079147 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:50:12.079147 [debug] [MainThread]: On master: Close
[0m14:50:12.081185 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:50:12.081185 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m14:50:12.081707 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m14:50:12.081707 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:50:12.081707 [info ] [MainThread]: 
[0m14:50:12.082745 [info ] [MainThread]: Finished running 8 view models in 0 hours 0 minutes and 0.74 seconds (0.74s).
[0m14:50:12.083906 [debug] [MainThread]: Command end result
[0m14:50:12.094141 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:50:12.095649 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:50:12.098812 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:50:12.098812 [info ] [MainThread]: 
[0m14:50:12.099837 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m14:50:12.099837 [info ] [MainThread]: 
[0m14:50:12.099837 [error] [MainThread]:   Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:50:12.099837 [info ] [MainThread]: 
[0m14:50:12.101350 [error] [MainThread]:   Runtime Error in model lecture (models\application\lecture.sql)
  Parser Error: syntax error at or near ";"
[0m14:50:12.101350 [info ] [MainThread]: 
[0m14:50:12.101925 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=2 SKIP=0 TOTAL=8
[0m14:50:12.102465 [debug] [MainThread]: Command `dbt run` failed at 14:50:12.102465 after 1.46 seconds
[0m14:50:12.102465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001430F1DC860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001430F078980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001430F079430>]}
[0m14:50:12.103516 [debug] [MainThread]: Flushing usage events
[0m14:50:12.551056 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:50:29.770316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015711F77710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000157150A0890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000157150A08F0>]}


============================== 14:50:29.773635 | e1e17954-9ce6-428b-b614-0e0d68df3edd ==============================
[0m14:50:29.773635 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:50:29.773635 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:50:29.885957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e1e17954-9ce6-428b-b614-0e0d68df3edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000157158C27B0>]}
[0m14:50:29.916131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e1e17954-9ce6-428b-b614-0e0d68df3edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000157147E9100>]}
[0m14:50:29.918667 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:50:30.036084 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:50:30.100549 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:50:30.100549 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\lecture.sql
[0m14:50:30.223967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e1e17954-9ce6-428b-b614-0e0d68df3edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015716A9FD70>]}
[0m14:50:30.249995 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:50:30.251503 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:50:30.266425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e1e17954-9ce6-428b-b614-0e0d68df3edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015716EDF260>]}
[0m14:50:30.266425 [info ] [MainThread]: Found 8 models, 424 macros
[0m14:50:30.266425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e1e17954-9ce6-428b-b614-0e0d68df3edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015716C11E50>]}
[0m14:50:30.268607 [info ] [MainThread]: 
[0m14:50:30.268607 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:50:30.268607 [info ] [MainThread]: 
[0m14:50:30.268607 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:50:30.271798 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:50:30.313964 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:50:30.313964 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:50:30.314997 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:50:30.324675 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m14:50:30.325680 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:50:30.328239 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:50:30.328239 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:50:30.328239 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:30.337406 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:50:30.338449 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:50:30.341527 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:50:30.341527 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:50:30.342549 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:30.351681 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:50:30.351681 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:50:30.353817 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m14:50:30.355071 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:50:30.358147 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:50:30.358147 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:50:30.359169 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:30.366852 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:50:30.367880 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:50:30.367880 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:50:30.368930 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:30.368930 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:50:30.368930 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:50:30.368930 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:30.369961 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:50:30.369961 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:50:30.369961 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:50:30.370994 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:30.370994 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:50:30.373046 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_application)
[0m14:50:30.373046 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:50:30.374562 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:50:30.374562 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:50:30.374562 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:30.383312 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:50:30.383312 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:50:30.383312 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:50:30.384827 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:30.384827 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:50:30.384827 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:50:30.385836 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:30.386341 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:50:30.386341 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:50:30.386341 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:50:30.386341 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:30.387368 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:50:30.388394 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_application, now create_pytorch_data_main_cleansed)
[0m14:50:30.389425 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:50:30.390461 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:50:30.390461 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:50:30.390461 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:30.399143 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:50:30.399143 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:50:30.400173 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:50:30.400173 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:30.400173 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:50:30.400173 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:50:30.401208 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:30.401208 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:50:30.402238 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:50:30.402238 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:50:30.402238 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:50:30.402238 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:50:30.405294 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m14:50:30.408312 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:50:30.408312 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:50:30.408312 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:50:30.416588 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:50:30.417609 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:50:30.417609 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:50:30.435019 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:50:30.436031 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:50:30.436558 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:50:30.436558 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:50:30.439627 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_application)
[0m14:50:30.440644 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:50:30.441685 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:50:30.441685 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:30.449442 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:50:30.449442 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:50:30.450463 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:50:30.466860 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:50:30.466860 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:50:30.468088 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:50:30.468088 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:50:30.470138 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_application, now list_pytorch_data_main_cleansed)
[0m14:50:30.472180 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:50:30.472180 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:50:30.472180 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:50:30.480423 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:50:30.480423 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:50:30.480423 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:50:30.497799 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:50:30.497799 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:50:30.498805 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:50:30.498805 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:50:30.501912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e1e17954-9ce6-428b-b614-0e0d68df3edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015716DC1B50>]}
[0m14:50:30.501912 [debug] [MainThread]: Using duckdb connection "master"
[0m14:50:30.501912 [debug] [MainThread]: On master: BEGIN
[0m14:50:30.501912 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:50:30.510217 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m14:50:30.510217 [debug] [MainThread]: On master: COMMIT
[0m14:50:30.511237 [debug] [MainThread]: Using duckdb connection "master"
[0m14:50:30.511237 [debug] [MainThread]: On master: COMMIT
[0m14:50:30.511237 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:50:30.511237 [debug] [MainThread]: On master: Close
[0m14:50:30.514373 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:50:30.514373 [info ] [Thread-1 (]: 1 of 8 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:50:30.514373 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:50:30.514373 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:50:30.518419 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:50:30.519473 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:50:30.536511 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:50:30.536511 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:50:30.537528 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:50:30.537528 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:50:30.546236 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m14:50:30.546236 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:50:30.546236 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:50:30.547265 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.550824 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:50:30.550824 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:50:30.550824 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.552936 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:50:30.553942 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:50:30.553942 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.561085 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:50:30.561085 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:50:30.561085 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:50:30.663781 [debug] [Thread-1 (]: SQL status: OK in 0.102 seconds
[0m14:50:30.666326 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:50:30.666326 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:50:30.667356 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:30.669422 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:50:30.689860 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1e17954-9ce6-428b-b614-0e0d68df3edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015716D9ED50>]}
[0m14:50:30.689860 [info ] [Thread-1 (]: 1 of 8 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.17s]
[0m14:50:30.690888 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:50:30.690888 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:50:30.691893 [info ] [Thread-1 (]: 2 of 8 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:50:30.691893 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:50:30.691893 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:50:30.693136 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:50:30.694162 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:50:30.695673 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:50:30.695673 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:50:30.696699 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:50:30.696699 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:30.709980 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:50:30.709980 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:50:30.709980 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:50:30.711002 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.712511 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:50:30.712511 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:50:30.713566 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.714605 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:50:30.715609 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:50:30.716111 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.717140 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:50:30.717140 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:50:30.717140 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:50:30.719195 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:30.720225 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:50:30.720225 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:50:30.720225 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:30.721739 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:50:30.741336 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1e17954-9ce6-428b-b614-0e0d68df3edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015716EC8FB0>]}
[0m14:50:30.741336 [info ] [Thread-1 (]: 2 of 8 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:50:30.742363 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:50:30.742363 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:50:30.742363 [info ] [Thread-1 (]: 3 of 8 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:50:30.743368 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:50:30.743368 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:50:30.744652 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:50:30.744652 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:50:30.747183 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:50:30.747183 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:50:30.747183 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:50:30.748269 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:30.760549 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:50:30.760549 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:50:30.760549 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:50:30.761581 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.762610 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:50:30.762610 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:50:30.764125 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.765645 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:50:30.765645 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:50:30.765645 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.766678 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:50:30.766678 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:50:30.767707 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:50:30.768736 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:30.770845 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:50:30.770845 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:50:30.771850 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:30.771850 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:50:30.792284 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1e17954-9ce6-428b-b614-0e0d68df3edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015712BBBDD0>]}
[0m14:50:30.792284 [info ] [Thread-1 (]: 3 of 8 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:50:30.793314 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:50:30.793314 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:50:30.793314 [info ] [Thread-1 (]: 4 of 8 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:50:30.793314 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:50:30.793314 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:50:30.795826 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:50:30.796330 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:50:30.797357 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:50:30.798386 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:50:30.798386 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:50:30.799410 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:30.812225 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:50:30.812225 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:50:30.812225 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:50:30.813258 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.815299 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:50:30.815299 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:50:30.815806 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.817321 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:50:30.817321 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:50:30.817321 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.818329 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:50:30.818329 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:50:30.819360 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:50:30.820393 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:30.821907 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:50:30.821907 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:50:30.822936 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:30.823966 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:50:30.842813 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1e17954-9ce6-428b-b614-0e0d68df3edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015717389490>]}
[0m14:50:30.842813 [info ] [Thread-1 (]: 4 of 8 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:50:30.843837 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:50:30.843837 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:50:30.843837 [info ] [Thread-1 (]: 5 of 8 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:50:30.844863 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:50:30.844863 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:50:30.845868 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:50:30.846914 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:50:30.849007 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:50:30.849007 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:50:30.849007 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:50:30.850035 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:30.861828 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:50:30.861828 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:50:30.862860 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:50:30.862860 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.864966 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:50:30.864966 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:50:30.864966 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.866482 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:50:30.867529 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:50:30.867529 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.868558 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:50:30.868558 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:50:30.868558 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:50:30.870623 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:30.871652 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:50:30.871652 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:50:30.872684 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:30.873716 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:50:30.893102 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1e17954-9ce6-428b-b614-0e0d68df3edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015717317BC0>]}
[0m14:50:30.893102 [info ] [Thread-1 (]: 5 of 8 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:50:30.894124 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:50:30.894124 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:50:30.894124 [info ] [Thread-1 (]: 6 of 8 START sql view model main_application.fcommits .......................... [RUN]
[0m14:50:30.894124 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:50:30.894124 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:50:30.895635 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:50:30.897185 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:50:30.899249 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:50:30.900347 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:50:30.900347 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:50:30.900347 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:30.912684 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:50:30.913714 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:50:30.913714 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits
left join raw_commits on raw_commits."author.id" = raw_contributors.id
  );

[0m14:50:30.913714 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from  raw_commits
left join raw_commits on raw_commits."author.id" = raw_contributors.id
  );

[0m14:50:30.914745 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:50:30.914745 [debug] [Thread-1 (]: On model.archi.fcommits: ROLLBACK
[0m14:50:30.917773 [debug] [Thread-1 (]: Failed to rollback 'model.archi.fcommits'
[0m14:50:30.917773 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:50:30.920851 [debug] [Thread-1 (]: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:50:30.921856 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1e17954-9ce6-428b-b614-0e0d68df3edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000157173A9310>]}
[0m14:50:30.921856 [error] [Thread-1 (]: 6 of 8 ERROR creating sql view model main_application.fcommits ................. [[31mERROR[0m in 0.03s]
[0m14:50:30.922359 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:50:30.922359 [debug] [Thread-1 (]: Began running node model.archi.lecture
[0m14:50:30.923381 [debug] [Thread-4 (]: Marking all children of 'model.archi.fcommits' to be skipped because of status 'error'.  Reason: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema).
[0m14:50:30.923381 [info ] [Thread-1 (]: 7 of 8 START sql view model main_application.lecture ........................... [RUN]
[0m14:50:30.924410 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.lecture)
[0m14:50:30.924410 [debug] [Thread-1 (]: Began compiling node model.archi.lecture
[0m14:50:30.925924 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.lecture"
[0m14:50:30.925924 [debug] [Thread-1 (]: Began executing node model.archi.lecture
[0m14:50:30.927948 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.lecture"
[0m14:50:30.928451 [debug] [Thread-1 (]: Using duckdb connection "model.archi.lecture"
[0m14:50:30.928451 [debug] [Thread-1 (]: On model.archi.lecture: BEGIN
[0m14:50:30.928451 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:30.939613 [debug] [Thread-1 (]: SQL status: OK in 0.010 seconds
[0m14:50:30.939613 [debug] [Thread-1 (]: Using duckdb connection "model.archi.lecture"
[0m14:50:30.939613 [debug] [Thread-1 (]: On model.archi.lecture: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.lecture"} */

  
  create view "pytorch_data"."main_application"."lecture__dbt_tmp" as (
    SELECT table_schema, table_name
FROM information_schema.tables
WHERE table_name = 'raw_commits'
  );

[0m14:50:30.940636 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:30.943249 [debug] [Thread-1 (]: Using duckdb connection "model.archi.lecture"
[0m14:50:30.944253 [debug] [Thread-1 (]: On model.archi.lecture: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.lecture"} */
alter view "pytorch_data"."main_application"."lecture__dbt_tmp" rename to "lecture"
[0m14:50:30.944253 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.946025 [debug] [Thread-1 (]: On model.archi.lecture: COMMIT
[0m14:50:30.946025 [debug] [Thread-1 (]: Using duckdb connection "model.archi.lecture"
[0m14:50:30.946025 [debug] [Thread-1 (]: On model.archi.lecture: COMMIT
[0m14:50:30.948162 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:30.949267 [debug] [Thread-1 (]: Using duckdb connection "model.archi.lecture"
[0m14:50:30.950305 [debug] [Thread-1 (]: On model.archi.lecture: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.lecture"} */
drop view if exists "pytorch_data"."main_application"."lecture__dbt_backup" cascade
[0m14:50:30.950305 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.951347 [debug] [Thread-1 (]: On model.archi.lecture: Close
[0m14:50:30.970965 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1e17954-9ce6-428b-b614-0e0d68df3edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015715950AA0>]}
[0m14:50:30.971999 [info ] [Thread-1 (]: 7 of 8 OK created sql view model main_application.lecture ...................... [[32mOK[0m in 0.05s]
[0m14:50:30.971999 [debug] [Thread-1 (]: Finished running node model.archi.lecture
[0m14:50:30.973025 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:50:30.973025 [info ] [Thread-1 (]: 8 of 8 START sql view model main.view .......................................... [RUN]
[0m14:50:30.973025 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.lecture, now model.archi.view)
[0m14:50:30.974052 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:50:30.975594 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:50:30.976620 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:50:30.979152 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:50:30.980203 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:50:30.980203 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:50:30.980203 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:50:30.995613 [debug] [Thread-1 (]: SQL status: OK in 0.015 seconds
[0m14:50:30.996115 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:50:30.996115 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:50:30.997134 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:30.998155 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:50:30.998155 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:50:30.999663 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:31.000704 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:50:31.001739 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:50:31.001739 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:50:31.002776 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:50:31.002776 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:50:31.002776 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:50:31.003809 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:31.005851 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:50:31.005851 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:50:31.006358 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:50:31.007388 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:50:31.026751 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1e17954-9ce6-428b-b614-0e0d68df3edd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015717365580>]}
[0m14:50:31.027782 [info ] [Thread-1 (]: 8 of 8 OK created sql view model main.view ..................................... [[32mOK[0m in 0.05s]
[0m14:50:31.027782 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:50:31.028808 [debug] [MainThread]: Using duckdb connection "master"
[0m14:50:31.028808 [debug] [MainThread]: On master: BEGIN
[0m14:50:31.028808 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:50:31.041594 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m14:50:31.041594 [debug] [MainThread]: On master: COMMIT
[0m14:50:31.041594 [debug] [MainThread]: Using duckdb connection "master"
[0m14:50:31.042617 [debug] [MainThread]: On master: COMMIT
[0m14:50:31.042617 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:50:31.042617 [debug] [MainThread]: On master: Close
[0m14:50:31.044680 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:50:31.044680 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m14:50:31.044680 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m14:50:31.045686 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:50:31.045686 [info ] [MainThread]: 
[0m14:50:31.046191 [info ] [MainThread]: Finished running 8 view models in 0 hours 0 minutes and 0.78 seconds (0.78s).
[0m14:50:31.047273 [debug] [MainThread]: Command end result
[0m14:50:31.058480 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:50:31.059508 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:50:31.063063 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:50:31.063063 [info ] [MainThread]: 
[0m14:50:31.063063 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:50:31.063063 [info ] [MainThread]: 
[0m14:50:31.064101 [error] [MainThread]:   Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Circular reference to CTE "raw_commits", There are two possible solutions. 
  1. use WITH RECURSIVE to use recursive CTEs. 
  2. If you want to use the TABLE name "raw_commits" the same as the CTE name, please explicitly add "SCHEMA" before table name. You can try "main.raw_commits" (main is the duckdb default schema)
[0m14:50:31.064101 [info ] [MainThread]: 
[0m14:50:31.064101 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=0 TOTAL=8
[0m14:50:31.064101 [debug] [MainThread]: Command `dbt run` failed at 14:50:31.064101 after 1.38 seconds
[0m14:50:31.065611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015716E32270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015714D05820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015714D05700>]}
[0m14:50:31.065611 [debug] [MainThread]: Flushing usage events
[0m14:50:31.531518 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:51:58.896051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B02F12E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B02F3470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B02F02C0>]}


============================== 14:51:58.898794 | 1526381f-151a-45c3-98ae-afc715a336ee ==============================
[0m14:51:58.898794 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:51:58.898794 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:51:59.013284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1526381f-151a-45c3-98ae-afc715a336ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4AE224DD0>]}
[0m14:51:59.044127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1526381f-151a-45c3-98ae-afc715a336ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4AFE60F80>]}
[0m14:51:59.046213 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:51:59.164817 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:51:59.229370 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 1 files changed.
[0m14:51:59.229370 [debug] [MainThread]: Partial parsing: deleted file: archi://models\application\lecture.sql
[0m14:51:59.230413 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m14:51:59.353525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1526381f-151a-45c3-98ae-afc715a336ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B23E62A0>]}
[0m14:51:59.379975 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:51:59.381078 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:51:59.405046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1526381f-151a-45c3-98ae-afc715a336ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B250BA10>]}
[0m14:51:59.405046 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:51:59.406556 [info ] [MainThread]: 
[0m14:51:59.406556 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:51:59.406556 [info ] [MainThread]: 
[0m14:51:59.407560 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:51:59.410107 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:51:59.454329 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:51:59.454329 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:51:59.454329 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:51:59.465219 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m14:51:59.466248 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:51:59.469264 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:51:59.469264 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:51:59.469264 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:51:59.478660 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:51:59.479696 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:51:59.481742 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:51:59.482757 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:51:59.482757 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:51:59.491029 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:51:59.492055 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:51:59.494104 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m14:51:59.494104 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:51:59.497924 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:51:59.497924 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:51:59.498930 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:51:59.507627 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:51:59.507627 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:51:59.507627 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:51:59.509139 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:51:59.509139 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:51:59.509139 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:51:59.510163 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:51:59.510163 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:51:59.510163 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:51:59.511186 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:51:59.511186 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:51:59.511186 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:51:59.513256 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_cleansed)
[0m14:51:59.513256 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:51:59.514278 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:51:59.515299 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:51:59.515299 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:51:59.524481 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:51:59.524481 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:51:59.525505 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:51:59.525505 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:51:59.525505 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:51:59.526531 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:51:59.526531 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:51:59.526531 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:51:59.527536 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:51:59.528041 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:51:59.528041 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:51:59.528041 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:51:59.530575 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main_application)
[0m14:51:59.530575 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:51:59.531592 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:51:59.531592 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:51:59.531592 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:51:59.540783 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:51:59.541807 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:51:59.541807 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:51:59.541807 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:51:59.541807 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:51:59.541807 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:51:59.542836 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:51:59.542836 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:51:59.543878 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:51:59.543878 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:51:59.543878 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:51:59.543878 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:51:59.547012 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m14:51:59.550260 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:51:59.550260 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:51:59.550260 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:51:59.558496 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:51:59.558496 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:51:59.558496 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:51:59.576062 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:51:59.576062 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:51:59.577570 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:51:59.578094 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:51:59.579652 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_cleansed)
[0m14:51:59.581703 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:51:59.581703 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:51:59.582734 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:51:59.590948 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:51:59.590948 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:51:59.591979 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:51:59.609551 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m14:51:59.610575 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:51:59.611613 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:51:59.611613 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:51:59.613670 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main_application)
[0m14:51:59.615181 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:51:59.615181 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:51:59.616214 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:51:59.624168 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:51:59.624168 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:51:59.624168 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:51:59.648976 [debug] [ThreadPool]: SQL status: OK in 0.024 seconds
[0m14:51:59.650061 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:51:59.650061 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:51:59.650061 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:51:59.654150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1526381f-151a-45c3-98ae-afc715a336ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B23E4440>]}
[0m14:51:59.654150 [debug] [MainThread]: Using duckdb connection "master"
[0m14:51:59.654150 [debug] [MainThread]: On master: BEGIN
[0m14:51:59.655661 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:51:59.664491 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m14:51:59.664491 [debug] [MainThread]: On master: COMMIT
[0m14:51:59.664491 [debug] [MainThread]: Using duckdb connection "master"
[0m14:51:59.666002 [debug] [MainThread]: On master: COMMIT
[0m14:51:59.666002 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:51:59.666002 [debug] [MainThread]: On master: Close
[0m14:51:59.670384 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:51:59.670888 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:51:59.670888 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:51:59.671892 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:51:59.676851 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:51:59.677409 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:51:59.695333 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:51:59.696842 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:51:59.697356 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:51:59.697356 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:51:59.707403 [debug] [Thread-1 (]: SQL status: OK in 0.010 seconds
[0m14:51:59.707940 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:51:59.707940 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:51:59.709023 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:51:59.713130 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:51:59.713130 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:51:59.713130 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:51:59.715197 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:51:59.715197 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:51:59.716228 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:51:59.722912 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:51:59.722912 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:51:59.724001 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:51:59.825189 [debug] [Thread-1 (]: SQL status: OK in 0.102 seconds
[0m14:51:59.828746 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:51:59.828746 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:51:59.830253 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:51:59.831275 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:51:59.852921 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1526381f-151a-45c3-98ae-afc715a336ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B2473950>]}
[0m14:51:59.853945 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.18s]
[0m14:51:59.854485 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:51:59.855031 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:51:59.855031 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:51:59.855031 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:51:59.855031 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:51:59.857211 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:51:59.857715 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:51:59.858750 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:51:59.859777 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:51:59.859777 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:51:59.859777 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:51:59.873110 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:51:59.874180 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:51:59.874180 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:51:59.875264 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:51:59.876272 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:51:59.877280 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:51:59.877280 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:51:59.878826 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:51:59.878826 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:51:59.879887 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:51:59.879887 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:51:59.879887 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:51:59.879887 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:51:59.882436 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:51:59.884503 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:51:59.884503 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:51:59.885528 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:51:59.886575 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:51:59.906147 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1526381f-151a-45c3-98ae-afc715a336ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B2D4F200>]}
[0m14:51:59.906147 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:51:59.907153 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:51:59.907153 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:51:59.907655 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:51:59.907655 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:51:59.907655 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:51:59.909771 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:51:59.909771 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:51:59.910774 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:51:59.912286 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:51:59.912286 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:51:59.912286 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:51:59.926383 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:51:59.926383 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:51:59.926383 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:51:59.927387 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:51:59.929251 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:51:59.929251 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:51:59.929251 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:51:59.931320 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:51:59.931320 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:51:59.931320 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:51:59.932828 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:51:59.932828 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:51:59.932828 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:51:59.934892 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:51:59.935901 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:51:59.936407 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:51:59.937413 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:51:59.937918 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:51:59.957635 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1526381f-151a-45c3-98ae-afc715a336ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B2D41A30>]}
[0m14:51:59.958643 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:51:59.959148 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:51:59.959148 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:51:59.959148 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:51:59.960152 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:51:59.960152 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:51:59.961662 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:51:59.962165 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:51:59.963672 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:51:59.963672 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:51:59.964677 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:51:59.965183 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:51:59.977475 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:51:59.977983 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:51:59.977983 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:51:59.978987 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:51:59.980021 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:51:59.981054 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:51:59.981054 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:51:59.983116 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:51:59.983116 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:51:59.983116 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:51:59.984150 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:51:59.984150 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:51:59.985183 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:51:59.986694 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:51:59.987735 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:51:59.987735 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:51:59.988775 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:51:59.989802 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:52:00.009617 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1526381f-151a-45c3-98ae-afc715a336ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B3D60320>]}
[0m14:52:00.009617 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:52:00.010643 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:52:00.010643 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:52:00.010643 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:52:00.011669 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:52:00.011669 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:52:00.012695 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:52:00.013722 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:52:00.015874 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:52:00.015874 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:52:00.017382 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:52:00.017382 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:52:00.030391 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:52:00.030391 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:52:00.031412 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:52:00.031412 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:52:00.033517 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:52:00.033517 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:52:00.034536 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:52:00.035585 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:52:00.036613 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:52:00.037131 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:52:00.037640 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:52:00.037640 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:52:00.037640 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:52:00.039705 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:52:00.040740 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:52:00.040740 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:52:00.041761 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:52:00.041761 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:52:00.062442 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1526381f-151a-45c3-98ae-afc715a336ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B3D78290>]}
[0m14:52:00.063483 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:52:00.063483 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:52:00.064519 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:52:00.064519 [info ] [Thread-1 (]: 6 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m14:52:00.064519 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:52:00.065581 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:52:00.066614 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:52:00.067132 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:52:00.067650 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:52:00.069678 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:52:00.069678 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:52:00.070194 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:52:00.082930 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:52:00.082930 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:52:00.083976 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoute d'autres colonnes nécessaires
    from main.raw_contributors -- spécifie le schéma ici
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from main.raw_commits -- spécifie le schéma ici
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from raw_commits
left join raw_contributors
    on raw_contributors.id = raw_commits."author.id"
  );

[0m14:52:00.083976 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login,
        -- Ajoute d'autres colonnes nécessaires
    from main.raw_contributors -- spécifie le schéma ici
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from main.raw_commits -- spécifie le schéma ici
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.url
from raw_commits
left join raw_contributors
    on raw_contributors.id = raw_commits."author.id"
  );

[0m14:52:00.085001 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:52:00.085001 [debug] [Thread-1 (]: On model.archi.fcommits: ROLLBACK
[0m14:52:00.087537 [debug] [Thread-1 (]: Failed to rollback 'model.archi.fcommits'
[0m14:52:00.088572 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:52:00.091675 [debug] [Thread-1 (]: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Values list "raw_contributors" does not have a column named "url"
  LINE 26:     raw_contributors.url
               ^
[0m14:52:00.091675 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1526381f-151a-45c3-98ae-afc715a336ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B2420410>]}
[0m14:52:00.091675 [error] [Thread-1 (]: 6 of 7 ERROR creating sql view model main_application.fcommits ................. [[31mERROR[0m in 0.03s]
[0m14:52:00.092707 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:52:00.092707 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:52:00.092707 [debug] [Thread-4 (]: Marking all children of 'model.archi.fcommits' to be skipped because of status 'error'.  Reason: Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Values list "raw_contributors" does not have a column named "url"
  LINE 26:     raw_contributors.url
               ^.
[0m14:52:00.093736 [info ] [Thread-1 (]: 7 of 7 START sql view model main.view .......................................... [RUN]
[0m14:52:00.093736 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:52:00.094768 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:52:00.095828 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:52:00.095828 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:52:00.098394 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:52:00.098394 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:52:00.099427 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:52:00.099427 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:52:00.107587 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m14:52:00.107587 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:52:00.107587 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:52:00.108614 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:52:00.110791 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:52:00.110791 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:52:00.111327 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:52:00.112885 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:52:00.112885 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:52:00.113937 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:52:00.113937 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:52:00.113937 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:52:00.113937 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:52:00.116473 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:52:00.117477 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:52:00.117983 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:52:00.119014 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:52:00.119014 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:52:00.139758 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1526381f-151a-45c3-98ae-afc715a336ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B2C2D550>]}
[0m14:52:00.139758 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.05s]
[0m14:52:00.140786 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:52:00.140786 [debug] [MainThread]: Using duckdb connection "master"
[0m14:52:00.141816 [debug] [MainThread]: On master: BEGIN
[0m14:52:00.141816 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:52:00.155198 [debug] [MainThread]: SQL status: OK in 0.013 seconds
[0m14:52:00.155198 [debug] [MainThread]: On master: COMMIT
[0m14:52:00.155198 [debug] [MainThread]: Using duckdb connection "master"
[0m14:52:00.155198 [debug] [MainThread]: On master: COMMIT
[0m14:52:00.155198 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:52:00.156705 [debug] [MainThread]: On master: Close
[0m14:52:00.157775 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:52:00.158813 [debug] [MainThread]: Connection 'create_pytorch_data_main_application' was properly closed.
[0m14:52:00.158813 [debug] [MainThread]: Connection 'list_pytorch_data_main_application' was properly closed.
[0m14:52:00.158813 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:52:00.158813 [info ] [MainThread]: 
[0m14:52:00.159843 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.75 seconds (0.75s).
[0m14:52:00.160873 [debug] [MainThread]: Command end result
[0m14:52:00.171199 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:52:00.172215 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:52:00.175373 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:52:00.176391 [info ] [MainThread]: 
[0m14:52:00.176391 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:52:00.176391 [info ] [MainThread]: 
[0m14:52:00.177395 [error] [MainThread]:   Runtime Error in model fcommits (models\application\fcommits.sql)
  Binder Error: Values list "raw_contributors" does not have a column named "url"
  LINE 26:     raw_contributors.url
               ^
[0m14:52:00.177395 [info ] [MainThread]: 
[0m14:52:00.177898 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m14:52:00.177898 [debug] [MainThread]: Command `dbt build` failed at 14:52:00.177898 after 1.37 seconds
[0m14:52:00.178923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B2006A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B02C2C00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4B02C1400>]}
[0m14:52:00.178923 [debug] [MainThread]: Flushing usage events
[0m14:52:00.654802 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:54:04.289598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D876FD190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D875DB3B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D87571B20>]}


============================== 14:54:04.292655 | a636aff8-2986-4422-9645-f1f131f4dd3c ==============================
[0m14:54:04.292655 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:54:04.292655 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt build', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:54:04.406834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a636aff8-2986-4422-9645-f1f131f4dd3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D87743740>]}
[0m14:54:04.437762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a636aff8-2986-4422-9645-f1f131f4dd3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D87016CC0>]}
[0m14:54:04.440304 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:54:04.559551 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:54:04.623901 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:54:04.623901 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m14:54:04.748644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a636aff8-2986-4422-9645-f1f131f4dd3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D88FB3290>]}
[0m14:54:04.825340 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:54:04.827388 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:54:04.850504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a636aff8-2986-4422-9645-f1f131f4dd3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D89082720>]}
[0m14:54:04.850504 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:54:04.851535 [info ] [MainThread]: 
[0m14:54:04.852563 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:54:04.852563 [info ] [MainThread]: 
[0m14:54:04.852563 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:54:04.855663 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:54:04.900020 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:54:04.900020 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:54:04.900529 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:54:04.910114 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m14:54:04.911135 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:54:04.914321 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:54:04.914321 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:54:04.915346 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:04.923946 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:54:04.923946 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:54:04.927315 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:54:04.927315 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:54:04.928337 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:04.935931 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:04.937441 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:54:04.939448 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main)
[0m14:54:04.939448 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:54:04.943488 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:54:04.943488 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:54:04.943994 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:04.952628 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:54:04.953650 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:54:04.953650 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:54:04.953650 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:04.953650 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:54:04.954679 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:54:04.954679 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:04.954679 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:54:04.955704 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:54:04.955704 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:54:04.955704 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:04.955704 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:54:04.957806 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_application)
[0m14:54:04.959255 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:54:04.959764 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:54:04.959764 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:54:04.960769 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:04.967952 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:04.969460 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:54:04.969460 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:54:04.970484 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:04.970484 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:54:04.970484 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:54:04.970484 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:04.971510 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:54:04.971510 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:54:04.971510 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:54:04.972588 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:04.972588 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:54:04.974774 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_application, now create_pytorch_data_main_cleansed)
[0m14:54:04.974774 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:54:04.975811 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:54:04.975811 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:54:04.975811 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:04.985005 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:04.985005 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:54:04.985005 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:54:04.986020 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:04.986020 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:54:04.986020 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:54:04.987039 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:04.987039 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:54:04.987039 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:54:04.988063 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:54:04.988063 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:04.988063 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:54:04.990629 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m14:54:04.993575 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:54:04.993575 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:54:04.994592 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:54:05.003781 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:54:05.003781 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:54:05.003781 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:54:05.021040 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:54:05.022063 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:54:05.022063 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:54:05.022063 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:54:05.025662 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_application)
[0m14:54:05.027710 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:54:05.027710 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:54:05.027710 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:05.035887 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:05.035887 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:54:05.036908 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:54:05.054166 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:54:05.054671 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:54:05.054671 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:54:05.055697 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:54:05.057742 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_application, now list_pytorch_data_main_cleansed)
[0m14:54:05.058758 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:54:05.058758 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:54:05.059764 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:05.067447 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:05.068481 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:54:05.068481 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:54:05.085368 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:54:05.085368 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:54:05.086655 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:54:05.086655 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:54:05.089719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a636aff8-2986-4422-9645-f1f131f4dd3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D897D8260>]}
[0m14:54:05.090224 [debug] [MainThread]: Using duckdb connection "master"
[0m14:54:05.090224 [debug] [MainThread]: On master: BEGIN
[0m14:54:05.090224 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:54:05.098351 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m14:54:05.099355 [debug] [MainThread]: On master: COMMIT
[0m14:54:05.099860 [debug] [MainThread]: Using duckdb connection "master"
[0m14:54:05.099860 [debug] [MainThread]: On master: COMMIT
[0m14:54:05.100390 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:54:05.100390 [debug] [MainThread]: On master: Close
[0m14:54:05.102968 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:54:05.102968 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:54:05.102968 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:54:05.103990 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:54:05.108584 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:54:05.108584 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:54:05.124965 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:54:05.125969 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:05.125969 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:54:05.127162 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:54:05.135863 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:54:05.136368 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:05.136368 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:54:05.136368 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.139929 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:05.140946 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:54:05.141549 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.143086 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:05.143086 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:54:05.143086 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.149697 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:54:05.150729 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:05.150729 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:54:05.251861 [debug] [Thread-1 (]: SQL status: OK in 0.101 seconds
[0m14:54:05.255664 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:05.255664 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:54:05.256684 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:05.258134 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:54:05.279427 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a636aff8-2986-4422-9645-f1f131f4dd3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D89048260>]}
[0m14:54:05.279427 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.17s]
[0m14:54:05.280520 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:54:05.280520 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:54:05.280520 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:54:05.281525 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:54:05.281525 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:54:05.282561 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:54:05.283587 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:54:05.285095 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:54:05.286098 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:05.286098 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:54:05.286098 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:05.299412 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:05.299412 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:05.300433 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:54:05.300433 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.302487 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:05.302487 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:54:05.302487 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.303523 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:05.305032 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:54:05.305032 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.306064 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:54:05.306064 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:05.306064 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:54:05.308120 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:05.309630 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:05.309630 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:54:05.310661 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:05.311738 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:54:05.331260 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a636aff8-2986-4422-9645-f1f131f4dd3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D898CEE40>]}
[0m14:54:05.331260 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:54:05.332283 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:54:05.332283 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:54:05.332283 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:54:05.333384 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:54:05.333384 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:54:05.334462 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:54:05.334462 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:54:05.337005 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:54:05.337005 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:05.338034 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:54:05.338034 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:05.350819 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:05.350819 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:05.351843 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:54:05.351843 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.353353 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:05.354377 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:54:05.354377 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.355407 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:05.356413 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:54:05.356917 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.357922 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:54:05.357922 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:05.357922 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:54:05.359465 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:05.360493 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:05.360493 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:54:05.361519 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:05.362545 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:54:05.381459 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a636aff8-2986-4422-9645-f1f131f4dd3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D898C1100>]}
[0m14:54:05.382481 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:54:05.382481 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:54:05.383499 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:54:05.383499 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:54:05.383499 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:54:05.384522 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:54:05.385557 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:54:05.385557 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:54:05.388107 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:54:05.388107 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:05.388107 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:54:05.388107 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:05.401965 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:05.401965 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:05.402984 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:54:05.402984 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.405116 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:05.405116 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:54:05.406121 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.407632 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:05.407632 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:54:05.407632 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.408658 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:54:05.409664 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:05.409664 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:54:05.411191 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:05.412213 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:05.412213 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:54:05.413240 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:05.414289 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:54:05.433785 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a636aff8-2986-4422-9645-f1f131f4dd3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D8986EFF0>]}
[0m14:54:05.434814 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:54:05.434814 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:54:05.434814 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:54:05.435841 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:54:05.435841 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:54:05.435841 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:54:05.436890 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:54:05.438426 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:54:05.439935 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:54:05.440959 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:05.440959 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:54:05.440959 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:05.454227 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:05.455253 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:05.455253 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:54:05.455253 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.457306 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:05.457306 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:54:05.457306 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.459822 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:05.459822 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:54:05.460327 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.461355 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:54:05.461355 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:05.461355 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:54:05.462382 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:05.464435 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:05.464435 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:54:05.465462 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:05.466483 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:54:05.485461 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a636aff8-2986-4422-9645-f1f131f4dd3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D8988F950>]}
[0m14:54:05.486483 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:54:05.486483 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:54:05.487501 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:54:05.487501 [info ] [Thread-1 (]: 6 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m14:54:05.487501 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:54:05.488530 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:54:05.489536 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:54:05.489536 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:54:05.491598 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:54:05.491598 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:54:05.492624 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:54:05.492624 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:05.504693 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:05.505714 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:54:05.505714 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login
    from main.raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from main.raw_commits -- spécifie le schéma ici
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.'url'
from raw_commits
left join raw_contributors
    on raw_contributors.id = raw_commits."author.id"
  );

[0m14:54:05.506736 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login
    from main.raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from main.raw_commits -- spécifie le schéma ici
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
    raw_contributors.'url'
from raw_commits
left join raw_contributors
    on raw_contributors.id = raw_commits."author.id"
  );

[0m14:54:05.506736 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:54:05.506736 [debug] [Thread-1 (]: On model.archi.fcommits: ROLLBACK
[0m14:54:05.510293 [debug] [Thread-1 (]: Failed to rollback 'model.archi.fcommits'
[0m14:54:05.510293 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:54:05.513381 [debug] [Thread-1 (]: Runtime Error in model fcommits (models\application\fcommits.sql)
  Parser Error: syntax error at or near "'url'"
[0m14:54:05.513381 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a636aff8-2986-4422-9645-f1f131f4dd3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D8988B260>]}
[0m14:54:05.513381 [error] [Thread-1 (]: 6 of 7 ERROR creating sql view model main_application.fcommits ................. [[31mERROR[0m in 0.03s]
[0m14:54:05.514398 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:54:05.514398 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:54:05.514398 [debug] [Thread-4 (]: Marking all children of 'model.archi.fcommits' to be skipped because of status 'error'.  Reason: Runtime Error in model fcommits (models\application\fcommits.sql)
  Parser Error: syntax error at or near "'url'".
[0m14:54:05.515475 [info ] [Thread-1 (]: 7 of 7 START sql view model main.view .......................................... [RUN]
[0m14:54:05.515475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:54:05.516513 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:54:05.517550 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:54:05.518577 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:54:05.520085 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:54:05.520593 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:05.520593 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:54:05.521124 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:05.528281 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m14:54:05.528281 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:05.529789 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:54:05.529789 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.531893 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:05.531893 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:54:05.531893 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.533945 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:05.533945 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:54:05.533945 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:05.534970 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:54:05.534970 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:05.535975 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:54:05.537505 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:05.538535 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:05.538535 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:54:05.539539 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:05.540042 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:54:05.559612 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a636aff8-2986-4422-9645-f1f131f4dd3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D8988F8F0>]}
[0m14:54:05.560646 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.04s]
[0m14:54:05.560646 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:54:05.561652 [debug] [MainThread]: Using duckdb connection "master"
[0m14:54:05.561652 [debug] [MainThread]: On master: BEGIN
[0m14:54:05.561652 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:54:05.574172 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m14:54:05.575205 [debug] [MainThread]: On master: COMMIT
[0m14:54:05.575205 [debug] [MainThread]: Using duckdb connection "master"
[0m14:54:05.575205 [debug] [MainThread]: On master: COMMIT
[0m14:54:05.575205 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:54:05.576236 [debug] [MainThread]: On master: Close
[0m14:54:05.577264 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:54:05.578310 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m14:54:05.578310 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m14:54:05.578310 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:54:05.578310 [info ] [MainThread]: 
[0m14:54:05.578310 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.73 seconds (0.73s).
[0m14:54:05.579817 [debug] [MainThread]: Command end result
[0m14:54:05.591192 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:54:05.591192 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:54:05.595837 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:54:05.595837 [info ] [MainThread]: 
[0m14:54:05.595837 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m14:54:05.595837 [info ] [MainThread]: 
[0m14:54:05.596856 [error] [MainThread]:   Runtime Error in model fcommits (models\application\fcommits.sql)
  Parser Error: syntax error at or near "'url'"
[0m14:54:05.596856 [info ] [MainThread]: 
[0m14:54:05.596856 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m14:54:05.597882 [debug] [MainThread]: Command `dbt build` failed at 14:54:05.597882 after 1.39 seconds
[0m14:54:05.597882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D873AC560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D878B9A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025D87A839B0>]}
[0m14:54:05.597882 [debug] [MainThread]: Flushing usage events
[0m14:54:06.088187 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:54:34.092287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEB9732EA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEB97328D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEB97319D0>]}


============================== 14:54:34.095373 | 9b1010f2-73f4-4d10-b30d-4ae1e4182e45 ==============================
[0m14:54:34.095373 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:54:34.095373 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:54:34.210005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9b1010f2-73f4-4d10-b30d-4ae1e4182e45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEB9C7F140>]}
[0m14:54:34.241327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9b1010f2-73f4-4d10-b30d-4ae1e4182e45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEB9C532F0>]}
[0m14:54:34.244348 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:54:34.366218 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:54:34.431165 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m14:54:34.431673 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m14:54:34.556077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9b1010f2-73f4-4d10-b30d-4ae1e4182e45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEBB31A120>]}
[0m14:54:34.582196 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:54:34.583221 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:54:34.606672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9b1010f2-73f4-4d10-b30d-4ae1e4182e45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEBB416540>]}
[0m14:54:34.606672 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:54:34.607712 [info ] [MainThread]: 
[0m14:54:34.608735 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:54:34.608735 [info ] [MainThread]: 
[0m14:54:34.608735 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:54:34.612277 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:54:34.656036 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:54:34.656036 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:54:34.656036 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:54:34.666789 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m14:54:34.667816 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:54:34.670355 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:54:34.671376 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:54:34.671902 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:34.680009 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:54:34.690533 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:54:34.693810 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:54:34.693810 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:54:34.693810 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:34.703005 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:54:34.704013 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:54:34.706067 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m14:54:34.706067 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:54:34.709619 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:54:34.710157 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:54:34.710157 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:34.718365 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:34.718365 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:54:34.719875 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:54:34.719875 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:34.719875 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:54:34.720899 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:54:34.720899 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:34.720899 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:54:34.721928 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:54:34.721928 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:54:34.721928 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:34.721928 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:54:34.723992 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main_application)
[0m14:54:34.723992 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:54:34.725110 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:54:34.726122 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:54:34.726122 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:34.734875 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:54:34.735884 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:54:34.735884 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:54:34.736392 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:34.736392 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:54:34.736392 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:54:34.736392 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:34.737425 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:54:34.737425 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:54:34.737425 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:54:34.738457 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:34.738457 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:54:34.740483 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_application, now create_pytorch_data_main)
[0m14:54:34.741033 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:54:34.742040 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:54:34.742548 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:54:34.742548 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:34.750248 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:34.751279 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:54:34.751279 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:54:34.752308 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:34.752308 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:54:34.752308 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:54:34.752308 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:34.753340 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:54:34.753870 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:54:34.753870 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:54:34.754415 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:34.754415 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:54:34.756522 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m14:54:34.760065 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:54:34.760065 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:54:34.760065 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:54:34.768169 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:34.769192 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:54:34.769192 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:54:34.787075 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m14:54:34.787579 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:54:34.788583 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:54:34.788583 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:54:34.791121 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main_application)
[0m14:54:34.793176 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:54:34.793176 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:54:34.793176 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:34.801321 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:34.801321 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:54:34.801321 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:54:34.818764 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:54:34.820274 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:54:34.820274 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:54:34.820274 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:54:34.823368 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_application, now list_pytorch_data_main)
[0m14:54:34.824389 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:54:34.824389 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:54:34.824389 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:34.832566 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:34.832566 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:54:34.833589 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:54:34.848441 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:54:34.849984 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:54:34.851013 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:54:34.851013 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:54:34.854284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b1010f2-73f4-4d10-b30d-4ae1e4182e45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEB7006030>]}
[0m14:54:34.854284 [debug] [MainThread]: Using duckdb connection "master"
[0m14:54:34.854284 [debug] [MainThread]: On master: BEGIN
[0m14:54:34.855310 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:54:34.862882 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m14:54:34.862882 [debug] [MainThread]: On master: COMMIT
[0m14:54:34.862882 [debug] [MainThread]: Using duckdb connection "master"
[0m14:54:34.863906 [debug] [MainThread]: On master: COMMIT
[0m14:54:34.863906 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:54:34.863906 [debug] [MainThread]: On master: Close
[0m14:54:34.866524 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:54:34.867055 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:54:34.867055 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:54:34.867055 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:54:34.871740 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:54:34.872743 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:54:34.889514 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:54:34.890025 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:34.890025 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:54:34.891029 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:54:34.899774 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:54:34.900279 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:34.900279 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:54:34.900279 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:34.904376 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:34.904376 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:54:34.905397 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:34.906424 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:34.906424 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:54:34.907430 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:34.914298 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:54:34.914298 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:34.914298 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:54:35.016446 [debug] [Thread-1 (]: SQL status: OK in 0.102 seconds
[0m14:54:35.020036 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:35.020539 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:54:35.021606 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:35.022715 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:54:35.043680 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b1010f2-73f4-4d10-b30d-4ae1e4182e45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEBB2B8290>]}
[0m14:54:35.044184 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.17s]
[0m14:54:35.044184 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:54:35.044184 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:54:35.045386 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:54:35.045386 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:54:35.045386 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:54:35.046539 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:54:35.047565 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:54:35.049077 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:54:35.050082 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:35.050082 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:54:35.050082 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:35.063091 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:35.063091 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:35.064113 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:54:35.064113 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.066193 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:35.066193 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:54:35.067216 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.068238 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:35.068238 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:54:35.068238 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.070259 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:54:35.070259 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:35.070770 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:54:35.071793 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:35.073863 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:35.073863 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:54:35.074882 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:35.075904 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:54:35.095834 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b1010f2-73f4-4d10-b30d-4ae1e4182e45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEBBB37920>]}
[0m14:54:35.095834 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:54:35.096838 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:54:35.096838 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:54:35.096838 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:54:35.097868 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:54:35.097868 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:54:35.098897 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:54:35.099902 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:54:35.101446 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:54:35.101446 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:35.101446 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:54:35.101446 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:35.115746 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:35.115746 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:35.115746 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:54:35.116765 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.118818 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:35.118818 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:54:35.118818 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.120841 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:35.121350 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:54:35.121350 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.122372 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:54:35.122372 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:35.122372 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:54:35.124441 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:35.125464 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:35.125464 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:54:35.126551 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:35.127570 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:54:35.147454 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b1010f2-73f4-4d10-b30d-4ae1e4182e45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEBBB4CAD0>]}
[0m14:54:35.147965 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:54:35.147965 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:54:35.147965 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:54:35.148969 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:54:35.148969 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:54:35.148969 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:54:35.150240 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:54:35.151264 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:54:35.152291 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:54:35.153312 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:35.153312 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:54:35.153312 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:35.166656 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:35.166656 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:35.166656 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:54:35.168166 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.169187 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:35.169187 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:54:35.170193 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.171720 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:35.171720 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:54:35.171720 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.172745 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:54:35.173770 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:35.173770 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:54:35.174820 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:35.175845 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:35.176870 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:54:35.177874 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:35.178379 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:54:35.196650 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b1010f2-73f4-4d10-b30d-4ae1e4182e45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEBBAF81D0>]}
[0m14:54:35.196650 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:54:35.198159 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:54:35.198159 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:54:35.198159 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:54:35.199197 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:54:35.199197 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:54:35.200706 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:54:35.201729 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:54:35.203893 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:54:35.203893 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:35.204916 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:54:35.204971 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:35.217249 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:35.218270 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:35.218270 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:54:35.218270 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.220806 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:35.220806 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:54:35.220806 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.222975 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:35.222975 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:54:35.223999 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.223999 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:54:35.223999 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:35.223999 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:54:35.226041 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:35.227597 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:35.227597 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:54:35.228640 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:35.228640 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:54:35.248578 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b1010f2-73f4-4d10-b30d-4ae1e4182e45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEBBAF8D40>]}
[0m14:54:35.248578 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:54:35.250088 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:54:35.250088 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:54:35.250088 [info ] [Thread-1 (]: 6 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m14:54:35.251269 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:54:35.251269 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:54:35.252307 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:54:35.253338 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:54:35.254367 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:54:35.255392 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:54:35.255392 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:54:35.255392 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:35.268672 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:35.268672 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:54:35.268672 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login
    from main.raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from main.raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
from raw_commits
left join raw_contributors
    on raw_contributors.id = raw_commits."author.id"
  );

[0m14:54:35.270180 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.271209 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:54:35.272236 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
alter view "pytorch_data"."main_application"."fcommits__dbt_tmp" rename to "fcommits"
[0m14:54:35.272236 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.273253 [debug] [Thread-1 (]: On model.archi.fcommits: COMMIT
[0m14:54:35.273253 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:54:35.273253 [debug] [Thread-1 (]: On model.archi.fcommits: COMMIT
[0m14:54:35.274298 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:35.275349 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:54:35.276857 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
drop view if exists "pytorch_data"."main_application"."fcommits__dbt_backup" cascade
[0m14:54:35.276857 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.277922 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:54:35.297941 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b1010f2-73f4-4d10-b30d-4ae1e4182e45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEBBB2EEA0>]}
[0m14:54:35.298469 [info ] [Thread-1 (]: 6 of 7 OK created sql view model main_application.fcommits ..................... [[32mOK[0m in 0.05s]
[0m14:54:35.298469 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:54:35.298469 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:54:35.298469 [info ] [Thread-1 (]: 7 of 7 START sql view model main.view .......................................... [RUN]
[0m14:54:35.299980 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:54:35.299980 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:54:35.301004 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:54:35.302026 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:54:35.304092 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:54:35.304092 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:35.304092 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:54:35.305138 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:35.318451 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:35.318973 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:35.318973 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:54:35.318973 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.321511 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:35.321511 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:54:35.321511 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.323558 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:35.323558 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:54:35.323558 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:35.324585 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:54:35.325609 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:35.325609 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:54:35.326631 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:35.328723 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:35.329245 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:54:35.330250 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:35.330756 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:54:35.350651 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b1010f2-73f4-4d10-b30d-4ae1e4182e45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEBCB626C0>]}
[0m14:54:35.350651 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.05s]
[0m14:54:35.351654 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:54:35.351654 [debug] [MainThread]: Using duckdb connection "master"
[0m14:54:35.352701 [debug] [MainThread]: On master: BEGIN
[0m14:54:35.352701 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:54:35.364967 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m14:54:35.364967 [debug] [MainThread]: On master: COMMIT
[0m14:54:35.364967 [debug] [MainThread]: Using duckdb connection "master"
[0m14:54:35.365994 [debug] [MainThread]: On master: COMMIT
[0m14:54:35.365994 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:54:35.365994 [debug] [MainThread]: On master: Close
[0m14:54:35.368069 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:54:35.368069 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m14:54:35.369074 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m14:54:35.369074 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:54:35.369578 [info ] [MainThread]: 
[0m14:54:35.369578 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.76 seconds (0.76s).
[0m14:54:35.370089 [debug] [MainThread]: Command end result
[0m14:54:35.380267 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:54:35.381303 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:54:35.384373 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:54:35.384373 [info ] [MainThread]: 
[0m14:54:35.385394 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:54:35.385394 [info ] [MainThread]: 
[0m14:54:35.385394 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m14:54:35.386416 [debug] [MainThread]: Command `dbt build` succeeded at 14:54:35.386416 after 1.38 seconds
[0m14:54:35.386416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEB991CF50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEB9953FB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DEB9953860>]}
[0m14:54:35.386416 [debug] [MainThread]: Flushing usage events
[0m14:54:35.831091 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:54:40.347226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA44580470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA43DB3AA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA43DB3980>]}


============================== 14:54:40.350291 | 25402fc7-ecfd-469c-acca-4da59d802f41 ==============================
[0m14:54:40.350291 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:54:40.350856 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:54:40.462826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '25402fc7-ecfd-469c-acca-4da59d802f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA449231A0>]}
[0m14:54:40.493714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '25402fc7-ecfd-469c-acca-4da59d802f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA443F1C10>]}
[0m14:54:40.495764 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:54:40.615995 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:54:40.681315 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:54:40.682342 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:54:40.695131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '25402fc7-ecfd-469c-acca-4da59d802f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA45C111C0>]}
[0m14:54:40.724218 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:54:40.725291 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:54:40.740355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '25402fc7-ecfd-469c-acca-4da59d802f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA45A918E0>]}
[0m14:54:40.740355 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:54:40.740355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '25402fc7-ecfd-469c-acca-4da59d802f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA44910290>]}
[0m14:54:40.741393 [info ] [MainThread]: 
[0m14:54:40.742901 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:54:40.742901 [info ] [MainThread]: 
[0m14:54:40.742901 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:54:40.745987 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:54:40.788834 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:54:40.788834 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:54:40.788834 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:54:40.800084 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m14:54:40.835712 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:54:40.838822 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:54:40.838822 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:54:40.838822 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:40.848093 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:54:40.849128 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:54:40.851660 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:54:40.852691 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:54:40.852691 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:40.860859 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:40.861910 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:54:40.862938 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m14:54:40.863962 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:54:40.867532 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:54:40.867532 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:54:40.868066 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:40.875740 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:40.876765 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:54:40.876765 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:54:40.876765 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:40.877879 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:54:40.877879 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:54:40.878407 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:40.878939 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:54:40.878939 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:54:40.878939 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:54:40.878939 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:40.878939 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:54:40.881485 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main)
[0m14:54:40.881485 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:54:40.882518 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:54:40.883556 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:54:40.883556 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:40.891770 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:40.892856 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:54:40.892856 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:54:40.892856 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:40.893882 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:54:40.893882 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:54:40.893882 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:40.894910 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:54:40.894910 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:54:40.894910 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:54:40.894910 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:40.894910 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:54:40.897474 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_application)
[0m14:54:40.897474 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:54:40.899041 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:54:40.899041 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:54:40.899041 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:40.907768 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:40.907768 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:54:40.908773 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:54:40.908773 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:40.909315 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:54:40.909315 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:54:40.909946 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:40.910456 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:54:40.910456 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:54:40.910970 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:54:40.910970 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:54:40.910970 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:54:40.913031 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m14:54:40.917149 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:54:40.917149 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:54:40.917149 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:54:40.925911 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:40.925911 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:54:40.925911 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:54:40.943726 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:54:40.943726 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:54:40.944760 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:54:40.944760 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:54:40.947820 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main)
[0m14:54:40.949363 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:54:40.949363 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:54:40.949363 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:40.958697 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:54:40.958697 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:54:40.958697 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:54:40.976441 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:54:40.977466 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:54:40.977466 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:54:40.978504 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:54:40.981042 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_application)
[0m14:54:40.982097 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:54:40.983119 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:54:40.983119 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:54:40.990846 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:54:40.991869 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:54:40.991869 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:54:41.008226 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:54:41.009250 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:54:41.009250 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:54:41.009250 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:54:41.012843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '25402fc7-ecfd-469c-acca-4da59d802f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA45C10230>]}
[0m14:54:41.012843 [debug] [MainThread]: Using duckdb connection "master"
[0m14:54:41.012843 [debug] [MainThread]: On master: BEGIN
[0m14:54:41.012843 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:54:41.022020 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m14:54:41.022551 [debug] [MainThread]: On master: COMMIT
[0m14:54:41.022551 [debug] [MainThread]: Using duckdb connection "master"
[0m14:54:41.022551 [debug] [MainThread]: On master: COMMIT
[0m14:54:41.023078 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:54:41.023078 [debug] [MainThread]: On master: Close
[0m14:54:41.025610 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:54:41.025610 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:54:41.026635 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:54:41.026635 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:54:41.031240 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:54:41.032266 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:54:41.050134 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:54:41.050134 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:41.050134 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:54:41.051160 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:54:41.058821 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:54:41.058821 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:41.060335 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:54:41.060335 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.064541 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:41.064541 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:54:41.064541 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.066057 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:41.066057 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:54:41.067094 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.073754 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:54:41.074263 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:41.074263 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:54:41.176368 [debug] [Thread-1 (]: SQL status: OK in 0.102 seconds
[0m14:54:41.179445 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:54:41.179445 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:54:41.180957 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:41.182073 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:54:41.203257 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25402fc7-ecfd-469c-acca-4da59d802f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA461206E0>]}
[0m14:54:41.203257 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.17s]
[0m14:54:41.203257 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:54:41.203257 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:54:41.204768 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:54:41.204768 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:54:41.204768 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:54:41.206829 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:54:41.206829 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:54:41.208909 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:54:41.208909 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:41.210416 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:54:41.210416 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:41.222757 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:41.223782 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:41.223782 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:54:41.223782 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.225296 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:41.226320 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:54:41.226320 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.227326 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:41.228567 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:54:41.228567 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.228567 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:54:41.230079 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:41.230079 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:54:41.231110 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:41.233247 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:54:41.233247 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:54:41.234265 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:41.235780 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:54:41.254576 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25402fc7-ecfd-469c-acca-4da59d802f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA462308C0>]}
[0m14:54:41.256088 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:54:41.256088 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:54:41.256088 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:54:41.257121 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:54:41.257121 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:54:41.257121 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:54:41.259193 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:54:41.259193 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:54:41.261723 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:54:41.261723 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:41.262756 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:54:41.262756 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:41.275060 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:41.275060 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:41.276568 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:54:41.276568 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.278651 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:41.278651 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:54:41.278651 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.281222 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:41.281222 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:54:41.281222 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.282290 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:54:41.282290 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:41.283324 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:54:41.284359 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:41.285391 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:54:41.285391 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:54:41.286903 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:41.287931 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:54:41.307846 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25402fc7-ecfd-469c-acca-4da59d802f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA45D0B5F0>]}
[0m14:54:41.308877 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:54:41.309457 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:54:41.309457 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:54:41.309457 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:54:41.310265 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:54:41.310265 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:54:41.312323 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:54:41.312323 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:54:41.314383 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:54:41.315408 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:41.315408 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:54:41.315408 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:41.327789 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:41.328826 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:41.328826 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:54:41.330009 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.331044 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:41.332071 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:54:41.332071 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.333096 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:41.334137 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:54:41.334137 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.335163 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:54:41.335163 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:41.335163 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:54:41.336673 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:41.338183 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:54:41.338183 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:54:41.339220 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:41.340229 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:54:41.360087 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25402fc7-ecfd-469c-acca-4da59d802f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA461E9BB0>]}
[0m14:54:41.360595 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:54:41.360595 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:54:41.360595 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:54:41.361627 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:54:41.361627 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:54:41.361627 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:54:41.363700 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:54:41.363700 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:54:41.366230 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:54:41.367254 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:41.367254 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:54:41.368291 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:41.380108 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:41.381140 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:41.381140 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:54:41.381140 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.383223 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:41.383223 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:54:41.384249 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.385276 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:41.385276 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:54:41.386282 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.386282 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:54:41.387339 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:41.387339 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:54:41.388368 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:41.390398 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:54:41.390398 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:54:41.391429 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:41.391966 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:54:41.412369 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25402fc7-ecfd-469c-acca-4da59d802f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA46252510>]}
[0m14:54:41.412369 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:54:41.413373 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:54:41.413373 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:54:41.413373 [info ] [Thread-1 (]: 6 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m14:54:41.414398 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:54:41.414398 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:54:41.415424 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:54:41.415424 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:54:41.418016 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:54:41.419037 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:54:41.419037 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:54:41.419037 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:41.431898 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:41.432487 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:54:41.432487 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login
    from main.raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from main.raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
from raw_commits
left join raw_contributors
    on raw_contributors.id = raw_commits."author.id"
  );

[0m14:54:41.432992 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.435044 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:54:41.435044 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
alter view "pytorch_data"."main_application"."fcommits" rename to "fcommits__dbt_backup"
[0m14:54:41.435044 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.436070 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:54:41.437581 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
alter view "pytorch_data"."main_application"."fcommits__dbt_tmp" rename to "fcommits"
[0m14:54:41.437581 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.438618 [debug] [Thread-1 (]: On model.archi.fcommits: COMMIT
[0m14:54:41.438618 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:54:41.438618 [debug] [Thread-1 (]: On model.archi.fcommits: COMMIT
[0m14:54:41.440129 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:41.441242 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:54:41.442295 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
drop view if exists "pytorch_data"."main_application"."fcommits__dbt_backup" cascade
[0m14:54:41.442821 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:41.443355 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:54:41.463395 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25402fc7-ecfd-469c-acca-4da59d802f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA462087A0>]}
[0m14:54:41.463395 [info ] [Thread-1 (]: 6 of 7 OK created sql view model main_application.fcommits ..................... [[32mOK[0m in 0.05s]
[0m14:54:41.464473 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:54:41.464473 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:54:41.464473 [info ] [Thread-1 (]: 7 of 7 START sql view model main.view .......................................... [RUN]
[0m14:54:41.465505 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:54:41.465505 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:54:41.466530 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:54:41.467552 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:54:41.468590 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:54:41.470101 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:41.470101 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:54:41.471127 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:54:41.483910 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:54:41.483910 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:41.483910 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:54:41.484940 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.486993 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:41.486993 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:54:41.488011 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.490041 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:41.490545 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:54:41.490545 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:54:41.491562 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:54:41.491562 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:41.492590 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:54:41.492590 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:41.494103 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:54:41.495147 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:54:41.496183 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:54:41.496183 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:54:41.516748 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25402fc7-ecfd-469c-acca-4da59d802f41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA4625C530>]}
[0m14:54:41.516748 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.05s]
[0m14:54:41.517771 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:54:41.517771 [debug] [MainThread]: Using duckdb connection "master"
[0m14:54:41.518795 [debug] [MainThread]: On master: BEGIN
[0m14:54:41.518795 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:54:41.531097 [debug] [MainThread]: SQL status: OK in 0.013 seconds
[0m14:54:41.532132 [debug] [MainThread]: On master: COMMIT
[0m14:54:41.532132 [debug] [MainThread]: Using duckdb connection "master"
[0m14:54:41.532132 [debug] [MainThread]: On master: COMMIT
[0m14:54:41.532132 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:54:41.533164 [debug] [MainThread]: On master: Close
[0m14:54:41.534198 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:54:41.535205 [debug] [MainThread]: Connection 'create_pytorch_data_main_application' was properly closed.
[0m14:54:41.535205 [debug] [MainThread]: Connection 'list_pytorch_data_main_application' was properly closed.
[0m14:54:41.535724 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:54:41.535724 [info ] [MainThread]: 
[0m14:54:41.535724 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.79 seconds (0.79s).
[0m14:54:41.537234 [debug] [MainThread]: Command end result
[0m14:54:41.547472 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:54:41.548492 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:54:41.552035 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:54:41.552035 [info ] [MainThread]: 
[0m14:54:41.552035 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:54:41.553057 [info ] [MainThread]: 
[0m14:54:41.553057 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m14:54:41.553057 [debug] [MainThread]: Command `dbt run` succeeded at 14:54:41.553057 after 1.29 seconds
[0m14:54:41.554077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA4448E4B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA445DFA40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DA43CD2EA0>]}
[0m14:54:41.554077 [debug] [MainThread]: Flushing usage events
[0m14:54:42.038414 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:55:27.832871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002937E935A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293018C9700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293018CBFE0>]}


============================== 14:55:27.834937 | 7a02654d-b7ee-41d4-8a29-42845c0c5de9 ==============================
[0m14:55:27.834937 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:55:27.835965 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:55:27.946845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7a02654d-b7ee-41d4-8a29-42845c0c5de9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029301F977D0>]}
[0m14:55:27.977073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7a02654d-b7ee-41d4-8a29-42845c0c5de9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002930159DD00>]}
[0m14:55:27.979103 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:55:28.091237 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:55:28.153283 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:55:28.153283 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:55:28.167132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7a02654d-b7ee-41d4-8a29-42845c0c5de9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002930319FE60>]}
[0m14:55:28.193732 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:55:28.194756 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:55:28.217306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7a02654d-b7ee-41d4-8a29-42845c0c5de9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293034D5220>]}
[0m14:55:28.218328 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:55:28.219839 [info ] [MainThread]: 
[0m14:55:28.219839 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:55:28.219839 [info ] [MainThread]: 
[0m14:55:28.220844 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:55:28.223413 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:55:28.266032 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:55:28.266032 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:55:28.266032 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:55:28.275917 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m14:55:28.276942 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:55:28.280010 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:55:28.281014 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:55:28.281014 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:28.289854 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:55:28.289854 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:55:28.293422 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:55:28.293422 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:55:28.293422 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:28.302077 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:55:28.303121 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:55:28.305176 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_application)
[0m14:55:28.305176 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:55:28.309270 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:55:28.309270 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:55:28.309270 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:28.318019 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:55:28.318019 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:55:28.319047 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:55:28.319047 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:28.319047 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:55:28.319047 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:55:28.320077 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:28.320077 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:55:28.320077 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:55:28.321081 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:55:28.321081 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:28.321585 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:55:28.323094 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_application, now create_pytorch_data_main_cleansed)
[0m14:55:28.323094 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:55:28.325119 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:55:28.326142 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:55:28.326142 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:28.334257 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:55:28.334257 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:55:28.335766 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:55:28.335766 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:28.335766 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:55:28.335766 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:55:28.336834 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:28.336834 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:55:28.337861 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:55:28.337861 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:55:28.337861 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:28.337861 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:55:28.339909 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main)
[0m14:55:28.339909 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:55:28.341415 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:55:28.341415 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:55:28.341415 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:28.351162 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:55:28.351665 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:55:28.351665 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:55:28.351665 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:28.351665 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:55:28.351665 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:55:28.353174 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:28.353174 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:55:28.353174 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:55:28.354204 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:55:28.354204 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:28.354204 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:55:28.356274 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_application'
[0m14:55:28.359357 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:55:28.359357 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:55:28.359357 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:55:28.368593 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:55:28.368593 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:55:28.368593 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:55:28.386000 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:55:28.387029 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:55:28.387029 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:55:28.388057 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:55:28.390121 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_application, now list_pytorch_data_main_cleansed)
[0m14:55:28.391633 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:55:28.391633 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:55:28.391633 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:28.400820 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:55:28.400820 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:55:28.401326 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:55:28.418093 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:55:28.419124 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:55:28.419124 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:55:28.419124 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:55:28.421665 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main)
[0m14:55:28.423713 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:55:28.423713 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:55:28.423713 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:28.432341 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:55:28.432341 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:55:28.432341 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:55:28.448729 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:55:28.449751 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:55:28.449751 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:55:28.449751 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:55:28.454333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a02654d-b7ee-41d4-8a29-42845c0c5de9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029301F26F30>]}
[0m14:55:28.454333 [debug] [MainThread]: Using duckdb connection "master"
[0m14:55:28.454333 [debug] [MainThread]: On master: BEGIN
[0m14:55:28.454333 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:55:28.463037 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m14:55:28.463037 [debug] [MainThread]: On master: COMMIT
[0m14:55:28.463037 [debug] [MainThread]: Using duckdb connection "master"
[0m14:55:28.464067 [debug] [MainThread]: On master: COMMIT
[0m14:55:28.464067 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:55:28.464067 [debug] [MainThread]: On master: Close
[0m14:55:28.466603 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:55:28.466603 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:55:28.467633 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:55:28.467633 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:55:28.471197 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:55:28.472304 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:55:28.489310 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:55:28.489310 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:55:28.489310 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:55:28.489310 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:55:28.499552 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:55:28.499552 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:55:28.499552 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:55:28.499552 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.504483 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:55:28.504483 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:55:28.504483 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.507033 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:55:28.507033 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:55:28.507033 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.513667 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:55:28.514699 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:55:28.514699 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:55:28.615415 [debug] [Thread-1 (]: SQL status: OK in 0.101 seconds
[0m14:55:28.620652 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:55:28.620652 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:55:28.622166 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:28.622671 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:55:28.643091 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a02654d-b7ee-41d4-8a29-42845c0c5de9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293013B52E0>]}
[0m14:55:28.644135 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.17s]
[0m14:55:28.644135 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:55:28.644135 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:55:28.645165 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:55:28.645165 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:55:28.645165 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:55:28.647213 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:55:28.647213 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:55:28.649752 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:55:28.649752 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:55:28.649752 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:55:28.649752 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:55:28.662539 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:55:28.663562 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:55:28.663562 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:55:28.664590 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.665615 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:55:28.665615 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:55:28.666639 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.667663 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:55:28.668688 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:55:28.668688 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.668688 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:55:28.668688 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:55:28.670202 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:55:28.671598 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:28.672632 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:55:28.672632 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:55:28.673761 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:28.674766 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:55:28.693304 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a02654d-b7ee-41d4-8a29-42845c0c5de9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029303BEEE40>]}
[0m14:55:28.694330 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:55:28.694330 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:55:28.695355 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:55:28.695355 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:55:28.695355 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:55:28.696378 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:55:28.697414 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:55:28.697414 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:55:28.699468 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:55:28.699468 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:55:28.699468 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:55:28.700978 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:55:28.713189 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:55:28.714221 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:55:28.714221 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:55:28.715247 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.716270 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:55:28.717299 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:55:28.717299 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.718330 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:55:28.719376 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:55:28.719376 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.719376 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:55:28.720887 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:55:28.720887 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:55:28.721969 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:28.722999 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:55:28.724108 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:55:28.725141 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:28.725141 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:55:28.745166 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a02654d-b7ee-41d4-8a29-42845c0c5de9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029303D0C680>]}
[0m14:55:28.746194 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:55:28.746194 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:55:28.747223 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:55:28.747223 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:55:28.747223 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:55:28.748252 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:55:28.749280 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:55:28.750308 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:55:28.752328 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:55:28.752863 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:55:28.752863 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:55:28.752863 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:55:28.766175 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:55:28.767265 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:55:28.767265 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:55:28.768269 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.769299 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:55:28.769299 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:55:28.770811 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.771840 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:55:28.771840 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:55:28.772846 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.773947 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:55:28.773947 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:55:28.773947 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:55:28.774967 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:28.775993 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:55:28.777020 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:55:28.778040 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:28.778040 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:55:28.798058 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a02654d-b7ee-41d4-8a29-42845c0c5de9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029303D48080>]}
[0m14:55:28.799132 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:55:28.799132 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:55:28.800140 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:55:28.800140 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:55:28.800140 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:55:28.801147 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:55:28.802681 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:55:28.802681 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:55:28.804752 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:55:28.804752 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:55:28.805779 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:55:28.805779 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:55:28.818082 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:55:28.818082 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:55:28.819591 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:55:28.819591 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.821102 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:55:28.822125 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:55:28.822125 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.823344 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:55:28.824427 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:55:28.824427 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.825465 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:55:28.825465 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:55:28.825465 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:55:28.826488 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:28.827864 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:55:28.828892 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:55:28.828892 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:28.829897 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:55:28.848817 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a02654d-b7ee-41d4-8a29-42845c0c5de9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293036E1160>]}
[0m14:55:28.850329 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:55:28.850840 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:55:28.850840 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:55:28.851354 [info ] [Thread-1 (]: 6 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m14:55:28.851354 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:55:28.851354 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:55:28.852380 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:55:28.853424 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:55:28.854458 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:55:28.855460 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:55:28.855460 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:55:28.855460 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:55:28.868165 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:55:28.869202 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:55:28.869202 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login
    from main.raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from main.raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
from raw_commits
left join raw_contributors
    on raw_contributors.id = raw_commits."author.id"
  );

[0m14:55:28.869202 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.871735 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:55:28.871735 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
alter view "pytorch_data"."main_application"."fcommits" rename to "fcommits__dbt_backup"
[0m14:55:28.871735 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.873820 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:55:28.874843 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
alter view "pytorch_data"."main_application"."fcommits__dbt_tmp" rename to "fcommits"
[0m14:55:28.874843 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.875849 [debug] [Thread-1 (]: On model.archi.fcommits: COMMIT
[0m14:55:28.876352 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:55:28.876352 [debug] [Thread-1 (]: On model.archi.fcommits: COMMIT
[0m14:55:28.877355 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:28.878391 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:55:28.879424 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
drop view if exists "pytorch_data"."main_application"."fcommits__dbt_backup" cascade
[0m14:55:28.879424 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:28.880934 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:55:28.899461 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a02654d-b7ee-41d4-8a29-42845c0c5de9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029303D2DA90>]}
[0m14:55:28.899461 [info ] [Thread-1 (]: 6 of 7 OK created sql view model main_application.fcommits ..................... [[32mOK[0m in 0.05s]
[0m14:55:28.900974 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:55:28.901484 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:55:28.901484 [info ] [Thread-1 (]: 7 of 7 START sql view model main.view .......................................... [RUN]
[0m14:55:28.901484 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:55:28.902490 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:55:28.902996 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:55:28.903998 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:55:28.906053 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:55:28.906641 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:55:28.906641 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:55:28.907144 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:55:28.919501 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:55:28.919501 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:55:28.919501 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:55:28.921008 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.922087 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:55:28.923092 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:55:28.923092 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.924124 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:55:28.925148 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:55:28.925148 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:28.926166 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:55:28.926166 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:55:28.926166 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:55:28.927172 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:28.928430 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:55:28.929472 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:55:28.929472 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:28.930979 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:55:28.949942 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a02654d-b7ee-41d4-8a29-42845c0c5de9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029303BBF770>]}
[0m14:55:28.950947 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.05s]
[0m14:55:28.951452 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:55:28.951452 [debug] [MainThread]: Using duckdb connection "master"
[0m14:55:28.952475 [debug] [MainThread]: On master: BEGIN
[0m14:55:28.952475 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:55:28.964752 [debug] [MainThread]: SQL status: OK in 0.013 seconds
[0m14:55:28.965774 [debug] [MainThread]: On master: COMMIT
[0m14:55:28.965774 [debug] [MainThread]: Using duckdb connection "master"
[0m14:55:28.965774 [debug] [MainThread]: On master: COMMIT
[0m14:55:28.965774 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:55:28.966801 [debug] [MainThread]: On master: Close
[0m14:55:28.968459 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:55:28.968967 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m14:55:28.968967 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m14:55:28.968967 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:55:28.968967 [info ] [MainThread]: 
[0m14:55:28.969998 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.75 seconds (0.75s).
[0m14:55:28.971006 [debug] [MainThread]: Command end result
[0m14:55:28.981790 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:55:28.982888 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:55:28.986020 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:55:28.986020 [info ] [MainThread]: 
[0m14:55:28.987053 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:55:28.987053 [info ] [MainThread]: 
[0m14:55:28.987053 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m14:55:28.988084 [debug] [MainThread]: Command `dbt build` succeeded at 14:55:28.988084 after 1.24 seconds
[0m14:55:28.988084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002937E935A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029301770890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029301CCCFB0>]}
[0m14:55:28.989089 [debug] [MainThread]: Flushing usage events
[0m14:55:29.465118 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:55:32.176547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1D7DD7860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1D5A5A3C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1D7DD7920>]}


============================== 14:55:32.179089 | 264a92c8-ae44-4b21-b99b-8f90275f9459 ==============================
[0m14:55:32.179089 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:55:32.179089 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:55:32.293741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '264a92c8-ae44-4b21-b99b-8f90275f9459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1D7D1B740>]}
[0m14:55:32.325409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '264a92c8-ae44-4b21-b99b-8f90275f9459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1D824EA80>]}
[0m14:55:32.327444 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:55:32.450095 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:55:32.515303 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:55:32.515303 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:55:32.529073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '264a92c8-ae44-4b21-b99b-8f90275f9459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1D9BCBB60>]}
[0m14:55:32.557124 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:55:32.558632 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:55:32.574497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '264a92c8-ae44-4b21-b99b-8f90275f9459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1D9D4BE00>]}
[0m14:55:32.574497 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:55:32.574497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '264a92c8-ae44-4b21-b99b-8f90275f9459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1D9D130E0>]}
[0m14:55:32.575531 [info ] [MainThread]: 
[0m14:55:32.576558 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:55:32.576558 [info ] [MainThread]: 
[0m14:55:32.576558 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:55:32.580127 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m14:55:32.623573 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:55:32.623573 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:55:32.624602 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:55:32.634929 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m14:55:32.635957 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:55:32.639040 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:55:32.639040 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:55:32.639040 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:32.648272 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:55:32.649312 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:55:32.651332 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m14:55:32.652337 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m14:55:32.652337 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:32.660971 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:55:32.661475 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m14:55:32.663592 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m14:55:32.663592 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m14:55:32.667683 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:55:32.667683 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:55:32.667683 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:32.676326 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:55:32.677347 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:55:32.677347 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m14:55:32.678382 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:32.678382 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:55:32.678382 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m14:55:32.679435 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:32.679435 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:55:32.679435 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m14:55:32.679435 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m14:55:32.679435 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:32.680943 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m14:55:32.682008 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main_application)
[0m14:55:32.683030 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m14:55:32.684062 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:55:32.684062 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:55:32.684062 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:32.692726 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:55:32.693811 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:55:32.693811 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m14:55:32.694818 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:32.694818 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:55:32.694818 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m14:55:32.694818 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:32.695842 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:55:32.695842 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m14:55:32.695842 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m14:55:32.696859 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:32.696859 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m14:55:32.698908 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_application, now create_pytorch_data_main)
[0m14:55:32.698908 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m14:55:32.699928 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:55:32.699928 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m14:55:32.699928 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:32.708657 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:55:32.709661 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:55:32.709661 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m14:55:32.709661 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:32.709661 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:55:32.709661 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m14:55:32.711173 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:32.711173 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:55:32.711173 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m14:55:32.712178 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m14:55:32.712683 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:55:32.712683 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m14:55:32.714712 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m14:55:32.717789 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:55:32.717789 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:55:32.717789 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:55:32.725923 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:55:32.726945 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:55:32.726945 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:55:32.743191 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:55:32.744203 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:55:32.745227 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:55:32.745227 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:55:32.747667 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main_application)
[0m14:55:32.748691 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:55:32.749721 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:55:32.749721 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:32.758947 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m14:55:32.758947 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:55:32.759971 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:55:32.776209 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:55:32.777238 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:55:32.777238 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:55:32.778264 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:55:32.780308 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_application, now list_pytorch_data_main)
[0m14:55:32.781817 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:55:32.781817 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:55:32.781817 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:32.791011 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:55:32.791011 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:55:32.791011 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:55:32.808908 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m14:55:32.809930 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:55:32.809930 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:55:32.809930 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:55:32.814002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '264a92c8-ae44-4b21-b99b-8f90275f9459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1DA2235F0>]}
[0m14:55:32.814002 [debug] [MainThread]: Using duckdb connection "master"
[0m14:55:32.814002 [debug] [MainThread]: On master: BEGIN
[0m14:55:32.814002 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:55:32.822690 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m14:55:32.822690 [debug] [MainThread]: On master: COMMIT
[0m14:55:32.824203 [debug] [MainThread]: Using duckdb connection "master"
[0m14:55:32.824203 [debug] [MainThread]: On master: COMMIT
[0m14:55:32.824203 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:55:32.824203 [debug] [MainThread]: On master: Close
[0m14:55:32.827292 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:55:32.827292 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m14:55:32.828316 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:55:32.828316 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:55:32.832455 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:55:32.833479 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:55:32.850011 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m14:55:32.851014 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:55:32.851518 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m14:55:32.851518 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:55:32.860189 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:55:32.860189 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:55:32.861194 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m14:55:32.861698 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:32.865280 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:55:32.865280 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m14:55:32.865280 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:32.867356 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:55:32.867356 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m14:55:32.867356 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:32.874472 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:55:32.874472 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:55:32.874472 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m14:55:32.875984 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:32.879058 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m14:55:32.879058 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m14:55:32.880083 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:32.881594 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m14:55:32.901409 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264a92c8-ae44-4b21-b99b-8f90275f9459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1DA2EFD70>]}
[0m14:55:32.902865 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.07s]
[0m14:55:32.902865 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:55:32.902865 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:55:32.902865 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m14:55:32.904320 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:55:32.904320 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:55:32.905830 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:55:32.905830 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:55:32.907897 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m14:55:32.908992 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:55:32.908992 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m14:55:32.908992 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:55:32.921708 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:55:32.921708 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:55:32.922733 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:55:32.922733 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:32.924835 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:55:32.924835 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m14:55:32.924835 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:32.926340 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:55:32.927386 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m14:55:32.927386 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:32.928411 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:55:32.928411 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:55:32.928411 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m14:55:32.929437 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:32.931975 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m14:55:32.931975 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m14:55:32.933438 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:32.933438 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m14:55:32.954007 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264a92c8-ae44-4b21-b99b-8f90275f9459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1DA334F20>]}
[0m14:55:32.954007 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m14:55:32.955042 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:55:32.955042 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:55:32.955042 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m14:55:32.956087 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:55:32.956087 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:55:32.957092 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:55:32.958127 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:55:32.960171 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m14:55:32.960171 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:55:32.961175 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m14:55:32.961175 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:55:32.973782 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:55:32.974786 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:55:32.974786 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m14:55:32.974786 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:32.976041 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:55:32.977551 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m14:55:32.977551 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:32.978596 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:55:32.979633 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m14:55:32.979633 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:32.979633 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:55:32.981142 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:55:32.981142 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m14:55:32.982165 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:32.983194 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m14:55:32.983194 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m14:55:32.984701 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:32.985733 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m14:55:33.005124 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264a92c8-ae44-4b21-b99b-8f90275f9459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1DA334470>]}
[0m14:55:33.005124 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m14:55:33.006128 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:55:33.006128 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:55:33.006632 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m14:55:33.006632 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:55:33.006632 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:55:33.008192 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:55:33.008707 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:55:33.009722 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m14:55:33.011230 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:55:33.011230 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m14:55:33.011230 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:55:33.024201 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:55:33.024201 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:55:33.024201 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m14:55:33.025251 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:33.026760 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:55:33.026760 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m14:55:33.027785 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:33.028790 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:55:33.029294 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m14:55:33.029294 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:33.030299 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:55:33.030299 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:55:33.031303 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m14:55:33.031888 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:33.032894 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m14:55:33.033929 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m14:55:33.034958 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:33.034958 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m14:55:33.054561 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264a92c8-ae44-4b21-b99b-8f90275f9459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1DA319550>]}
[0m14:55:33.054561 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m14:55:33.055588 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:55:33.055588 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:55:33.055588 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m14:55:33.056626 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:55:33.056626 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:55:33.058133 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:55:33.058133 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:55:33.061211 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m14:55:33.061714 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:55:33.061714 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m14:55:33.061714 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:55:33.075525 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m14:55:33.075525 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:55:33.075525 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m14:55:33.076550 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:33.078060 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:55:33.078060 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m14:55:33.079126 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:33.081139 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:55:33.081139 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m14:55:33.081649 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:33.082673 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:55:33.082673 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:55:33.082673 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m14:55:33.083698 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:33.084724 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m14:55:33.085749 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m14:55:33.085749 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:33.087247 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m14:55:33.105906 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264a92c8-ae44-4b21-b99b-8f90275f9459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1DA2EB140>]}
[0m14:55:33.106937 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m14:55:33.106937 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:55:33.106937 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:55:33.108446 [info ] [Thread-1 (]: 6 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m14:55:33.108446 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:55:33.108446 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:55:33.109474 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:55:33.109474 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:55:33.112062 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m14:55:33.112062 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:55:33.113086 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m14:55:33.113086 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:55:33.125415 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:55:33.125415 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:55:33.126420 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with raw_contributors as (
    select
        id,
        login
    from main.raw_contributors
),

raw_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from main.raw_commits
)

select
    raw_commits."author.id",
    raw_commits."commit.url",
    raw_contributors.id,
from raw_commits
left join raw_contributors
    on raw_contributors.id = raw_commits."author.id"
  );

[0m14:55:33.126420 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:33.128966 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:55:33.128966 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
alter view "pytorch_data"."main_application"."fcommits" rename to "fcommits__dbt_backup"
[0m14:55:33.128966 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:33.131000 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:55:33.131000 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
alter view "pytorch_data"."main_application"."fcommits__dbt_tmp" rename to "fcommits"
[0m14:55:33.131505 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:33.132531 [debug] [Thread-1 (]: On model.archi.fcommits: COMMIT
[0m14:55:33.132531 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:55:33.132531 [debug] [Thread-1 (]: On model.archi.fcommits: COMMIT
[0m14:55:33.133558 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:33.134587 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m14:55:33.134587 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
drop view if exists "pytorch_data"."main_application"."fcommits__dbt_backup" cascade
[0m14:55:33.136097 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:33.137127 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m14:55:33.155965 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264a92c8-ae44-4b21-b99b-8f90275f9459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1DA32F410>]}
[0m14:55:33.156998 [info ] [Thread-1 (]: 6 of 7 OK created sql view model main_application.fcommits ..................... [[32mOK[0m in 0.05s]
[0m14:55:33.156998 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:55:33.158112 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:55:33.158112 [info ] [Thread-1 (]: 7 of 7 START sql view model main.view .......................................... [RUN]
[0m14:55:33.158112 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:55:33.158112 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:55:33.159622 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:55:33.161133 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:55:33.162641 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m14:55:33.162641 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:55:33.163644 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m14:55:33.163644 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:55:33.175800 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m14:55:33.175800 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:55:33.176822 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m14:55:33.176822 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:33.178887 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:55:33.178887 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m14:55:33.179907 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:33.181415 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:55:33.182421 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m14:55:33.182421 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m14:55:33.183451 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:55:33.183451 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:55:33.183451 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m14:55:33.185510 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:33.186536 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m14:55:33.186536 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m14:55:33.187562 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:55:33.188665 [debug] [Thread-1 (]: On model.archi.view: Close
[0m14:55:33.208095 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264a92c8-ae44-4b21-b99b-8f90275f9459', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1DA3620F0>]}
[0m14:55:33.208095 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.05s]
[0m14:55:33.209117 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:55:33.209117 [debug] [MainThread]: Using duckdb connection "master"
[0m14:55:33.210140 [debug] [MainThread]: On master: BEGIN
[0m14:55:33.210140 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:55:33.221935 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m14:55:33.221935 [debug] [MainThread]: On master: COMMIT
[0m14:55:33.223447 [debug] [MainThread]: Using duckdb connection "master"
[0m14:55:33.223447 [debug] [MainThread]: On master: COMMIT
[0m14:55:33.223447 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:55:33.223447 [debug] [MainThread]: On master: Close
[0m14:55:33.225533 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:55:33.226557 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m14:55:33.226557 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m14:55:33.226557 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:55:33.226557 [info ] [MainThread]: 
[0m14:55:33.227588 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.65 seconds (0.65s).
[0m14:55:33.227588 [debug] [MainThread]: Command end result
[0m14:55:33.237843 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:55:33.239885 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:55:33.242420 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:55:33.242420 [info ] [MainThread]: 
[0m14:55:33.243927 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:55:33.243927 [info ] [MainThread]: 
[0m14:55:33.243927 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m14:55:33.244962 [debug] [MainThread]: Command `dbt run` succeeded at 14:55:33.244962 after 1.15 seconds
[0m14:55:33.244962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1D80A43B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1D8269640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F1D826A420>]}
[0m14:55:33.244962 [debug] [MainThread]: Flushing usage events
[0m14:55:33.696750 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:55:41.060722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C25B806B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C25BE8E30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C25BE89E0>]}


============================== 14:55:41.063828 | 60776995-7fc1-4976-b60a-6770c0c7b285 ==============================
[0m14:55:41.063828 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:55:41.063828 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m14:55:41.175968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '60776995-7fc1-4976-b60a-6770c0c7b285', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C26556FC0>]}
[0m14:55:41.206222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '60776995-7fc1-4976-b60a-6770c0c7b285', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C259FF800>]}
[0m14:55:41.209385 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m14:55:41.324870 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m14:55:41.386792 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:55:41.386792 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:55:41.401054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '60776995-7fc1-4976-b60a-6770c0c7b285', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C2777BDD0>]}
[0m14:55:41.415447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '60776995-7fc1-4976-b60a-6770c0c7b285', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C27A77FB0>]}
[0m14:55:41.415447 [info ] [MainThread]: Found 7 models, 424 macros
[0m14:55:41.416485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '60776995-7fc1-4976-b60a-6770c0c7b285', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C26566180>]}
[0m14:55:41.417511 [info ] [MainThread]: 
[0m14:55:41.417511 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:55:41.418535 [info ] [MainThread]: 
[0m14:55:41.419060 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:55:41.421098 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m14:55:41.465539 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:55:41.466565 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m14:55:41.466565 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:55:41.476764 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m14:55:41.509400 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m14:55:41.509400 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:55:41.527641 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m14:55:41.528659 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m14:55:41.529679 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m14:55:41.529679 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m14:55:41.532255 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_cleansed)
[0m14:55:41.534300 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:55:41.534300 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m14:55:41.534300 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:41.543474 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:55:41.543474 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m14:55:41.544500 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:55:41.560400 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:55:41.561909 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m14:55:41.562465 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m14:55:41.562465 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m14:55:41.565043 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main_application)
[0m14:55:41.566064 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:55:41.566064 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m14:55:41.567087 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:55:41.574747 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:55:41.575765 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m14:55:41.575765 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m14:55:41.591559 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m14:55:41.593071 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m14:55:41.593071 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m14:55:41.594142 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m14:55:41.596192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '60776995-7fc1-4976-b60a-6770c0c7b285', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C264DABD0>]}
[0m14:55:41.598242 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m14:55:41.598242 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m14:55:41.599269 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m14:55:41.601802 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m14:55:41.603367 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m14:55:41.603367 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m14:55:41.604371 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m14:55:41.604371 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m14:55:41.604371 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m14:55:41.605395 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m14:55:41.606417 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m14:55:41.606417 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m14:55:41.607436 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m14:55:41.607436 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m14:55:41.607436 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m14:55:41.608576 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m14:55:41.609580 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m14:55:41.609580 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m14:55:41.609580 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m14:55:41.611091 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m14:55:41.611091 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m14:55:41.612116 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m14:55:41.612116 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m14:55:41.613627 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m14:55:41.613627 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m14:55:41.613627 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m14:55:41.614667 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m14:55:41.615691 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m14:55:41.615691 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m14:55:41.616713 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m14:55:41.616713 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m14:55:41.616713 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.fcommits)
[0m14:55:41.616713 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m14:55:41.617735 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m14:55:41.618757 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m14:55:41.618757 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m14:55:41.618757 [debug] [Thread-1 (]: Began running node model.archi.view
[0m14:55:41.619778 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.fcommits, now model.archi.view)
[0m14:55:41.619778 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m14:55:41.621290 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m14:55:41.621290 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m14:55:41.621290 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m14:55:41.622319 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:55:41.622319 [debug] [MainThread]: Connection 'list_pytorch_data_main_application' was properly closed.
[0m14:55:41.622319 [debug] [MainThread]: Connection 'model.archi.view' was properly closed.
[0m14:55:41.623831 [debug] [MainThread]: Command end result
[0m14:55:41.650308 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:55:41.651314 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:55:41.655012 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m14:55:41.828345 [debug] [MainThread]: Acquiring new duckdb connection 'generate_catalog'
[0m14:55:41.828345 [info ] [MainThread]: Building catalog
[0m14:55:41.832918 [debug] [ThreadPool]: Acquiring new duckdb connection 'pytorch_data.information_schema'
[0m14:55:41.836491 [debug] [ThreadPool]: Using duckdb connection "pytorch_data.information_schema"
[0m14:55:41.837511 [debug] [ThreadPool]: On pytorch_data.information_schema: BEGIN
[0m14:55:41.837511 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:55:41.845734 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m14:55:41.845734 [debug] [ThreadPool]: Using duckdb connection "pytorch_data.information_schema"
[0m14:55:41.846770 [debug] [ThreadPool]: On pytorch_data.information_schema: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "pytorch_data.information_schema"} */
with relations AS (
      select
        t.table_name
        , t.database_name
        , t.schema_name
        , 'BASE TABLE' as table_type
        , t.comment as table_comment
      from duckdb_tables() t
      WHERE t.database_name = 'pytorch_data'
      UNION ALL
      SELECT v.view_name as table_name
      , v.database_name
      , v.schema_name
      , 'VIEW' as table_type
      , v.comment as table_comment
      from duckdb_views() v
      WHERE v.database_name = 'pytorch_data'
    )
    select
        'pytorch_data' as table_database,
        r.schema_name as table_schema,
        r.table_name,
        r.table_type,
        r.table_comment,
        c.column_name,
        c.column_index as column_index,
        c.data_type as column_type,
        c.comment as column_comment,
        '' as table_owner
    FROM relations r JOIN duckdb_columns() c ON r.schema_name = c.schema_name AND r.table_name = c.table_name
    WHERE (upper(r.schema_name) = upper('main') or upper(r.schema_name) = upper('main_application') or upper(r.schema_name) = upper('main_cleansed'))
    ORDER BY
        r.schema_name,
        r.table_name,
        c.column_index
[0m14:55:41.973698 [debug] [ThreadPool]: SQL status: OK in 0.127 seconds
[0m14:55:41.996701 [debug] [ThreadPool]: On pytorch_data.information_schema: ROLLBACK
[0m14:55:41.996701 [debug] [ThreadPool]: Failed to rollback 'pytorch_data.information_schema'
[0m14:55:41.996701 [debug] [ThreadPool]: On pytorch_data.information_schema: Close
[0m14:55:42.022211 [debug] [MainThread]: Wrote artifact CatalogArtifact to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\catalog.json
[0m14:55:42.032522 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m14:55:42.033585 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m14:55:42.033585 [info ] [MainThread]: Catalog written to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\catalog.json
[0m14:55:42.034615 [debug] [MainThread]: Command `dbt docs generate` succeeded at 14:55:42.034615 after 1.06 seconds
[0m14:55:42.034615 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m14:55:42.034615 [debug] [MainThread]: Connection 'pytorch_data.information_schema' was properly closed.
[0m14:55:42.034615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C261A15B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C259FFFB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C279837D0>]}
[0m14:55:42.035640 [debug] [MainThread]: Flushing usage events
[0m14:55:42.415379 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:55:50.733588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000293695642C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002936B0D1820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002936BE1EA20>]}


============================== 14:55:50.737639 | 24100ede-83d0-4422-b361-454e1c12b93b ==============================
[0m14:55:50.737639 [info ] [MainThread]: Running with dbt=1.9.1
[0m14:55:50.737639 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt docs serve', 'send_anonymous_usage_stats': 'True'}
[0m14:55:50.847439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '24100ede-83d0-4422-b361-454e1c12b93b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002936C336E40>]}
[0m14:55:50.878458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '24100ede-83d0-4422-b361-454e1c12b93b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002936BD5D850>]}
[0m15:04:41.099218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026B9EB916A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026B9E26F260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026B9E26D460>]}


============================== 15:04:41.101761 | 0c66913f-fc03-4635-ad59-b11c8aa9bb21 ==============================
[0m15:04:41.101761 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:04:41.101761 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m15:04:41.214299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0c66913f-fc03-4635-ad59-b11c8aa9bb21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026B9F0079E0>]}
[0m15:04:41.245498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0c66913f-fc03-4635-ad59-b11c8aa9bb21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026B9EFAFA40>]}
[0m15:04:41.247957 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:04:41.362488 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:04:41.424128 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:04:41.424128 [debug] [MainThread]: Partial parsing: updated file: archi://models\application\fcommits.sql
[0m15:04:41.544293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0c66913f-fc03-4635-ad59-b11c8aa9bb21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026B9F033740>]}
[0m15:04:41.570847 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:04:41.571873 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:04:41.594420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0c66913f-fc03-4635-ad59-b11c8aa9bb21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026BA050FE00>]}
[0m15:04:41.595450 [info ] [MainThread]: Found 7 models, 424 macros
[0m15:04:41.596810 [info ] [MainThread]: 
[0m15:04:41.596810 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:04:41.596810 [info ] [MainThread]: 
[0m15:04:41.597834 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:04:41.600379 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:04:41.643767 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:04:41.644805 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:04:41.644805 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:04:41.654550 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m15:04:41.655578 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:04:41.658650 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:04:41.658650 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:04:41.658650 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:41.668436 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m15:04:41.668436 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:04:41.672038 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:04:41.672038 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:04:41.672038 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:41.679480 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:04:41.680989 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:04:41.682529 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_application)
[0m15:04:41.683558 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m15:04:41.686660 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m15:04:41.686660 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:04:41.687685 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:41.695875 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:04:41.696966 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m15:04:41.696966 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m15:04:41.696966 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:41.696966 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m15:04:41.697974 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m15:04:41.697974 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:41.699017 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m15:04:41.699017 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m15:04:41.699017 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m15:04:41.699017 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:41.700051 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m15:04:41.701559 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_application, now create_pytorch_data_main)
[0m15:04:41.701559 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m15:04:41.703069 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:04:41.703069 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:04:41.703069 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:41.711852 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m15:04:41.711852 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:04:41.713402 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m15:04:41.713402 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:41.713402 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:04:41.713402 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m15:04:41.714425 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:41.714934 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:04:41.714934 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:04:41.715442 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:04:41.715442 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:41.715442 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m15:04:41.717954 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main, now create_pytorch_data_main_cleansed)
[0m15:04:41.717954 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:04:41.719463 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:04:41.719463 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:04:41.719463 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:41.728010 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:04:41.728010 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:04:41.729032 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:04:41.729032 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:41.729032 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:04:41.729032 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:04:41.730054 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:41.730054 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:04:41.731058 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:04:41.731058 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:04:41.731562 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:41.731562 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:04:41.733590 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_application'
[0m15:04:41.737198 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m15:04:41.737198 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m15:04:41.737198 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:04:41.745985 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:04:41.745985 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m15:04:41.745985 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:04:41.763432 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m15:04:41.764440 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m15:04:41.764949 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m15:04:41.764949 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m15:04:41.766994 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_application, now list_pytorch_data_main)
[0m15:04:41.769042 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:04:41.769042 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m15:04:41.769042 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:41.777901 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:04:41.777901 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:04:41.777901 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:04:41.793817 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:04:41.795330 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m15:04:41.795330 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m15:04:41.796371 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m15:04:41.798431 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_cleansed)
[0m15:04:41.799457 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:04:41.799457 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:04:41.800968 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:41.808717 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:04:41.809750 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:04:41.809750 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:04:41.826148 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:04:41.827182 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:04:41.827182 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:04:41.828214 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:04:41.830748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0c66913f-fc03-4635-ad59-b11c8aa9bb21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026B9E54E0F0>]}
[0m15:04:41.830748 [debug] [MainThread]: Using duckdb connection "master"
[0m15:04:41.831772 [debug] [MainThread]: On master: BEGIN
[0m15:04:41.831772 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:04:41.839480 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m15:04:41.839480 [debug] [MainThread]: On master: COMMIT
[0m15:04:41.839480 [debug] [MainThread]: Using duckdb connection "master"
[0m15:04:41.840990 [debug] [MainThread]: On master: COMMIT
[0m15:04:41.840990 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:04:41.840990 [debug] [MainThread]: On master: Close
[0m15:04:41.844071 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m15:04:41.844071 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m15:04:41.845105 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m15:04:41.845105 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m15:04:41.849721 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m15:04:41.849721 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m15:04:41.865751 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m15:04:41.867260 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:04:41.867381 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m15:04:41.867381 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:04:41.876180 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m15:04:41.876180 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:04:41.876180 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m15:04:41.877689 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:41.881261 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:04:41.881261 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m15:04:41.882278 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:41.883302 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:04:41.883302 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m15:04:41.884359 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:41.890996 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m15:04:41.890996 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:04:41.891501 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m15:04:41.892525 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:41.895599 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:04:41.895599 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m15:04:41.896614 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:41.898124 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m15:04:41.917531 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0c66913f-fc03-4635-ad59-b11c8aa9bb21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026BA0508170>]}
[0m15:04:41.918539 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.07s]
[0m15:04:41.919048 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m15:04:41.919048 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m15:04:41.920052 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m15:04:41.920052 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m15:04:41.920052 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m15:04:41.921560 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m15:04:41.921560 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m15:04:41.923826 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m15:04:41.923826 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:04:41.924880 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m15:04:41.924880 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:04:41.937841 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m15:04:41.937841 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:04:41.937841 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m15:04:41.938850 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:41.940366 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:04:41.940883 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m15:04:41.941397 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:41.942434 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:04:41.942434 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m15:04:41.943468 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:41.944505 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m15:04:41.944505 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:04:41.944505 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m15:04:41.946103 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:41.947646 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:04:41.947646 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m15:04:41.947646 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:41.949161 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m15:04:41.968270 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0c66913f-fc03-4635-ad59-b11c8aa9bb21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026BA0D85F40>]}
[0m15:04:41.968270 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m15:04:41.969785 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m15:04:41.969785 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m15:04:41.969785 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m15:04:41.970791 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m15:04:41.970791 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m15:04:41.972317 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m15:04:41.972317 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m15:04:41.974384 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m15:04:41.975413 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m15:04:41.975413 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m15:04:41.975413 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:04:41.988797 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m15:04:41.988797 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m15:04:41.988797 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m15:04:41.988797 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:41.991345 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m15:04:41.991345 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m15:04:41.992379 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:41.993430 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m15:04:41.993430 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m15:04:41.994464 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:41.995499 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m15:04:41.995499 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m15:04:41.995499 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m15:04:41.997557 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:41.998594 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m15:04:41.998594 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m15:04:41.999623 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:42.000628 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m15:04:42.019156 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0c66913f-fc03-4635-ad59-b11c8aa9bb21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026BA1D7C470>]}
[0m15:04:42.019156 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m15:04:42.020669 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m15:04:42.021182 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m15:04:42.021714 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m15:04:42.021714 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m15:04:42.021714 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m15:04:42.022736 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m15:04:42.023820 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m15:04:42.025914 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m15:04:42.025914 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:04:42.025914 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m15:04:42.026944 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:04:42.039140 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m15:04:42.039140 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:04:42.039140 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m15:04:42.040655 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:42.042171 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:04:42.042171 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m15:04:42.043178 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:42.044208 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:04:42.044208 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m15:04:42.045241 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:42.046277 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m15:04:42.046277 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:04:42.046277 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m15:04:42.047307 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:42.048341 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:04:42.049373 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m15:04:42.049373 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:42.050885 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m15:04:42.069564 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0c66913f-fc03-4635-ad59-b11c8aa9bb21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026BA0C1B8C0>]}
[0m15:04:42.071116 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m15:04:42.071116 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m15:04:42.071116 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m15:04:42.071116 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m15:04:42.072629 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m15:04:42.072629 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m15:04:42.073674 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m15:04:42.074705 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m15:04:42.075732 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m15:04:42.076762 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m15:04:42.076762 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m15:04:42.076762 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:04:42.089093 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m15:04:42.090120 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m15:04:42.090636 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m15:04:42.091151 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:42.093187 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m15:04:42.093694 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m15:04:42.093694 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:42.095735 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m15:04:42.095735 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m15:04:42.095735 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:42.096760 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m15:04:42.096760 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m15:04:42.097799 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m15:04:42.098846 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:42.099878 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m15:04:42.099878 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m15:04:42.101392 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:42.102396 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m15:04:42.121120 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0c66913f-fc03-4635-ad59-b11c8aa9bb21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026BA0D47DA0>]}
[0m15:04:42.121120 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m15:04:42.122153 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m15:04:42.122153 [debug] [Thread-1 (]: Began running node model.archi.view
[0m15:04:42.122153 [info ] [Thread-1 (]: 6 of 7 START sql view model main.view .......................................... [RUN]
[0m15:04:42.122153 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.view)
[0m15:04:42.123664 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m15:04:42.124725 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m15:04:42.124725 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m15:04:42.126785 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m15:04:42.127807 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m15:04:42.127807 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m15:04:42.127807 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:04:42.141103 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m15:04:42.141103 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m15:04:42.141103 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m15:04:42.142136 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:42.144179 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m15:04:42.144179 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m15:04:42.144688 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:42.145696 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m15:04:42.146728 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m15:04:42.146728 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:42.147278 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m15:04:42.148287 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m15:04:42.148287 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m15:04:42.149801 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:42.150810 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m15:04:42.151317 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m15:04:42.152345 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:42.152345 [debug] [Thread-1 (]: On model.archi.view: Close
[0m15:04:42.172276 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0c66913f-fc03-4635-ad59-b11c8aa9bb21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026BA0C7A2D0>]}
[0m15:04:42.172276 [info ] [Thread-1 (]: 6 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.05s]
[0m15:04:42.173309 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m15:04:42.173309 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m15:04:42.173309 [info ] [Thread-1 (]: 7 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m15:04:42.173309 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.view, now model.archi.fcommits)
[0m15:04:42.174823 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m15:04:42.175866 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m15:04:42.176992 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m15:04:42.178361 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m15:04:42.179391 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m15:04:42.179391 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m15:04:42.179391 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:04:42.192241 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m15:04:42.192241 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m15:04:42.193251 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with clean_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from "pytorch_data"."main_cleansed"."cleancommit"  -- Utilisation de ref() pour se référer au modèle cleancommit.sql
),

clean_contributors as (
    select
        id,
        login
    from "pytorch_data"."main_cleansed"."cleancontributor"  -- Utilisation de ref() pour se référer au modèle cleancontributor.sql
)

select
    clean_commits."author.id",
    clean_commits."commit.url",
    clean_commits."commit.author.name",
    clean_commits."commit.author.date",
    clean_contributors.id as contributor_id,
    clean_contributors.login as contributor_login
from clean_commits
left join clean_contributors
    on clean_contributors.id = clean_commits."author.id"
  );

[0m15:04:42.193251 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:42.195316 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m15:04:42.195820 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
alter view "pytorch_data"."main_application"."fcommits" rename to "fcommits__dbt_backup"
[0m15:04:42.195820 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:42.196825 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m15:04:42.197868 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
alter view "pytorch_data"."main_application"."fcommits__dbt_tmp" rename to "fcommits"
[0m15:04:42.197868 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:42.198897 [debug] [Thread-1 (]: On model.archi.fcommits: COMMIT
[0m15:04:42.198897 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m15:04:42.198897 [debug] [Thread-1 (]: On model.archi.fcommits: COMMIT
[0m15:04:42.200111 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:42.202644 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m15:04:42.202644 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
drop view if exists "pytorch_data"."main_application"."fcommits__dbt_backup" cascade
[0m15:04:42.203690 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:42.203690 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m15:04:42.223277 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0c66913f-fc03-4635-ad59-b11c8aa9bb21', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026BA1D986E0>]}
[0m15:04:42.223277 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main_application.fcommits ..................... [[32mOK[0m in 0.05s]
[0m15:04:42.224332 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m15:04:42.225364 [debug] [MainThread]: Using duckdb connection "master"
[0m15:04:42.225364 [debug] [MainThread]: On master: BEGIN
[0m15:04:42.225364 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:04:42.237718 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m15:04:42.237718 [debug] [MainThread]: On master: COMMIT
[0m15:04:42.238741 [debug] [MainThread]: Using duckdb connection "master"
[0m15:04:42.238741 [debug] [MainThread]: On master: COMMIT
[0m15:04:42.238741 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:04:42.238741 [debug] [MainThread]: On master: Close
[0m15:04:42.241297 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:04:42.241297 [debug] [MainThread]: Connection 'create_pytorch_data_main_cleansed' was properly closed.
[0m15:04:42.242325 [debug] [MainThread]: Connection 'list_pytorch_data_main_cleansed' was properly closed.
[0m15:04:42.242325 [debug] [MainThread]: Connection 'model.archi.fcommits' was properly closed.
[0m15:04:42.242325 [info ] [MainThread]: 
[0m15:04:42.243363 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.64 seconds (0.64s).
[0m15:04:42.244815 [debug] [MainThread]: Command end result
[0m15:04:42.255074 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:04:42.257084 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:04:42.260630 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:04:42.260630 [info ] [MainThread]: 
[0m15:04:42.261151 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:04:42.261664 [info ] [MainThread]: 
[0m15:04:42.261664 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m15:04:42.261664 [debug] [MainThread]: Command `dbt build` succeeded at 15:04:42.261664 after 1.25 seconds
[0m15:04:42.262695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026B9E9C23F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026B9E9C2330>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026B9E9C0800>]}
[0m15:04:42.262695 [debug] [MainThread]: Flushing usage events
[0m15:04:42.734369 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:04:47.333552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298C8F680E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CBA43FB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CBA43E00>]}


============================== 15:04:47.337137 | bd3fee01-7fad-41ca-9c7b-358f4a68ade5 ==============================
[0m15:04:47.337137 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:04:47.337689 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:04:47.446718 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bd3fee01-7fad-41ca-9c7b-358f4a68ade5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CB627920>]}
[0m15:04:47.477302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bd3fee01-7fad-41ca-9c7b-358f4a68ade5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CBCD6F00>]}
[0m15:04:47.479346 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:04:47.591865 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:04:47.654144 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:04:47.654144 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:04:47.666886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bd3fee01-7fad-41ca-9c7b-358f4a68ade5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CCEB8470>]}
[0m15:04:47.693959 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:04:47.694988 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:04:47.709370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bd3fee01-7fad-41ca-9c7b-358f4a68ade5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CD1F4EC0>]}
[0m15:04:47.801483 [info ] [MainThread]: Found 7 models, 424 macros
[0m15:04:47.802640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bd3fee01-7fad-41ca-9c7b-358f4a68ade5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CD062A50>]}
[0m15:04:47.803673 [info ] [MainThread]: 
[0m15:04:47.804204 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:04:47.804204 [info ] [MainThread]: 
[0m15:04:47.804730 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:04:47.806781 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data'
[0m15:04:47.849631 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:04:47.849631 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:04:47.849631 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:04:47.859853 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m15:04:47.861361 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:04:47.863457 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:04:47.863457 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:04:47.864465 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:47.873193 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m15:04:47.874237 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:04:47.876287 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data"
[0m15:04:47.876287 [debug] [ThreadPool]: On list_pytorch_data: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"pytorch_data"'
    
  
  
[0m15:04:47.877293 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:47.885022 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:04:47.886046 [debug] [ThreadPool]: On list_pytorch_data: Close
[0m15:04:47.887341 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data, now create_pytorch_data_main_cleansed)
[0m15:04:47.888384 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_cleansed"
"
[0m15:04:47.891945 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:04:47.891945 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:04:47.891945 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:47.900219 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:04:47.901224 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:04:47.901224 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: BEGIN
[0m15:04:47.901729 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:47.901729 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:04:47.901729 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_cleansed"} */

    
    
        create schema if not exists "pytorch_data"."main_cleansed"
    
[0m15:04:47.902757 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:47.902757 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:04:47.903791 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_cleansed"
[0m15:04:47.903791 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: COMMIT
[0m15:04:47.903791 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:47.903791 [debug] [ThreadPool]: On create_pytorch_data_main_cleansed: Close
[0m15:04:47.905846 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_cleansed, now create_pytorch_data_main_application)
[0m15:04:47.906855 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main_application"
"
[0m15:04:47.907869 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m15:04:47.907869 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:04:47.907869 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:47.916652 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m15:04:47.917183 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m15:04:47.917183 [debug] [ThreadPool]: On create_pytorch_data_main_application: BEGIN
[0m15:04:47.918192 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:47.918192 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m15:04:47.918702 [debug] [ThreadPool]: On create_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main_application"} */

    
    
        create schema if not exists "pytorch_data"."main_application"
    
[0m15:04:47.918702 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:47.919709 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m15:04:47.919709 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main_application"
[0m15:04:47.919709 [debug] [ThreadPool]: On create_pytorch_data_main_application: COMMIT
[0m15:04:47.919709 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:47.919709 [debug] [ThreadPool]: On create_pytorch_data_main_application: Close
[0m15:04:47.922255 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_pytorch_data_main_application, now create_pytorch_data_main)
[0m15:04:47.922255 [debug] [ThreadPool]: Creating schema "database: "pytorch_data"
schema: "main"
"
[0m15:04:47.923335 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:04:47.923335 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='pytorch_data'
        and type='sqlite'
    
  
[0m15:04:47.924367 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:47.932502 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:04:47.932502 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:04:47.933527 [debug] [ThreadPool]: On create_pytorch_data_main: BEGIN
[0m15:04:47.933527 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:47.933527 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:04:47.933527 [debug] [ThreadPool]: On create_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "create_pytorch_data_main"} */

    
    
        create schema if not exists "pytorch_data"."main"
    
[0m15:04:47.934563 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:47.934563 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:04:47.934563 [debug] [ThreadPool]: Using duckdb connection "create_pytorch_data_main"
[0m15:04:47.934563 [debug] [ThreadPool]: On create_pytorch_data_main: COMMIT
[0m15:04:47.936072 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:04:47.936072 [debug] [ThreadPool]: On create_pytorch_data_main: Close
[0m15:04:47.938623 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main_cleansed'
[0m15:04:47.941643 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:04:47.941643 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:04:47.941643 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:04:47.949300 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:04:47.949300 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:04:47.949300 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:04:47.966643 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:04:47.967664 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:04:47.968191 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:04:47.968191 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:04:47.970822 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main_application)
[0m15:04:47.972981 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m15:04:47.972981 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m15:04:47.972981 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:47.982172 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m15:04:47.982172 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m15:04:47.982172 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:04:47.999080 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m15:04:48.000085 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m15:04:48.001093 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m15:04:48.001093 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m15:04:48.003833 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_application, now list_pytorch_data_main)
[0m15:04:48.004867 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:04:48.004867 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m15:04:48.004867 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:48.013494 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:04:48.013494 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:04:48.013494 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:04:48.030890 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:04:48.030890 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m15:04:48.032228 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m15:04:48.032228 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m15:04:48.035315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bd3fee01-7fad-41ca-9c7b-358f4a68ade5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CCEFFBC0>]}
[0m15:04:48.035315 [debug] [MainThread]: Using duckdb connection "master"
[0m15:04:48.036341 [debug] [MainThread]: On master: BEGIN
[0m15:04:48.036341 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:04:48.045073 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m15:04:48.045073 [debug] [MainThread]: On master: COMMIT
[0m15:04:48.045073 [debug] [MainThread]: Using duckdb connection "master"
[0m15:04:48.045073 [debug] [MainThread]: On master: COMMIT
[0m15:04:48.046096 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:04:48.046096 [debug] [MainThread]: On master: Close
[0m15:04:48.049247 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m15:04:48.049247 [info ] [Thread-1 (]: 1 of 7 START sql view model main_cleansed.cleancommit .......................... [RUN]
[0m15:04:48.049247 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m15:04:48.050281 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m15:04:48.054893 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m15:04:48.054893 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m15:04:48.071134 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancommit"
[0m15:04:48.072173 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:04:48.072173 [debug] [Thread-1 (]: On model.archi.cleancommit: BEGIN
[0m15:04:48.072173 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:04:48.081321 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m15:04:48.081321 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:04:48.081321 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */

  
  create view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" as (
    with raw as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id",
        -- Ajoutez d'autres colonnes nécessaires
    from raw_commits
    where "author.id" is not null  -- Filtrer les commits sans message
)

select
    "commit.author.name",
    "commit.author.date",
    "commit.url",
    "author.id"
from raw
  );

[0m15:04:48.082364 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.085935 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:04:48.085935 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit" rename to "cleancommit__dbt_backup"
[0m15:04:48.086952 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.087986 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:04:48.087986 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
alter view "pytorch_data"."main_cleansed"."cleancommit__dbt_tmp" rename to "cleancommit"
[0m15:04:48.089011 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.095120 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m15:04:48.095120 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:04:48.096164 [debug] [Thread-1 (]: On model.archi.cleancommit: COMMIT
[0m15:04:48.197214 [debug] [Thread-1 (]: SQL status: OK in 0.102 seconds
[0m15:04:48.200774 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancommit"
[0m15:04:48.200774 [debug] [Thread-1 (]: On model.archi.cleancommit: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancommit"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancommit__dbt_backup" cascade
[0m15:04:48.201802 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:48.204054 [debug] [Thread-1 (]: On model.archi.cleancommit: Close
[0m15:04:48.224329 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd3fee01-7fad-41ca-9c7b-358f4a68ade5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CB150E60>]}
[0m15:04:48.225333 [info ] [Thread-1 (]: 1 of 7 OK created sql view model main_cleansed.cleancommit ..................... [[32mOK[0m in 0.17s]
[0m15:04:48.225333 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m15:04:48.225333 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m15:04:48.226843 [info ] [Thread-1 (]: 2 of 7 START sql view model main_cleansed.cleancontributor ..................... [RUN]
[0m15:04:48.226843 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m15:04:48.226843 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m15:04:48.228896 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m15:04:48.228896 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m15:04:48.230921 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleancontributor"
[0m15:04:48.231425 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:04:48.231425 [debug] [Thread-1 (]: On model.archi.cleancontributor: BEGIN
[0m15:04:48.231425 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:04:48.244792 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m15:04:48.244792 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:04:48.244792 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */

  
  create view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m15:04:48.245808 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.247319 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:04:48.247319 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor" rename to "cleancontributor__dbt_backup"
[0m15:04:48.248345 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.249367 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:04:48.249367 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
alter view "pytorch_data"."main_cleansed"."cleancontributor__dbt_tmp" rename to "cleancontributor"
[0m15:04:48.249367 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.250917 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m15:04:48.250917 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:04:48.251943 [debug] [Thread-1 (]: On model.archi.cleancontributor: COMMIT
[0m15:04:48.252964 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:48.255060 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleancontributor"
[0m15:04:48.255060 [debug] [Thread-1 (]: On model.archi.cleancontributor: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleancontributor"} */
drop view if exists "pytorch_data"."main_cleansed"."cleancontributor__dbt_backup" cascade
[0m15:04:48.256074 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:48.256074 [debug] [Thread-1 (]: On model.archi.cleancontributor: Close
[0m15:04:48.275959 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd3fee01-7fad-41ca-9c7b-358f4a68ade5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CD657F50>]}
[0m15:04:48.276983 [info ] [Thread-1 (]: 2 of 7 OK created sql view model main_cleansed.cleancontributor ................ [[32mOK[0m in 0.05s]
[0m15:04:48.276983 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m15:04:48.277987 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m15:04:48.277987 [info ] [Thread-1 (]: 3 of 7 START sql view model main_cleansed.cleanissue ........................... [RUN]
[0m15:04:48.278491 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m15:04:48.278491 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m15:04:48.279586 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m15:04:48.279586 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m15:04:48.282153 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanissue"
[0m15:04:48.282153 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m15:04:48.283188 [debug] [Thread-1 (]: On model.archi.cleanissue: BEGIN
[0m15:04:48.283188 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:04:48.296014 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m15:04:48.296014 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m15:04:48.296014 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */

  
  create view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" as (
    with raw as (
    select
        id,
        title,
        "user.id",
        created_at,
        closed_at,
        "pull_request.html_url"
        -- Ajoutez d'autres colonnes nécessaires
    from raw_issues
    where id is not null  -- Filtrer les issues sans titre
)

select
    id,
    title,
    "user.id",
    created_at
from raw
  );

[0m15:04:48.297042 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.298609 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m15:04:48.298609 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue" rename to "cleanissue__dbt_backup"
[0m15:04:48.299614 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.301124 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m15:04:48.301124 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
alter view "pytorch_data"."main_cleansed"."cleanissue__dbt_tmp" rename to "cleanissue"
[0m15:04:48.301124 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.302144 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m15:04:48.303167 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m15:04:48.303167 [debug] [Thread-1 (]: On model.archi.cleanissue: COMMIT
[0m15:04:48.304195 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:48.305757 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanissue"
[0m15:04:48.306273 [debug] [Thread-1 (]: On model.archi.cleanissue: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanissue"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanissue__dbt_backup" cascade
[0m15:04:48.306273 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:48.307295 [debug] [Thread-1 (]: On model.archi.cleanissue: Close
[0m15:04:48.327232 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd3fee01-7fad-41ca-9c7b-358f4a68ade5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CD66C950>]}
[0m15:04:48.327232 [info ] [Thread-1 (]: 3 of 7 OK created sql view model main_cleansed.cleanissue ...................... [[32mOK[0m in 0.05s]
[0m15:04:48.328237 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m15:04:48.328237 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m15:04:48.329315 [info ] [Thread-1 (]: 4 of 7 START sql view model main_cleansed.cleanpr .............................. [RUN]
[0m15:04:48.329315 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m15:04:48.329315 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m15:04:48.330822 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m15:04:48.330822 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m15:04:48.332880 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.cleanpr"
[0m15:04:48.333908 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:04:48.333908 [debug] [Thread-1 (]: On model.archi.cleanpr: BEGIN
[0m15:04:48.333908 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:04:48.347139 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m15:04:48.347643 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:04:48.347643 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */

  
  create view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" as (
    with raw as (
    select
        id,
        state,
        title,
        created_at,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_pull_requests
    where id is not null  -- Filtrer les PR sans titre
)

select
    id,
    title,
    state,
    created_at
from raw
  );

[0m15:04:48.348153 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.350202 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:04:48.350202 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr" rename to "cleanpr__dbt_backup"
[0m15:04:48.350202 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.351712 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:04:48.352738 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
alter view "pytorch_data"."main_cleansed"."cleanpr__dbt_tmp" rename to "cleanpr"
[0m15:04:48.352738 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.353763 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m15:04:48.353763 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:04:48.354786 [debug] [Thread-1 (]: On model.archi.cleanpr: COMMIT
[0m15:04:48.355811 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:48.356833 [debug] [Thread-1 (]: Using duckdb connection "model.archi.cleanpr"
[0m15:04:48.356833 [debug] [Thread-1 (]: On model.archi.cleanpr: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.cleanpr"} */
drop view if exists "pytorch_data"."main_cleansed"."cleanpr__dbt_backup" cascade
[0m15:04:48.358341 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:48.358341 [debug] [Thread-1 (]: On model.archi.cleanpr: Close
[0m15:04:48.378393 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd3fee01-7fad-41ca-9c7b-358f4a68ade5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CD619D90>]}
[0m15:04:48.378899 [info ] [Thread-1 (]: 4 of 7 OK created sql view model main_cleansed.cleanpr ......................... [[32mOK[0m in 0.05s]
[0m15:04:48.378899 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m15:04:48.379924 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m15:04:48.379924 [info ] [Thread-1 (]: 5 of 7 START sql view model main_application.dcontributeur ..................... [RUN]
[0m15:04:48.379924 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m15:04:48.380931 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m15:04:48.381435 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m15:04:48.382457 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m15:04:48.384530 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.dcontributeur"
[0m15:04:48.385550 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m15:04:48.385550 [debug] [Thread-1 (]: On model.archi.dcontributeur: BEGIN
[0m15:04:48.385550 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:04:48.397807 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m15:04:48.398812 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m15:04:48.398812 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */

  
  create view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" as (
    with raw as (
    select
        id,
        login,
        -- Ajoutez d'autres colonnes nécessaires
    from raw_contributors
    where id is not null  -- Filtrer les contributeurs sans email
)

select
    id,
    login
from raw
  );

[0m15:04:48.399317 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.400832 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m15:04:48.400832 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur" rename to "dcontributeur__dbt_backup"
[0m15:04:48.401838 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.403347 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m15:04:48.403347 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
alter view "pytorch_data"."main_application"."dcontributeur__dbt_tmp" rename to "dcontributeur"
[0m15:04:48.403347 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.404372 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m15:04:48.405422 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m15:04:48.405422 [debug] [Thread-1 (]: On model.archi.dcontributeur: COMMIT
[0m15:04:48.406445 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:48.407995 [debug] [Thread-1 (]: Using duckdb connection "model.archi.dcontributeur"
[0m15:04:48.407995 [debug] [Thread-1 (]: On model.archi.dcontributeur: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.dcontributeur"} */
drop view if exists "pytorch_data"."main_application"."dcontributeur__dbt_backup" cascade
[0m15:04:48.409001 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:48.410175 [debug] [Thread-1 (]: On model.archi.dcontributeur: Close
[0m15:04:48.429748 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd3fee01-7fad-41ca-9c7b-358f4a68ade5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CD628E00>]}
[0m15:04:48.430251 [info ] [Thread-1 (]: 5 of 7 OK created sql view model main_application.dcontributeur ................ [[32mOK[0m in 0.05s]
[0m15:04:48.430756 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m15:04:48.431264 [debug] [Thread-1 (]: Began running node model.archi.view
[0m15:04:48.431264 [info ] [Thread-1 (]: 6 of 7 START sql view model main.view .......................................... [RUN]
[0m15:04:48.431264 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.view)
[0m15:04:48.432288 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m15:04:48.433316 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m15:04:48.433316 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m15:04:48.435371 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.view"
[0m15:04:48.436416 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m15:04:48.436416 [debug] [Thread-1 (]: On model.archi.view: BEGIN
[0m15:04:48.436416 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:04:48.449236 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m15:04:48.450239 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m15:04:48.450239 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */

  
  create view "pytorch_data"."main"."view__dbt_tmp" as (
    SELECT * FROM raw_commits
  );

[0m15:04:48.450743 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.452306 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m15:04:48.452306 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view" rename to "view__dbt_backup"
[0m15:04:48.453335 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.454359 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m15:04:48.455383 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
alter view "pytorch_data"."main"."view__dbt_tmp" rename to "view"
[0m15:04:48.455383 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.456481 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m15:04:48.456481 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m15:04:48.456481 [debug] [Thread-1 (]: On model.archi.view: COMMIT
[0m15:04:48.458549 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:48.459576 [debug] [Thread-1 (]: Using duckdb connection "model.archi.view"
[0m15:04:48.459576 [debug] [Thread-1 (]: On model.archi.view: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.view"} */
drop view if exists "pytorch_data"."main"."view__dbt_backup" cascade
[0m15:04:48.460580 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:48.461085 [debug] [Thread-1 (]: On model.archi.view: Close
[0m15:04:48.481655 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd3fee01-7fad-41ca-9c7b-358f4a68ade5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CD613EC0>]}
[0m15:04:48.481655 [info ] [Thread-1 (]: 6 of 7 OK created sql view model main.view ..................................... [[32mOK[0m in 0.05s]
[0m15:04:48.482659 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m15:04:48.482659 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m15:04:48.482659 [info ] [Thread-1 (]: 7 of 7 START sql view model main_application.fcommits .......................... [RUN]
[0m15:04:48.483688 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.view, now model.archi.fcommits)
[0m15:04:48.483688 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m15:04:48.485749 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m15:04:48.485749 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m15:04:48.487798 [debug] [Thread-1 (]: Writing runtime sql for node "model.archi.fcommits"
[0m15:04:48.487798 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m15:04:48.488832 [debug] [Thread-1 (]: On model.archi.fcommits: BEGIN
[0m15:04:48.488832 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:04:48.501673 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m15:04:48.501673 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m15:04:48.501673 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */

  
  create view "pytorch_data"."main_application"."fcommits__dbt_tmp" as (
    with clean_commits as (
    select
        "commit.author.name",
        "commit.author.date",
        "commit.url",
        "author.id"
    from "pytorch_data"."main_cleansed"."cleancommit"  -- Utilisation de ref() pour se référer au modèle cleancommit.sql
),

clean_contributors as (
    select
        id,
        login
    from "pytorch_data"."main_cleansed"."cleancontributor"  -- Utilisation de ref() pour se référer au modèle cleancontributor.sql
)

select
    clean_commits."author.id",
    clean_commits."commit.url",
    clean_commits."commit.author.name",
    clean_commits."commit.author.date",
    clean_contributors.id as contributor_id,
    clean_contributors.login as contributor_login
from clean_commits
left join clean_contributors
    on clean_contributors.id = clean_commits."author.id"
  );

[0m15:04:48.502677 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.504066 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m15:04:48.505096 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
alter view "pytorch_data"."main_application"."fcommits" rename to "fcommits__dbt_backup"
[0m15:04:48.505096 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.507636 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m15:04:48.507636 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
alter view "pytorch_data"."main_application"."fcommits__dbt_tmp" rename to "fcommits"
[0m15:04:48.507636 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:04:48.508660 [debug] [Thread-1 (]: On model.archi.fcommits: COMMIT
[0m15:04:48.508660 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m15:04:48.509685 [debug] [Thread-1 (]: On model.archi.fcommits: COMMIT
[0m15:04:48.509685 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:48.512234 [debug] [Thread-1 (]: Using duckdb connection "model.archi.fcommits"
[0m15:04:48.512234 [debug] [Thread-1 (]: On model.archi.fcommits: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "node_id": "model.archi.fcommits"} */
drop view if exists "pytorch_data"."main_application"."fcommits__dbt_backup" cascade
[0m15:04:48.513318 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:04:48.514348 [debug] [Thread-1 (]: On model.archi.fcommits: Close
[0m15:04:48.532899 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd3fee01-7fad-41ca-9c7b-358f4a68ade5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CD64E120>]}
[0m15:04:48.533945 [info ] [Thread-1 (]: 7 of 7 OK created sql view model main_application.fcommits ..................... [[32mOK[0m in 0.05s]
[0m15:04:48.533945 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m15:04:48.534971 [debug] [MainThread]: Using duckdb connection "master"
[0m15:04:48.534971 [debug] [MainThread]: On master: BEGIN
[0m15:04:48.534971 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:04:48.548216 [debug] [MainThread]: SQL status: OK in 0.013 seconds
[0m15:04:48.548216 [debug] [MainThread]: On master: COMMIT
[0m15:04:48.548216 [debug] [MainThread]: Using duckdb connection "master"
[0m15:04:48.549259 [debug] [MainThread]: On master: COMMIT
[0m15:04:48.549259 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:04:48.549259 [debug] [MainThread]: On master: Close
[0m15:04:48.550769 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:04:48.550769 [debug] [MainThread]: Connection 'create_pytorch_data_main' was properly closed.
[0m15:04:48.551802 [debug] [MainThread]: Connection 'list_pytorch_data_main' was properly closed.
[0m15:04:48.551802 [debug] [MainThread]: Connection 'model.archi.fcommits' was properly closed.
[0m15:04:48.552335 [info ] [MainThread]: 
[0m15:04:48.552335 [info ] [MainThread]: Finished running 7 view models in 0 hours 0 minutes and 0.75 seconds (0.75s).
[0m15:04:48.552868 [debug] [MainThread]: Command end result
[0m15:04:48.563119 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:04:48.564188 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:04:48.567752 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:04:48.567752 [info ] [MainThread]: 
[0m15:04:48.567752 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:04:48.568759 [info ] [MainThread]: 
[0m15:04:48.568759 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m15:04:48.569263 [debug] [MainThread]: Command `dbt run` succeeded at 15:04:48.569263 after 1.32 seconds
[0m15:04:48.569263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CB186AB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CB187F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298CB185730>]}
[0m15:04:48.569263 [debug] [MainThread]: Flushing usage events
[0m15:04:49.022955 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:04:56.829992 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226AC2E76E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226AC2E7470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226AC69B7D0>]}


============================== 15:04:56.832537 | 2a7532cc-5509-4cb2-bac9-a842545671c0 ==============================
[0m15:04:56.832537 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:04:56.833565 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt docs generate', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:04:56.941939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2a7532cc-5509-4cb2-bac9-a842545671c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226AC82F620>]}
[0m15:04:56.971588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2a7532cc-5509-4cb2-bac9-a842545671c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226ABC84A40>]}
[0m15:04:56.973678 [info ] [MainThread]: Registered adapter: duckdb=1.9.1
[0m15:04:57.093767 [debug] [MainThread]: checksum: 5e8d1596cf4eae33c11286bbb248a722d21b9f00d8a7ced8137c642517055418, vars: {}, profile: , target: , version: 1.9.1
[0m15:04:57.157423 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:04:57.158460 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:04:57.171814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2a7532cc-5509-4cb2-bac9-a842545671c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226ADBAC620>]}
[0m15:04:57.185904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2a7532cc-5509-4cb2-bac9-a842545671c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226ADD6C5F0>]}
[0m15:04:57.186936 [info ] [MainThread]: Found 7 models, 424 macros
[0m15:04:57.186936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a7532cc-5509-4cb2-bac9-a842545671c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226AC874950>]}
[0m15:04:57.188448 [info ] [MainThread]: 
[0m15:04:57.188448 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:04:57.189483 [info ] [MainThread]: 
[0m15:04:57.189483 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:04:57.192016 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_pytorch_data_main'
[0m15:04:57.235774 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:04:57.235774 [debug] [ThreadPool]: On list_pytorch_data_main: BEGIN
[0m15:04:57.235774 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:04:57.246040 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m15:04:57.281441 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main"
[0m15:04:57.281441 [debug] [ThreadPool]: On list_pytorch_data_main: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:04:57.298409 [debug] [ThreadPool]: SQL status: OK in 0.017 seconds
[0m15:04:57.299435 [debug] [ThreadPool]: On list_pytorch_data_main: ROLLBACK
[0m15:04:57.299435 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main'
[0m15:04:57.300944 [debug] [ThreadPool]: On list_pytorch_data_main: Close
[0m15:04:57.302989 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main, now list_pytorch_data_main_cleansed)
[0m15:04:57.305054 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:04:57.305054 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: BEGIN
[0m15:04:57.306084 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:57.313914 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m15:04:57.314949 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_cleansed"
[0m15:04:57.314949 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_cleansed"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_cleansed'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:04:57.331954 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:04:57.332465 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: ROLLBACK
[0m15:04:57.332975 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_cleansed'
[0m15:04:57.333516 [debug] [ThreadPool]: On list_pytorch_data_main_cleansed: Close
[0m15:04:57.334543 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_pytorch_data_main_cleansed, now list_pytorch_data_main_application)
[0m15:04:57.337076 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m15:04:57.337076 [debug] [ThreadPool]: On list_pytorch_data_main_application: BEGIN
[0m15:04:57.337076 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:04:57.345219 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:04:57.346242 [debug] [ThreadPool]: Using duckdb connection "list_pytorch_data_main_application"
[0m15:04:57.346242 [debug] [ThreadPool]: On list_pytorch_data_main_application: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "list_pytorch_data_main_application"} */
select
      'pytorch_data' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_application'
    and lower(table_catalog) = 'pytorch_data'
  
[0m15:04:57.362632 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:04:57.363638 [debug] [ThreadPool]: On list_pytorch_data_main_application: ROLLBACK
[0m15:04:57.364144 [debug] [ThreadPool]: Failed to rollback 'list_pytorch_data_main_application'
[0m15:04:57.364144 [debug] [ThreadPool]: On list_pytorch_data_main_application: Close
[0m15:04:57.367209 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a7532cc-5509-4cb2-bac9-a842545671c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226ADCA8830>]}
[0m15:04:57.368716 [debug] [Thread-1 (]: Began running node model.archi.cleancommit
[0m15:04:57.368716 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.archi.cleancommit'
[0m15:04:57.369722 [debug] [Thread-1 (]: Began compiling node model.archi.cleancommit
[0m15:04:57.373797 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancommit"
[0m15:04:57.374848 [debug] [Thread-1 (]: Began executing node model.archi.cleancommit
[0m15:04:57.374848 [debug] [Thread-1 (]: Finished running node model.archi.cleancommit
[0m15:04:57.374848 [debug] [Thread-1 (]: Began running node model.archi.cleancontributor
[0m15:04:57.375874 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancommit, now model.archi.cleancontributor)
[0m15:04:57.375874 [debug] [Thread-1 (]: Began compiling node model.archi.cleancontributor
[0m15:04:57.376918 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleancontributor"
[0m15:04:57.377943 [debug] [Thread-1 (]: Began executing node model.archi.cleancontributor
[0m15:04:57.377943 [debug] [Thread-1 (]: Finished running node model.archi.cleancontributor
[0m15:04:57.378950 [debug] [Thread-1 (]: Began running node model.archi.cleanissue
[0m15:04:57.379456 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleancontributor, now model.archi.cleanissue)
[0m15:04:57.379456 [debug] [Thread-1 (]: Began compiling node model.archi.cleanissue
[0m15:04:57.379456 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanissue"
[0m15:04:57.380966 [debug] [Thread-1 (]: Began executing node model.archi.cleanissue
[0m15:04:57.380966 [debug] [Thread-1 (]: Finished running node model.archi.cleanissue
[0m15:04:57.381989 [debug] [Thread-1 (]: Began running node model.archi.cleanpr
[0m15:04:57.381989 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanissue, now model.archi.cleanpr)
[0m15:04:57.381989 [debug] [Thread-1 (]: Began compiling node model.archi.cleanpr
[0m15:04:57.384109 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.cleanpr"
[0m15:04:57.385112 [debug] [Thread-1 (]: Began executing node model.archi.cleanpr
[0m15:04:57.385112 [debug] [Thread-1 (]: Finished running node model.archi.cleanpr
[0m15:04:57.386138 [debug] [Thread-1 (]: Began running node model.archi.dcontributeur
[0m15:04:57.386138 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.cleanpr, now model.archi.dcontributeur)
[0m15:04:57.386138 [debug] [Thread-1 (]: Began compiling node model.archi.dcontributeur
[0m15:04:57.387168 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.dcontributeur"
[0m15:04:57.388198 [debug] [Thread-1 (]: Began executing node model.archi.dcontributeur
[0m15:04:57.388198 [debug] [Thread-1 (]: Finished running node model.archi.dcontributeur
[0m15:04:57.388198 [debug] [Thread-1 (]: Began running node model.archi.view
[0m15:04:57.389202 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.dcontributeur, now model.archi.view)
[0m15:04:57.389202 [debug] [Thread-1 (]: Began compiling node model.archi.view
[0m15:04:57.389705 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.view"
[0m15:04:57.391213 [debug] [Thread-1 (]: Began executing node model.archi.view
[0m15:04:57.391213 [debug] [Thread-1 (]: Finished running node model.archi.view
[0m15:04:57.391213 [debug] [Thread-1 (]: Began running node model.archi.fcommits
[0m15:04:57.392239 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.archi.view, now model.archi.fcommits)
[0m15:04:57.392239 [debug] [Thread-1 (]: Began compiling node model.archi.fcommits
[0m15:04:57.393267 [debug] [Thread-1 (]: Writing injected SQL for node "model.archi.fcommits"
[0m15:04:57.394294 [debug] [Thread-1 (]: Began executing node model.archi.fcommits
[0m15:04:57.394294 [debug] [Thread-1 (]: Finished running node model.archi.fcommits
[0m15:04:57.395338 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:04:57.395338 [debug] [MainThread]: Connection 'list_pytorch_data_main_application' was properly closed.
[0m15:04:57.395338 [debug] [MainThread]: Connection 'model.archi.fcommits' was properly closed.
[0m15:04:57.396367 [debug] [MainThread]: Command end result
[0m15:04:57.422577 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:04:57.423609 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:04:57.427754 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\run_results.json
[0m15:04:57.428776 [debug] [MainThread]: Acquiring new duckdb connection 'generate_catalog'
[0m15:04:57.428776 [info ] [MainThread]: Building catalog
[0m15:04:57.433838 [debug] [ThreadPool]: Acquiring new duckdb connection 'pytorch_data.information_schema'
[0m15:04:57.436957 [debug] [ThreadPool]: Using duckdb connection "pytorch_data.information_schema"
[0m15:04:57.436957 [debug] [ThreadPool]: On pytorch_data.information_schema: BEGIN
[0m15:04:57.437984 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:04:57.446731 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m15:04:57.446731 [debug] [ThreadPool]: Using duckdb connection "pytorch_data.information_schema"
[0m15:04:57.446731 [debug] [ThreadPool]: On pytorch_data.information_schema: /* {"app": "dbt", "dbt_version": "1.9.1", "profile_name": "archi", "target_name": "dev", "connection_name": "pytorch_data.information_schema"} */
with relations AS (
      select
        t.table_name
        , t.database_name
        , t.schema_name
        , 'BASE TABLE' as table_type
        , t.comment as table_comment
      from duckdb_tables() t
      WHERE t.database_name = 'pytorch_data'
      UNION ALL
      SELECT v.view_name as table_name
      , v.database_name
      , v.schema_name
      , 'VIEW' as table_type
      , v.comment as table_comment
      from duckdb_views() v
      WHERE v.database_name = 'pytorch_data'
    )
    select
        'pytorch_data' as table_database,
        r.schema_name as table_schema,
        r.table_name,
        r.table_type,
        r.table_comment,
        c.column_name,
        c.column_index as column_index,
        c.data_type as column_type,
        c.comment as column_comment,
        '' as table_owner
    FROM relations r JOIN duckdb_columns() c ON r.schema_name = c.schema_name AND r.table_name = c.table_name
    WHERE (upper(r.schema_name) = upper('main_cleansed') or upper(r.schema_name) = upper('main_application') or upper(r.schema_name) = upper('main'))
    ORDER BY
        r.schema_name,
        r.table_name,
        c.column_index
[0m15:04:57.466696 [debug] [ThreadPool]: SQL status: OK in 0.019 seconds
[0m15:04:57.489778 [debug] [ThreadPool]: On pytorch_data.information_schema: ROLLBACK
[0m15:04:57.489778 [debug] [ThreadPool]: Failed to rollback 'pytorch_data.information_schema'
[0m15:04:57.489778 [debug] [ThreadPool]: On pytorch_data.information_schema: Close
[0m15:04:57.514854 [debug] [MainThread]: Wrote artifact CatalogArtifact to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\catalog.json
[0m15:04:57.525087 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\manifest.json
[0m15:04:57.526126 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\semantic_manifest.json
[0m15:04:57.526126 [info ] [MainThread]: Catalog written to C:\Users\julie\repo\ArchiDecisionnelle\archi\target\catalog.json
[0m15:04:57.526126 [debug] [MainThread]: Command `dbt docs generate` succeeded at 15:04:57.526126 after 0.78 seconds
[0m15:04:57.526126 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m15:04:57.527639 [debug] [MainThread]: Connection 'pytorch_data.information_schema' was properly closed.
[0m15:04:57.527639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226A8B65FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226AC2E6C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226AE14BA70>]}
[0m15:04:57.527639 [debug] [MainThread]: Flushing usage events
[0m15:04:57.886623 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:05:02.313791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014818FE0A10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014818FE1970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014818FE0BF0>]}


============================== 15:05:02.316329 | 4fc3c79a-e818-494f-955b-809885f8f7fb ==============================
[0m15:05:02.316329 [info ] [MainThread]: Running with dbt=1.9.1
[0m15:05:02.316329 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\julie\\repo\\ArchiDecisionnelle\\archi\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt docs serve', 'send_anonymous_usage_stats': 'True'}
[0m15:05:02.428626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4fc3c79a-e818-494f-955b-809885f8f7fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014819505B20>]}
[0m15:05:02.459449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4fc3c79a-e818-494f-955b-809885f8f7fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000148194F4200>]}
